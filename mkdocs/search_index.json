{
    "docs": [
        {
            "location": "/", 
            "text": "Installation Guides\n\n\nThe Open Science Grid consists primarily of a fabric of services at\nparticipating sites.\n\n\nOne of the most common ways of participating in the OSG is to install\none of our software services at your site and provide computational\npower opportunistically to the grid.\n\n\nOur most common software products include:\n\n\n\n\nHTCondor CE Installation\n: Provides a \ngateway\n\n  between the grid and your batch system.\n\n\nHTTP Proxy\n: Caches the most commonly-used files at your\n  site to preserve bandwidth (a custom packaging of the venerable \nsquid2\n software).\n\n\nCVMFS\n The CernVM File System (CVMFS) is a global-scale, read-only,\n  hierarchical filesystem.  CVMFS volumes distribute the majority of the scientific\n  software used on OSG in addition to the OSG worker node client.\n\n\nWorker node client\n and \nglexec\n: An RPM-based install\n  of the worker node software; this includes the \nglexec\n binary (not provided by the\n  CVMFS install) which allows pilots to securely isolate payload jobs.\n\n\n\n\nYou can help!\n\n\nDocumentation is a task that is never done!  Feel free to fork this on github and\nsend us any updates or corrections.\n\n\nIn particular, many documents are being converted from our old twiki to this site.\nWe have used an automatic converter, but most documents need a human touch prior\nto being included in the table of contents.\n\n\nIf you'd like to contribute, please consider trying to clean up one of these\ndocuments:\n\n\n\n\nCA Certificate Updater script\n\n\nHost certificate management package\n\n\nJob Router Recipes\n\n\nInstalling the Worker Node from OASIS\n\n\nInstalling a GridFTP Server", 
            "title": "Home"
        }, 
        {
            "location": "/#installation-guides", 
            "text": "The Open Science Grid consists primarily of a fabric of services at\nparticipating sites.  One of the most common ways of participating in the OSG is to install\none of our software services at your site and provide computational\npower opportunistically to the grid.  Our most common software products include:   HTCondor CE Installation : Provides a  gateway \n  between the grid and your batch system.  HTTP Proxy : Caches the most commonly-used files at your\n  site to preserve bandwidth (a custom packaging of the venerable  squid2  software).  CVMFS  The CernVM File System (CVMFS) is a global-scale, read-only,\n  hierarchical filesystem.  CVMFS volumes distribute the majority of the scientific\n  software used on OSG in addition to the OSG worker node client.  Worker node client  and  glexec : An RPM-based install\n  of the worker node software; this includes the  glexec  binary (not provided by the\n  CVMFS install) which allows pilots to securely isolate payload jobs.", 
            "title": "Installation Guides"
        }, 
        {
            "location": "/#you-can-help", 
            "text": "Documentation is a task that is never done!  Feel free to fork this on github and\nsend us any updates or corrections.  In particular, many documents are being converted from our old twiki to this site.\nWe have used an automatic converter, but most documents need a human touch prior\nto being included in the table of contents.  If you'd like to contribute, please consider trying to clean up one of these\ndocuments:   CA Certificate Updater script  Host certificate management package  Job Router Recipes  Installing the Worker Node from OASIS  Installing a GridFTP Server", 
            "title": "You can help!"
        }, 
        {
            "location": "/install-overview/", 
            "text": "OSG Site Installation Overview\n\n\nThis document outlines the overall installation process for an OSG site and provides many links into detailed installation, configuration, troubleshooting, and similar pages. If you do not see software-related technical documentation listed here, try the search bar to the left or contacting us at \ngoc@opensciencegrid.org\n.\n\n\nPlan the Site\n\n\nIf you have not done so already, \nplan the overall architecture of your OSG site\n. It is recommended that your plan be sufficiently detailed to include the OSG hosts that are needed and the main software components for each host. Be sure to consider \nthe operating systems that OSG supports\n. A simple way to organize this information is in a table; for example, a basic site might include:\n\n\n\n\n\n\n\n\nPurpose\n\n\nHost\n\n\nMajor Software\n\n\n\n\n\n\n\n\n\n\nCompute Element (CE)\n\n\nosg-ce.example.edu\n\n\nOSG CE, HTCondor Central Manager, etc. (\nosg-ce-condor\n)\n\n\n\n\n\n\nWorker Nodes\n\n\nwNNN.cluster.example.edu\n\n\nOSG worker node client (\nosg-wn-client\n)\n\n\n\n\n\n\n\n\nPrepare the Batch System\n\n\nThe assumption is that you have an existing batch system at your site. Currently, we support \nHTCondor\n, \nLSF\n, \nPBS\n and \nTORQUE\n, \nSGE\n, and \nSlurm\n batch systems.\n\n\nFor smaller sites (less than 50 worker nodes), the most common way to add a site to OSG is to install the OSG Compute Element (CE) on the central host of your batch system.  At such a site - especially if you have minimal time to maintain a CE - you may want to contact goc@opensciencegrid.org to ask about using an OSG-hosted CE instead of running your own.  Before proceeding with an install, be sure that you can submit and successfully run a job from your OSG CE host into your batch system.\n\n\nAdd OSG Software\n\n\nIf necessary, provision all OSG hosts that are in your site plan and that do not exist yet.\n\n\n\n\nNote\n\n\nFor sites with more than a trivial number of hosts, it is recommended to use some sort of configuration management tool to install, configure, and maintain your site. While beyond the scope of OSG\u2019s documentation to explain how to select and use such a system, some popular configuration management tools are \nPuppet\n, \nChef\n, \nAnsible\n, and \nCFEngine\n.\n\n\n\n\nGeneral Installation Instructions\n\n\n\n\nSecurity information for OSG signed RPMs\n\n\nUsing Yum and RPM\n\n\nInstall the OSG repositories\n\n\nOSG Software release series\n - look here to upgrade from OSG 3.1 to OSG 3.2 or from OSG 3.2 to OSG 3.3\n\n\nInstallation best practices\n\n\nFirewalls the complete guide\n\n\n\n\nInstalling and Managing Certificates for Site Security\n\n\n\n\nInstalling the grid certificate authorities (CAs)\n\n\nHow do I get PKI host and service X.509 certificates?\n\n\nAutomatically updating the grid certificate authorities (CAs)\n\n\nSHA-2 certificates and minimum required OSG software versions\n\n\nOSG PKI command line client reference\n\n\n\n\nAdding OSG Software to Worker Nodes\n\n\n\n\nWorker Node (WN) Client Overview\n\n\nInstall the WN client software on every worker node \u2013 pick a method:\n\n\nUsing RPMs\n \u2013 useful when managing your worker nodes with a tool (e.g., Puppet, Chef)\n\n\nUsing a tarball\n \u2013 useful for installation onto a shared filesystem (does not require root access)\n\n\nUsing OASIS\n \u2013 useful when \nOASIS\n is already mounted on your worker nodes\n\n\n\n\n\n\n(optional) \nInstall the CernVM-FS client\n to make it easy for user jobs to install needed software from OSG\u2019s OASIS repositories\n\n\n(optional, advanced) \nInstall gLExec on the OSG worker node\n, if you know you need it\n\n\n\n\nInstalling and Configuring the Compute Element\n\n\n\n\nPreparing to install the compute element\n\n\nInstall the compute element (HTCondor-CE and other software):\n\n\nOverview and architecture\n\n\nInstall HTCondor-CE\n\n\nConfigure the HTCondor-CE job router\n, including common recipes\n\n\nTroubleshooting HTCondor-CE installations\n\n\nSubmitting jobs to HTCondor-CE\n\n\n\n\n\n\nTroubleshooting osg-configure\n\n\n\n\nInstalling and Configuring Other Nodes\n\n\nAll of these node types and their services are optional, although OSG requires the Frontier Squid caching service if you have installed \nCVMFS\n on your worker nodes.\n\n\n\n\nInstall Frontier Squid, the HTTP caching proxy service\n\n\nRSV monitoring to monitor and report to OSG on the health of your site\n\n\nRSV Overview\n\n\nInstall RSV\n\n\nTroubleshooting RSV\n\n\n\n\n\n\nInstall the GlideinWMS VO Frontend\n if your want your users\u2019 jobs to run on the OSG\n\n\nInstall the RSV GlideinWMS Tester\n if you want to test your front-end's ability to submit jobs to sites in the OSG\n\n\n\n\n\n\nStorage element (pick one):\n\n\nGridFTP\n\n\nInstall standalone OSG GridFTP\n: GridFTP server\n\n\n(optional) \nInstall load-balanced OSG GridFTP\n: when a single GridFTP server isn't enough\n\n\n\n\n\n\nBeStMan\n\n\nBeStMan Overview\n: Bestman-related information, planning, and guides\n\n\nInstall Bestman SE\n: BeStMan2 SRM server + GridFTP server\n\n\nInstall Bestman Gateway Hadoop\n: BeStMan2 SRM server + GridFTP server + Hadoop\n\n\n\n\n\n\nHadoop Distributed File System (HDFS)\n\n\nHadoop Overview\n: HDFS information, planning, and guides\n\n\n\n\n\n\nXRootD\n\n\nXRootd Overview\n: XRootD information, planning, and guides\n\n\nInstall Xrootd Server\n: XRootD redirector installation\n\n\nInstall BeStMan-Gateway XRootD\n: BeStMan2 SRM server + GridFTP server + XRootD fuse\n\n\n\n\n\n\n\n\n\n\n\n\nTest OSG Software\n\n\nAt very least, it is vital to test \nmanual\n submission of jobs from inside and outside of your site through your CE to your batch system. If this process does not work manually, it will probably not work for the glideinWMS pilot factory either.\n\n\n\n\nTest job submission into an HTCondor-CE\n\n\nOSG Troubleshooting guide\n\n\nValidating Supported VOs\n\n\n\n\nStart GlideinWMS Pilot Submissions\n\n\nTo begin running \nGlideinWMS\n pilot jobs at your site, e-mail \n and tell them that you want to start accepting Glideins. Please provide them with the following information:\n\n\n\n\nThe type of CE (HTCondor-CE or the now-unsupported GRAM-CE)\n\n\nThe fully qualified hostname of the CE\n\n\nResource/WLCG name\n\n\nOS major version of your worker nodes\u00a0\u2014 EL\u00a06, EL\u00a07, or a mix of both?\n\n\nDo you accept multicore jobs?\n\n\nMaximum job walltime\n\n\nMaximum job memory usage\n\n\n\n\nOnce the factory team has enough information, they will start submitting pilots from the test factory to your CE. Initially, this will be one pilot at a time but once the factory verifies that pilot jobs are running successfully, that number will be ramped up to 10, then 100.\n\n\nVerify Reporting and Monitoring\n\n\nTo verify that your site is correctly reporting to the OSG, check \nOSG's Accounting Portal\n for records of your site reports (select your site from the drop-down box). If you have enabled the OSG VO, you can also check \nhttp://osg-flock.grid.iu.edu/monitoring/condor/sites/all_1day.html\n.\n\n\nScale Up Site to Full Production\n\n\nAfter successfully running all the pilot jobs that are submitted by the test factory and verifying your site reports, your site will be deemed production ready. No action is required on your end, factory operations will start submitting pilot jobs from the production factory.", 
            "title": "Installation Overview"
        }, 
        {
            "location": "/install-overview/#osg-site-installation-overview", 
            "text": "This document outlines the overall installation process for an OSG site and provides many links into detailed installation, configuration, troubleshooting, and similar pages. If you do not see software-related technical documentation listed here, try the search bar to the left or contacting us at  goc@opensciencegrid.org .", 
            "title": "OSG Site Installation Overview"
        }, 
        {
            "location": "/install-overview/#plan-the-site", 
            "text": "If you have not done so already,  plan the overall architecture of your OSG site . It is recommended that your plan be sufficiently detailed to include the OSG hosts that are needed and the main software components for each host. Be sure to consider  the operating systems that OSG supports . A simple way to organize this information is in a table; for example, a basic site might include:     Purpose  Host  Major Software      Compute Element (CE)  osg-ce.example.edu  OSG CE, HTCondor Central Manager, etc. ( osg-ce-condor )    Worker Nodes  wNNN.cluster.example.edu  OSG worker node client ( osg-wn-client )", 
            "title": "Plan the Site"
        }, 
        {
            "location": "/install-overview/#prepare-the-batch-system", 
            "text": "The assumption is that you have an existing batch system at your site. Currently, we support  HTCondor ,  LSF ,  PBS  and  TORQUE ,  SGE , and  Slurm  batch systems.  For smaller sites (less than 50 worker nodes), the most common way to add a site to OSG is to install the OSG Compute Element (CE) on the central host of your batch system.  At such a site - especially if you have minimal time to maintain a CE - you may want to contact goc@opensciencegrid.org to ask about using an OSG-hosted CE instead of running your own.  Before proceeding with an install, be sure that you can submit and successfully run a job from your OSG CE host into your batch system.", 
            "title": "Prepare the Batch System"
        }, 
        {
            "location": "/install-overview/#add-osg-software", 
            "text": "If necessary, provision all OSG hosts that are in your site plan and that do not exist yet.   Note  For sites with more than a trivial number of hosts, it is recommended to use some sort of configuration management tool to install, configure, and maintain your site. While beyond the scope of OSG\u2019s documentation to explain how to select and use such a system, some popular configuration management tools are  Puppet ,  Chef ,  Ansible , and  CFEngine .", 
            "title": "Add OSG Software"
        }, 
        {
            "location": "/install-overview/#general-installation-instructions", 
            "text": "Security information for OSG signed RPMs  Using Yum and RPM  Install the OSG repositories  OSG Software release series  - look here to upgrade from OSG 3.1 to OSG 3.2 or from OSG 3.2 to OSG 3.3  Installation best practices  Firewalls the complete guide", 
            "title": "General Installation Instructions"
        }, 
        {
            "location": "/install-overview/#installing-and-managing-certificates-for-site-security", 
            "text": "Installing the grid certificate authorities (CAs)  How do I get PKI host and service X.509 certificates?  Automatically updating the grid certificate authorities (CAs)  SHA-2 certificates and minimum required OSG software versions  OSG PKI command line client reference", 
            "title": "Installing and Managing Certificates for Site Security"
        }, 
        {
            "location": "/install-overview/#adding-osg-software-to-worker-nodes", 
            "text": "Worker Node (WN) Client Overview  Install the WN client software on every worker node \u2013 pick a method:  Using RPMs  \u2013 useful when managing your worker nodes with a tool (e.g., Puppet, Chef)  Using a tarball  \u2013 useful for installation onto a shared filesystem (does not require root access)  Using OASIS  \u2013 useful when  OASIS  is already mounted on your worker nodes    (optional)  Install the CernVM-FS client  to make it easy for user jobs to install needed software from OSG\u2019s OASIS repositories  (optional, advanced)  Install gLExec on the OSG worker node , if you know you need it", 
            "title": "Adding OSG Software to Worker Nodes"
        }, 
        {
            "location": "/install-overview/#installing-and-configuring-the-compute-element", 
            "text": "Preparing to install the compute element  Install the compute element (HTCondor-CE and other software):  Overview and architecture  Install HTCondor-CE  Configure the HTCondor-CE job router , including common recipes  Troubleshooting HTCondor-CE installations  Submitting jobs to HTCondor-CE    Troubleshooting osg-configure", 
            "title": "Installing and Configuring the Compute Element"
        }, 
        {
            "location": "/install-overview/#installing-and-configuring-other-nodes", 
            "text": "All of these node types and their services are optional, although OSG requires the Frontier Squid caching service if you have installed  CVMFS  on your worker nodes.   Install Frontier Squid, the HTTP caching proxy service  RSV monitoring to monitor and report to OSG on the health of your site  RSV Overview  Install RSV  Troubleshooting RSV    Install the GlideinWMS VO Frontend  if your want your users\u2019 jobs to run on the OSG  Install the RSV GlideinWMS Tester  if you want to test your front-end's ability to submit jobs to sites in the OSG    Storage element (pick one):  GridFTP  Install standalone OSG GridFTP : GridFTP server  (optional)  Install load-balanced OSG GridFTP : when a single GridFTP server isn't enough    BeStMan  BeStMan Overview : Bestman-related information, planning, and guides  Install Bestman SE : BeStMan2 SRM server + GridFTP server  Install Bestman Gateway Hadoop : BeStMan2 SRM server + GridFTP server + Hadoop    Hadoop Distributed File System (HDFS)  Hadoop Overview : HDFS information, planning, and guides    XRootD  XRootd Overview : XRootD information, planning, and guides  Install Xrootd Server : XRootD redirector installation  Install BeStMan-Gateway XRootD : BeStMan2 SRM server + GridFTP server + XRootD fuse", 
            "title": "Installing and Configuring Other Nodes"
        }, 
        {
            "location": "/install-overview/#test-osg-software", 
            "text": "At very least, it is vital to test  manual  submission of jobs from inside and outside of your site through your CE to your batch system. If this process does not work manually, it will probably not work for the glideinWMS pilot factory either.   Test job submission into an HTCondor-CE  OSG Troubleshooting guide  Validating Supported VOs", 
            "title": "Test OSG Software"
        }, 
        {
            "location": "/install-overview/#start-glideinwms-pilot-submissions", 
            "text": "To begin running  GlideinWMS  pilot jobs at your site, e-mail   and tell them that you want to start accepting Glideins. Please provide them with the following information:   The type of CE (HTCondor-CE or the now-unsupported GRAM-CE)  The fully qualified hostname of the CE  Resource/WLCG name  OS major version of your worker nodes\u00a0\u2014 EL\u00a06, EL\u00a07, or a mix of both?  Do you accept multicore jobs?  Maximum job walltime  Maximum job memory usage   Once the factory team has enough information, they will start submitting pilots from the test factory to your CE. Initially, this will be one pilot at a time but once the factory verifies that pilot jobs are running successfully, that number will be ramped up to 10, then 100.", 
            "title": "Start GlideinWMS Pilot Submissions"
        }, 
        {
            "location": "/install-overview/#verify-reporting-and-monitoring", 
            "text": "To verify that your site is correctly reporting to the OSG, check  OSG's Accounting Portal  for records of your site reports (select your site from the drop-down box). If you have enabled the OSG VO, you can also check  http://osg-flock.grid.iu.edu/monitoring/condor/sites/all_1day.html .", 
            "title": "Verify Reporting and Monitoring"
        }, 
        {
            "location": "/install-overview/#scale-up-site-to-full-production", 
            "text": "After successfully running all the pilot jobs that are submitted by the test factory and verifying your site reports, your site will be deemed production ready. No action is required on your end, factory operations will start submitting pilot jobs from the production factory.", 
            "title": "Scale Up Site to Full Production"
        }, 
        {
            "location": "/common/yum/", 
            "text": "YUM Repositories\n\n\nAbout This Document\n\n\nThis document introduces YUM repositories and how OSG uses them.\n\n\nRepositories\n\n\nOSG hosts four public-facing repositories at \nrepo.grid.iu.edu\n:\n\n\n\n\nrelease\n: This repository contains software that we are willing to support and can be used by the general community.\n\n\ncontrib\n: RPMs contributed from outside the OSG.\n\n\ntesting\n: This repository contains software ready for testing. If you install packages from here, they may be buggy, but we will provide limited assistance in providing a migration path to a fixed version.\n\n\ndevelopment\n: This repository is the bleeding edge. Installing from this repository may cause the host to stop functioning, and we will not assist in undoing any damage.\n\n\n\n\nOSG's RPM packages rely also on external packages provided by supported OSes and EPEL. You must have the following repositories available and enabled:\n\n\n\n\nyour OS repositories (SL 6/7, CentOS 6/7, or RHEL 6/7 repositories)\n\n\nEPEL repositories\n\n\nthe OSG repositories you'd like to use\n\n\n\n\nIf one of these repositories is missing you may have missing dependencies.\n\n\n\n\nWarning\n\n\nWe did not test other repositories. If you use packages from other repositories, like \njpackage\n, \ndag\n, or \nrpmforge\n, you may encounter problems.\n\n\n\n\nEnabling Repositories\n\n\nIn \nour advice on using yum\n you will learn many tricks and tips on using yum.\n\n\nTo use the packages in a repository without adding special options to the yum command the repository must be enabled.\n\n\nInstall the Yum Repositories required by OSG\n\n\nThe OSG RPMs currently support Red Hat Enterprise Linux 6, 7, and variants.\n\n\nOSG RPMs are distributed via the OSG yum repositories. Some packages depend on packages distributed via the \nEPEL\n repositories. So both repositories must be enabled.\n\n\nInstall EPEL\n\n\n\n\nInstall the EPEL repository, if not already present. \nNote:\n This enables EPEL by default. Choose the right version to match your OS version.\n#\n EPEL \n6\n \n(\nFor RHEL \n6\n, CentOS \n6\n, and SL \n6\n)\n\n\n[root@client ~] #\n rpm -Uvh https://dl.fedoraproject.org/pub/epel/epel-release-latest-6.noarch.rpm\n\n#\n EPEL \n7\n \n(\nFor RHEL \n7\n, CentOS \n7\n, and SL \n7\n)\n \n\n[root@client ~] #\n rpm -Uvh https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\nif you have your own mirror or configuration of the EPEL repository, you \nMUST\n verify that the OSG repository has a better yum priority than EPEL (\ndetails\n). Otherwise, you will have strange dependency resolution (\ndepsolving\n) issues.\n\n\n\n\nInstall the Yum priorities package\n\n\nFor packages that exist in both OSG and EPEL repositories, it is important to prefer the OSG ones or else OSG software installs may fail. Installing the Yum priorities package enables the repository priority system to work.\n\n\n\n\n\n\nInstall the Yum priorities package:\n\n\n[root@client ~]#\n yum install yum-plugin-priorities\n\n\n\n\n\n\n\n\n\nEnsure that \n/etc/yum.conf\n has the following line in the \n[main]\n section (particularly when using ROCKS), thereby enabling Yum plugins, including the priorities one:\n\n\nplugins=1\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nIf you do not have a required key you can force the installation using \n--nogpgcheck=\n; e.g., \nyum install --nogpgcheck yum-priorities\n.\n\n\n\n\nInstall OSG Repositories\n\n\nIf you are upgrading from one OSG series to another, remove the old OSG repository definition files and clean the Yum cache:\n\n\n[root@client ~]$\n yum clean all \n\n[root@client ~]$\n rpm -e osg-release\n\n\n\n\n\nThis step ensures that local changes to \n*.repo\n files will not block the installation of the new OSG repositories. After this step, \n*.repo\n files that have been changed will exist in \n/etc/yum.repos.d/\n with the \n*.rpmsave\n extension. After installing the new OSG repositories (the next step) you may want to apply any changes made in the \n*.rpmsave\n files to the new \n*.repo\n files.\n\n\nInstall the OSG repositories:\n\n\n[root@client ~]$\n rpm -Uvh \nURL\n\n\n\n\n\n\nWhere \nURL\n is one of the following:\n\n\n\n\n\n\n\n\nSeries\n\n\nEL6 URL (for RHEL 6, CentOS 6, or SL 6)\n\n\nEL7 URL (for RHEL 7, CentOS 7, or SL 7)\n\n\n\n\n\n\n\n\n\n\nOSG 3.3\n\n\nhttps://repo.grid.iu.edu/osg/3.3/osg-3.3-el6-release-latest.rpm\n\n\nhttps://repo.grid.iu.edu/osg/3.3/osg-3.3-el7-release-latest.rpm\n\n\n\n\n\n\nOSG 3.4\n\n\nhttps://repo.grid.iu.edu/osg/3.4/osg-3.4-el6-release-latest.rpm\n\n\nhttps://repo.grid.iu.edu/osg/3.4/osg-3.4-el7-release-latest.rpm\n\n\n\n\n\n\n\n\nPriorities\n\n\n Make sure you installed the Yum priorities plugin, as described above. Not doing so is a common mistake that causes failed installations.\n\n\nThe only OSG repository enabled by default is the release one. If you want to enable another one, such as \nosg-testing\n, then edit its file (e.g. \n/etc/yum.repos.d/osg-testing.repo\n) and change the enabled option from 0 to 1:\n\n\n[osg-testing]\n\n\nname\n=\nOSG Software for Enterprise Linux 5 - Testing - $basearch\n\n\n#baseurl=http://repo.grid.iu.edu/osg/3.2/el5/testing/$basearch\n\n\nmirrorlist\n=\nhttp://repo.grid.iu.edu/mirror/osg/3.2/el5/testing/$basearch\n\n\nfailovermethod\n=\npriority\n\n\npriority\n=\n98\n\n\nenabled\n=\n1\n\n\ngpgcheck\n=\n1\n\n\ngpgkey\n=\nfile:///etc/pki/rpm-gpg/RPM-GPG-KEY-OSG\n\n\n\n\n\n\n\n\nWarning\n\n\nif you have your own mirror or configuration of the EPEL repository, you \nMUST\n verify that the OSG repository has a better yum priority than EPEL. Otherwise, you will have strange dependency resolution issues.\n\n\n\n\nReference\n\n\n\n\nBasic use of Yum\n\n\nBest practices in using Yum", 
            "title": "Yum Repos"
        }, 
        {
            "location": "/common/yum/#yum-repositories", 
            "text": "", 
            "title": "YUM Repositories"
        }, 
        {
            "location": "/common/yum/#about-this-document", 
            "text": "This document introduces YUM repositories and how OSG uses them.", 
            "title": "About This Document"
        }, 
        {
            "location": "/common/yum/#repositories", 
            "text": "OSG hosts four public-facing repositories at  repo.grid.iu.edu :   release : This repository contains software that we are willing to support and can be used by the general community.  contrib : RPMs contributed from outside the OSG.  testing : This repository contains software ready for testing. If you install packages from here, they may be buggy, but we will provide limited assistance in providing a migration path to a fixed version.  development : This repository is the bleeding edge. Installing from this repository may cause the host to stop functioning, and we will not assist in undoing any damage.   OSG's RPM packages rely also on external packages provided by supported OSes and EPEL. You must have the following repositories available and enabled:   your OS repositories (SL 6/7, CentOS 6/7, or RHEL 6/7 repositories)  EPEL repositories  the OSG repositories you'd like to use   If one of these repositories is missing you may have missing dependencies.   Warning  We did not test other repositories. If you use packages from other repositories, like  jpackage ,  dag , or  rpmforge , you may encounter problems.", 
            "title": "Repositories"
        }, 
        {
            "location": "/common/yum/#enabling-repositories", 
            "text": "In  our advice on using yum  you will learn many tricks and tips on using yum.  To use the packages in a repository without adding special options to the yum command the repository must be enabled.", 
            "title": "Enabling Repositories"
        }, 
        {
            "location": "/common/yum/#install-the-yum-repositories-required-by-osg", 
            "text": "The OSG RPMs currently support Red Hat Enterprise Linux 6, 7, and variants.  OSG RPMs are distributed via the OSG yum repositories. Some packages depend on packages distributed via the  EPEL  repositories. So both repositories must be enabled.", 
            "title": "Install the Yum Repositories required by OSG"
        }, 
        {
            "location": "/common/yum/#install-epel", 
            "text": "Install the EPEL repository, if not already present.  Note:  This enables EPEL by default. Choose the right version to match your OS version. #  EPEL  6   ( For RHEL  6 , CentOS  6 , and SL  6 )  [root@client ~] #  rpm -Uvh https://dl.fedoraproject.org/pub/epel/epel-release-latest-6.noarch.rpm #  EPEL  7   ( For RHEL  7 , CentOS  7 , and SL  7 )   [root@client ~] #  rpm -Uvh https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm     Warning  if you have your own mirror or configuration of the EPEL repository, you  MUST  verify that the OSG repository has a better yum priority than EPEL ( details ). Otherwise, you will have strange dependency resolution ( depsolving ) issues.", 
            "title": "Install EPEL"
        }, 
        {
            "location": "/common/yum/#install-the-yum-priorities-package", 
            "text": "For packages that exist in both OSG and EPEL repositories, it is important to prefer the OSG ones or else OSG software installs may fail. Installing the Yum priorities package enables the repository priority system to work.    Install the Yum priorities package:  [root@client ~]#  yum install yum-plugin-priorities    Ensure that  /etc/yum.conf  has the following line in the  [main]  section (particularly when using ROCKS), thereby enabling Yum plugins, including the priorities one:  plugins=1     Note  If you do not have a required key you can force the installation using  --nogpgcheck= ; e.g.,  yum install --nogpgcheck yum-priorities .", 
            "title": "Install the Yum priorities package"
        }, 
        {
            "location": "/common/yum/#install-osg-repositories", 
            "text": "If you are upgrading from one OSG series to another, remove the old OSG repository definition files and clean the Yum cache:  [root@client ~]$  yum clean all  [root@client ~]$  rpm -e osg-release  This step ensures that local changes to  *.repo  files will not block the installation of the new OSG repositories. After this step,  *.repo  files that have been changed will exist in  /etc/yum.repos.d/  with the  *.rpmsave  extension. After installing the new OSG repositories (the next step) you may want to apply any changes made in the  *.rpmsave  files to the new  *.repo  files.  Install the OSG repositories:  [root@client ~]$  rpm -Uvh  URL   Where  URL  is one of the following:     Series  EL6 URL (for RHEL 6, CentOS 6, or SL 6)  EL7 URL (for RHEL 7, CentOS 7, or SL 7)      OSG 3.3  https://repo.grid.iu.edu/osg/3.3/osg-3.3-el6-release-latest.rpm  https://repo.grid.iu.edu/osg/3.3/osg-3.3-el7-release-latest.rpm    OSG 3.4  https://repo.grid.iu.edu/osg/3.4/osg-3.4-el6-release-latest.rpm  https://repo.grid.iu.edu/osg/3.4/osg-3.4-el7-release-latest.rpm", 
            "title": "Install OSG Repositories"
        }, 
        {
            "location": "/common/yum/#priorities", 
            "text": "Make sure you installed the Yum priorities plugin, as described above. Not doing so is a common mistake that causes failed installations.  The only OSG repository enabled by default is the release one. If you want to enable another one, such as  osg-testing , then edit its file (e.g.  /etc/yum.repos.d/osg-testing.repo ) and change the enabled option from 0 to 1:  [osg-testing]  name = OSG Software for Enterprise Linux 5 - Testing - $basearch  #baseurl=http://repo.grid.iu.edu/osg/3.2/el5/testing/$basearch  mirrorlist = http://repo.grid.iu.edu/mirror/osg/3.2/el5/testing/$basearch  failovermethod = priority  priority = 98  enabled = 1  gpgcheck = 1  gpgkey = file:///etc/pki/rpm-gpg/RPM-GPG-KEY-OSG    Warning  if you have your own mirror or configuration of the EPEL repository, you  MUST  verify that the OSG repository has a better yum priority than EPEL. Otherwise, you will have strange dependency resolution issues.", 
            "title": "Priorities"
        }, 
        {
            "location": "/common/yum/#reference", 
            "text": "Basic use of Yum  Best practices in using Yum", 
            "title": "Reference"
        }, 
        {
            "location": "/common/ca/", 
            "text": "Installing Certificate Authorities Certificates and related RPMs\n\n\nThis document provides you with details of various options to install the Certificate Authority (CA) certificates and have up-to-date certificate revocation list (CRL).\n\n\nWhen installing software with RPMs, you need to decide how you want to install the Certificate Authority (CA) certificates. You might ask \"why do I care? Can\u2019t you just give them to me?\" We can, but you have a few things to consider:\n\n\n\n\nWhat set of CA certificates do you want? How much control do you want over the set of CA certificates? (Some sites might not want to install specific CAs for policy or security reasons.)\n\n\nHow do you want to update them?\n\n\nDo you want to centrally manage the CA certificates or install them on each computer at your site?\n\n\n\n\nYou have four options for installing CA certificates:\n\n\n\n\nInstall an RPM for a specific set of CA certificates.\n\n\nInstall \nosg-update-certs\n, a program that lets you install/update a predefined set of CA certificates, then adjust the set by adding or deleting specific CAs.\n\n\nInstall an RPM that installs \nno\n CAs. This is useful when you want your RPM installations to succeed (because our RPMs require CA certificates, and this RPM satisfies that dependency) but you want to manage them with your own technique.\n\n\nMake no choice, let \nyum\n decide for you.\n\n\n\n\nAdditionally this page also provides instruction on installation of a tool (fetch-crl) to ensure your site has up-to-date certificate revocation list (CRL) from the CA.\n\n\nPrior to following the instructions on this page, you must enable our \nyum repositories\n\n\nInstall CA certificates: Options\n\n\nPlease choose one of the four options to install the CA certificates.\n\n\nOption 1: Install an RPM for a specific set of CA certificates\n\n\nIf you want to install an RPM for one of our predefined CA certificates, you have two choices to make:\n\n\nWhich set of CAs?\n\n\n\n\n(\nrecommended\n) The OSG CA certificates. This is similar to the IGTF set, but may have a small number of additions or deletions. (See \nhere\n for details)\n\n\nThe default \nIGTF\n CA certificates.\n\n\n\n\nDepending on your choice, you select one of two RPMs:\n\n\n\n\n\n\n\n\nSet of CAs\n\n\nFormat\n --\n\n\nRPM name\n\n\nInstallation command (as root)\n\n\n\n\n\n\n\n\n\n\nOSG\n\n\nOpenSSL-both\n\n\nosg-ca-certs\n\n\nyum install osg-ca-certs\n\n\n\n\n\n\nIGTF\n\n\nOpenSSL-both\n\n\nigtf-ca-certs\n\n\nyum install igtf-ca-certs\n\n\n\n\n\n\n\n\nHow do I keep CAs updated?\n\n\nPlease follow the \nupdate instructions\n to make sure that the CAs are kept updated.\n\n\nOption 2: Install osg-update-certs\n\n\nInstall this with:\n\n\n[root@client ~]$ yum install osg-ca-scripts\n\n\n\n\n\n\nYou have the same choices for CA certificates as above. In order to choose, you will run \nosg-ca-manage\n, which will install the CA certificates. Then (if desired) you need to enable periodic updating of the CA certificates.\n\n\n\n\n\n\n\n\nSet of CAs\n\n\nFormat\n\n\nCA certs name\n\n\nInstallation command (as root)\n\n\n\n\n\n\n\n\n\n\nOSG\n\n\nOpenSSL-both\n\n\nosg\n\n\n/usr/sbin/osg-ca-manage setupCA --location root --url osg\n\n\n\n\n\n\nIGTF\n\n\nOpenSSL-both\n\n\nigtf\n\n\n/usr/sbin/osg-ca-manage setupCA --location root --url igtf\n\n\n\n\n\n\n\n\nHere is an example:\n\n\n[root@client ~]$ /usr/sbin/osg-ca-manage setupCA --location root --url osg \n\n\nSetting\n \nup\n \nCA\n \nCertificates\n \nfor\n \nOSG\n \ninstallation\n\n\nCA\n \nCertificates\n \nwill\n \nbe\n \ninstalled\n \ninto\n \n/\netc\n/\ngrid\n-\nsecurity\n/\ncertificates\n\n\nosg\n-\nupdate\n-\ncerts\n\n  \nLog\n \nfile\n:\n \n/\nvar\n/\nlog\n/\nosg\n-\nupdate\n-\ncerts\n.\nlog\n\n  \nUpdates\n \nfrom\n:\n \nhttp\n:\n//\nsoftware\n.\ngrid\n.\niu\n.\nedu\n/\npacman\n/\ncadist\n/\nca\n-\ncerts\n-\nversion\n-\nnew\n\n\n\nWill\n \nupdate\n \nCA\n \ncertificates\n \nfrom\n \nversion\n \nunknown\n \nto\n \nversion\n \n1.21\nNEW\n.\n\n\nUpdate\n \nsuccessful\n.\n\n\n\nSetup\n \ncompleted\n \nsuccessfully\n.\n\n\n\n\n\n\nInitially the CA certificates will not be updated. You can tell by looking at:\n\n\n[root@client ~]$ /sbin/service osg-update-certs-cron  status\n\n\nPeriodic\n \nosg\n-\nupdate\n-\ncerts\n \nis\n \ndisabled\n.\n\n\n\n\n\n\nYou can enable the \ncron\n job that updates the CA certs with:\n\n\n[root@client ~]$ /sbin/service osg-update-certs-cron  start\n\n\nEnabling\n \nperiodic\n \nosg\n-\nupdate\n-\ncerts\n:\n                        \n[\n  \nOK\n  ]\n\n\n\n\n\n\nA complete set of options available though \nosg-ca-manage\n command, including your interface to adding and removing CAs, could be found at \nosg-ca-manage documentation\n\n\nOption 3: Install an RPM that installs no CAs\n\n\nInstall this with:\n\n\nyum install empty-ca-certs \u2013-enablerepo=osg-empty\n\n\n\n\n\n\n\nWarning\n\n\nIf you choose this option, you are responsible for installing the CA certificates yourself. You must install them in \n/etc/grid-security/certificates\n, or make a symlink from that location to the directory that contains the CA certificates.\n\n\n\n\nOption 4: Make no choice, let yum decide for you\n\n\nIf you use \nyum\n to install software that requires CA certificates but you haven\u2019t made one of these choices, yum will choose a default. Right now, it is Option #1 from above (\nInstall an RPM for a specific set of CA certificates\n), and the osg-ca-certs RPM is chosen.\n\n\nInstall other CAs\n\n\nIn addition to the above CAs, you can install other CAs via RPM. These only work with the RPMs that provide CAs (that is, \nosg-ca-certs\n and the like, but not \nosg-ca-scripts\n.) They are in addition to the above RPMs, so do not only install these extra CAs.\n\n\n\n\n\n\n\n\nSet of CAs\n\n\nFormat\n\n\nRPM name\n\n\nInstallation command (as root)\n\n\n\n\n\n\n\n\n\n\ncilogon-basic \n cilogon-openid\n\n\nOpenSSL-both\n\n\ncilogon-ca-certs\n\n\nyum install cilogon-ca-certs\n\n\n\n\n\n\n\n\nManaging Certificate Revocation Lists\n\n\nIn addition to CA certificates, you normally need to have updated Certificate Revocation Lists (CRLs) which are are lists of certificates that have been revoked for any reason. Software in the OSG Software Stack use these to ensure that you are talking to valid clients or servers. We use a tool named \nfetch-crl\n that periodically updates the CRLs. Fetch CRL is a utility that updates Certificate Authority (CA) Certificate Revocation Lists (CRLs). These are lists of certificates that were granted by the CA, but have since been revoked. It is good practice to regularly update the CRL list for each CA to ensure that you do not authenticate any certificate that has been revoked.\n\n\nfetch-crl\n is installed as two different system services. The fetch-crl-boot service runs only\nat boot time. The \nfetch-crl-cron\n service runs \nfetch-crl\n every 6 hours (with a random sleep\ntime included) by default. Both services are disabled by default. At the very minimum, the\n\nfetch-crl-cron\n service needs to be enabled otherwise services will begin to fail as the\nexisting CRLs expire.\n\n\nInstall \nfetch-crl\n\n\nNormally \nfetch-crl\n is installed when you install the rest of the software and you do not need\nto specifically install it. If you do wish to install it, you can install it as:\n\n\n# For RHEL 5, CentOS 5, and SL5 \n\n\n[root@client ~]$ yum install fetch-crl3\n\n\n# For RHEL 6 or 7, CentOS 6 or 7, and SL6 or SL7 \n\n\n[root@client ~]$ yum install fetch-crl\n\n\n\n\n\n\nEnable and Start \nfetch-crl\n\n\nTo enable fetch-crl (fetch Certificate Revocation Lists) services by default on the node:\n\n\n# For RHEL 5, CentOS 5, and SL5 \n\n\n[root@client ~]$ /sbin/chkconfig fetch-crl3-boot on\n\n\n[root@client ~]$ /sbin/chkconfig fetch-crl3-cron on\n\n\n# For RHEL 6 or 7, CentOS 6 or 7, and SL6 or SL7 \n \n\n\n[root@client ~]$ /sbin/chkconfig fetch-crl-boot on\n\n\n[root@client ~]$ /sbin/chkconfig fetch-crl-cron on\n\n\n\n\n\n\nTo start fetch-crl:\n\n\n# For RHEL 5, CentOS 5, and SL5 \n\n\n[root@client ~]$ /sbin/service fetch-crl3-boot start\n\n\n[root@client ~]$ /sbin/service fetch-crl3-cron start\n\n\n# For RHEL 6 or 7, CentOS 6 or 7, and SL6 or SL7 \n \n\n\n[root@client ~]$ /sbin/service fetch-crl-boot start\n\n\n[root@client ~]$ /sbin/service fetch-crl-cron start\n\n\n\n\n\n\n\n\nNote\n\n\nWhile it is necessary to start \nfetch-crl-cron\n in order to have it active, \nfetch-crl-boot\n is started automatically at boot time if enabled. The start command will run \nfetch-crl-boot\n at the moment when it is invoked and it may take some time to complete.\n\n\n\n\nConfigure \nfetch-crl\n\n\nTo modify the times that fetch-crl-cron runs, edit \n/etc/cron.d/fetch-crl\n (or \n/etc/cron.d/fetch-crl3\n depending on the version you have).\n\n\nBy default, \nfetch-crl\n connects directly to the remote CA; this is\ninefficient and potentially harmful if done simultaneously by many nodes\n(e.g. all the worker nodes of a big cluster). We recommend you provide a\nHTTP proxy (such as \nsquid\n) the worker nodes can utilize; OSG provides\n\npackaging of squid\n.\n\n\nTo configure fetch-crl to use an HTTP proxy server:\n\n\n\n\n\n\nIf using \nfetch-crl\n version 2 (the \nfetch-crl\n package on RHEL5 only), then create the file \n/etc/sysconfig/fetch-crl\n and add the following line:\n\n\nexport http_proxy=\nhttp://your.squid.fqdn:port\n\n\nAdjust the URL appropriately for your proxy server.\n\n\n\n\n\n\nIf using \nfetch-crl\n version 3 on RHEL5 via the \nfetch-crl3\n package\n    or on RHEL6/RHEL7 via the \nfetch-crl\n package, then create or edit the\n    file \n/etc/fetch-crl3.conf\n (RHEL5) or \n/etc/fetch-crl.conf\n\n    (RHEL6/RHEL7) and add the following line:\n\n\nhttp_proxy=\nhttp://your.squid.fqdn:port\n\n\nAgain, adjust the URL appropriately for your proxy server.\n\n\n\n\n\n\nNote that the \nnosymlinks\n option in the configuration files refers\nto ignoring links within the certificates directory (e.g. two different\nnames for the same file). It is perfectly fine if the path of the CA\ncertificates directory itself (\ninfodir\n) is a link to a directory.\n\n\nAny modifications to the configuration file will be preserved during an RPM update.\n\n\nCurrent versions of \nfetch-crl\n and \nfetch-crl3\n produce more output.\nIt is possible to send the output to syslog instead of the default email system. To do so:\n\n\n\n\n\n\nChange the configuration file to enable syslog:\n\n\nlogmode = syslog\n  syslogfacility = daemon\\\n/pre\\\n\n\n\n\n\n\nMake sure the file \n/var/log/daemon\n exists, e.g. touching the file\n\n\n\n\nChange \n/etc/logrotate.d\n files to rotate it\n\n\n\n\nStart/Stop fetch-crl: A quick guide\n\n\nYou need to fetch the latest CA Certificate Revocation Lists (CRLs) and you should enable the fetch-crl service to keep the CRLs up to date:\n\n\n# For RHEL 5, CentOS 5, and SL5 \n\n\n[root@client ~]$ /usr/sbin/fetch-crl3 # This fetches the CRLs\n\n\n[root@client ~]$ /sbin/service fetch-crl3-boot start\n\n\n[root@client ~]$ /sbin/service fetch-crl3-cron start\n\n\n# For RHEL 6 or 7, CentOS 6 or 7, and SL6 or SL7\n\n\n[root@client ~]$ /usr/sbin/fetch-crl # This fetches the CRLs\n\n\n[root@client ~]$ /sbin/service fetch-crl-boot start\n\n\n[root@client ~]$ /sbin/service fetch-crl-cron start\n\n\n\n\n\n\nTo enable the \nfetch-crl\n service to keep the CRLs up to date after reboots:\n\n\n# For RHEL 5, CentOS 5, and SL5 \n\n\n[root@client ~]$ /sbin/chkconfig fetch-crl3-boot on\n\n\n[root@client ~]$ /sbin/chkconfig fetch-crl3-cron on\n\n\n# For RHEL 6 or 7, CentOS 6 or 7, and SL6 or SL7 \n\n\n[root@client ~]$ /sbin/chkconfig fetch-crl-boot on\n\n\n[root@client ~]$ /sbin/chkconfig fetch-crl-cron on\n\n\n\n\n\n\nTo stop \nfetch-crl\n:\n\n\n# For RHEL 5, CentOS 5, and SL5 \n\n\n[root@client ~]$ /sbin/service fetch-crl3-boot stop\n\n\n[root@client ~]$ /sbin/service fetch-crl3-cron stop\n\n\n# For RHEL 6 or 7, CentOS 6 or 7, and SL6 or SL7 \n\n\n[root@client ~]$ /sbin/service fetch-crl-boot stop\n\n\n[root@client ~]$ /sbin/service fetch-crl-cron stop\n\n\n\n\n\n\nTo disable the fetch-crl service:\n\n\n# For RHEL 5, CentOS 5, and SL5 \n\n\n[root@client ~]$ /sbin/chkconfig fetch-crl3-boot off\n\n\n[root@client ~]$ /sbin/chkconfig fetch-crl3-cron off\n\n\n# For RHEL 6 or 7, CentOS 6 or 7, and SL6 or SL7 \n\n\n[root@client ~]$ /sbin/chkconfig fetch-crl-boot off\n\n\n[root@client ~]$ /sbin/chkconfig fetch-crl-cron off\n\n\n\n\n\n\nUpdating CAs/CRLs\n\n\nWhy maintain up-to-date Trusted CA /CRL information\n\n\nThe Trusted Certificate Authority (CA) certificates, and their associated Certificate Revocation Lists (CRLs), are used for every transaction on a resource that establishes an authenticated network connection based on end user\u2019s certificate. In order for the authentication to succeed, the user\u2019s certificate must have been issued by one of the CAs in the Trusted CA directory, and the user\u2019s certificate must not be listed in the CRL for that CA. CRLs can be thought of as a black list of certificates. CAs are the trust authorities, similar to DMV that issues you the driving license. (Another way of thinking CRLs is the do-not-fly lists at the airports. if your certificate shows up in CRLs, you are not allowed access.) This is handled at the certificate validation stage even before the authorization check (which will provide the mapping of an authenticated user to a local account UID/GID). So you do not need to do worry about it; the grid software will do this for you. However, you should make sure that your site has the most up-to-date list of Trusted CAs. There are multiple trust authorities in OSG (think of it as a different DMV for each state). If you do not have an up-to-date list of CAs it is possible that some of your users transactions at your site will start to fail. A current CRL list for each CA is also necessary, since without one transactions for users of that CA will fail.\n\n\nHow to ensure you are get up-to-date CA/CRL information\n\n\n\n\nIf you installed CAs using rpm packages (\nosg-ca-certs\n,\nigtf-ca-certs\n) (Options 1, 4), you will need to install the software described in \nthe CA update document\n, and enable \nosg-ca-certs-updater\n service to keep the CAs automatically updated. If you do not install the updater, you will have to regularly run yum update to keep the CAs updated.\n\n\nIf you use Option 2 (i.e. \nosg-update-certs\n) then make sure that you have the corresponding service enabled.\n\n\n\n\n[root@client ~]$ /sbin/service osg-update-certs-cron  status\n   Periodic osg-update-certs is enabled.\n\n\n\n\nEnsure that fetch-crl cron is enabled\\\n\n\n\n\n[root@client ~]$ /sbin/service fetch-crl-cron  status\n  Periodic fetch-crl is enabled.\n\n\nTroubleshooting\n\n\nUseful configuration and log files\n\n\nConfiguration files:\n\n\n\n\n\n\n\n\nPackage\n\n\nFile Description\n\n\nLocation\n\n\nComment\n\n\n\n\n\n\n\n\n\n\nAll CA Packages\n\n\nCA File Location\n\n\n/etc/grid-security/certificates\n\n\n\n\n\n\n\n\nAll CA Packages\n\n\nIndex files\n\n\n/etc/grid-security/certificates/INDEX.html\n or \n/etc/grid-security/certificates/INDEX.txt\n\n\nLatest version also available at \nhttp://software.grid.iu.edu/pacman/cadist/\n\n\n\n\n\n\nAll CA Packages\n\n\nChange Log\n\n\n/etc/grid-security/certificates/CHANGES\n\n\nLatest version also available at \nhttp://software.grid.iu.edu/pacman/cadist/CHANGES\n\n\n\n\n\n\nosg-ca-certs or igtf-ca-certs\n\n\ncontain only CA files\n\n\n\n\n\n\n\n\n\n\nosg-ca-scripts\n\n\nConfiguration File for osg-update-certs\n\n\n/etc/osg/osg-update-certs.conf\n\n\nThis file may be edited by hand, though it is recommended to use osg-ca-manage to set configuration parameters.\n\n\n\n\n\n\nfetch-crl-2.x\n\n\nConfiguration file\n\n\n/etc/fetch-crl.conf\n\n\n\n\n\n\n\n\nfetch-crl-3.x\n\n\nConfiguration file\n\n\n/etc/fetch-crl3.conf\n\n\n\n\n\n\n\n\n\n\nThe index and change log files contain a summary of all the CA distributed and their version.\n\n\nLogs files:\n\n\n\n\n\n\n\n\nPackage\n\n\nFile Description\n\n\nLocation\n\n\n\n\n\n\n\n\n\n\nosg-ca-scripts\n\n\nLog file of osg-update-certs\n\n\n/var/log/osg-update-certs.log\n\n\n\n\n\n\nosg-ca-scripts\n\n\nStdout of osg-update-certs\n\n\n/var/log/osg-ca-certs-status.system.out\n\n\n\n\n\n\nosg-ca-scripts\n\n\nStdout of osg-ca-manage\n\n\n/var/log/osg-ca-manage.system.out\n\n\n\n\n\n\nosg-ca-scripts\n\n\nStdout of initial CA setup\n\n\n/var/log/osg-setup-ca-certificates.system.out\n\n\n\n\n\n\n\n\nTests\n\n\nTo test the host certificate of a server \nopenssl s_client\n can be used. Here is an example with the gatekeeper:\n\n\nUCL_PROMPT\n openssl s_client -showcerts -cert /etc/grid-security/hostcert.pem -key /etc/grid-security/hostkey.pem -CApath /etc/grid-security/certificates/ -debug -connect osg-gk.mwt2.org:2119\n\n\n\n\n\n\nFrequently Asked Questions\n\n\nLocation of Certificates?\n\n\n /etc/grid-security/certificates \n\n\n\n\n\nWhat is the version of OSG CA package I have installed and what are its contents?\n\n\nThe version of the CA package ca be found at \n/etc/grid-security/certificates/INDEX.html\n or \n/etc/grid-security/certificates/INDEX.txt\n. The changes file can be found at \n/etc/grid-security/certificates/CHANGES\n.\n\n\nContents of OSG CA package?\n\n\nThe OSG CA Distribution contains:\n\n\n\n\nIGTF Distribution of Authority Root Certificates\n (CAs accredited by the \nInternational Grid Trust Federation\n)\n\n\nPurdue TeraGrid CA\n\n\n\n\nDetails of CAs in OSG distribution can be found \nhere\n. For additional details what is in the current release, see the \ndistribution site\n and \nchange log\n.\n\n\nHow can I add or remove a particular CA file?\n\n\nAdd and remove of CA files are supported only if you CA files are being installed using \nosg-update-certs\n, which is included in the \nosg-ca-scripts\n package (option 2), for all other options no support for adding and removing a particular CA file is provided by OSG. The preferred approach to add or remove a CA is to use \nosg-ca-manage\n. For adding a new CA \nosg-ca-manage add [--dir \nlocal_dir\n] --hash \nCA_hash\n may be used, while a CA is removed using \nosg-ca-manage remove --hash \nCA_hash\n.\n\n\nAre there any log files or configuration files associated with CA certificate package?\n\n\nIf CA files are installed using \nosg-ca-certs\n or \nigtf-ca-certs\n rpms (i.e. options 1, 4) no log or configuration files are present.\n\n\nLog and configuration files are however present for \nosg-ca-scripts\n rpm package (option 2).\n\n\nConfig files: \n/etc/osg/osg-update-certs.conf\n Log files: \n/var/log/osg-update-certs.log\n, \n/var/log/osg-ca-certs-status.system.out\n, \n/var/log/osg-ca-manage.system.out\n, \n/var/log/osg-setup-ca-certificates.system.out\n\n\nAre CA packages automatically updated?\n\n\nIf CA files are installed using \nosg-ca-certs\n or \nigtf-ca-certs\n rpms (i.e. options 1, 4), you will need to install the software described in OsgCaCertsUpdater, and enable osg-ca-certs-updater service to keep the CAs automatically updated.\n\n\nIf CA files are being installed using \nosg-ca-scripts\n rpm package (option 2), CA files are kept up-to-date as long as \nosg-update-certs-cron\n service the package provides has been started.\n\n\nHow do I manually update my CA package?\n\n\nFor Option 1: run one of the following \nyum update osg-ca-certs\n or \nyum update igtf-ca-certs\n depending on the rpm package you installed.\n\n\nFor Option 4: run \nyum update osg-ca-certs\n\n\nFor Option 2: You do not need to do a manual update, make sure \nosg-update-certs-cron\n is enabled using\n\n\n[root@client ~]$ /sbin/service osg-update-certs-cron  status\n\n\n\n\n\n\nIf the service is disabled, enable it using\n\n\n[root@client ~]$ /sbin/service osg-update-certs-cron  start\n\n\n\n\n\n\nIf for some extraordinary reason you need to manually update the CA you could run \nosg-ca-manage [--force] refreshCA\n.\n\n\nWhere are the configuration files for fetch-crl?\n\n\n/etc/fetch-crl.conf\n or \n/etc/fetch-crl3.conf\n for fetch-crl 2.x or 3.x respectively\n\n\nReferences\n\n\nSome guides on x509 certificates:\n\n\n\n\nUseful commands: \nhttp://security.ncsa.illinois.edu/research/grid-howtos/usefulopenssl.html\n\n\nInstall GSI authentication on a server: \nhttp://security.ncsa.illinois.edu/research/wssec/gsihttps/\n\n\nCertificates how-to: \nhttp://www.nordugrid.org/documents/certificate_howto.html\n\n\n\n\nSome examples about verifying the certificates:\n\n\n\n\nhttp://gagravarr.org/writing/openssl-certs/others.shtml\n\n\nhttp://www.cyberciti.biz/faq/test-ssl-certificates-diagnosis-ssl-certificate/\n\n\nhttp://www.cyberciti.biz/tips/debugging-ssl-communications-from-unix-shell-prompt.html\n\n\n\n\nRelated software:\n\n\n\n\nDescription, manual and examples of OsgCaManage\n\n\nOsgCaCertsUpdater\n\n\nUpgrading Fetch-Crl 2 to Fetch-Crl 3 on EL5", 
            "title": "CA Certificates"
        }, 
        {
            "location": "/common/ca/#installing-certificate-authorities-certificates-and-related-rpms", 
            "text": "This document provides you with details of various options to install the Certificate Authority (CA) certificates and have up-to-date certificate revocation list (CRL).  When installing software with RPMs, you need to decide how you want to install the Certificate Authority (CA) certificates. You might ask \"why do I care? Can\u2019t you just give them to me?\" We can, but you have a few things to consider:   What set of CA certificates do you want? How much control do you want over the set of CA certificates? (Some sites might not want to install specific CAs for policy or security reasons.)  How do you want to update them?  Do you want to centrally manage the CA certificates or install them on each computer at your site?   You have four options for installing CA certificates:   Install an RPM for a specific set of CA certificates.  Install  osg-update-certs , a program that lets you install/update a predefined set of CA certificates, then adjust the set by adding or deleting specific CAs.  Install an RPM that installs  no  CAs. This is useful when you want your RPM installations to succeed (because our RPMs require CA certificates, and this RPM satisfies that dependency) but you want to manage them with your own technique.  Make no choice, let  yum  decide for you.   Additionally this page also provides instruction on installation of a tool (fetch-crl) to ensure your site has up-to-date certificate revocation list (CRL) from the CA.  Prior to following the instructions on this page, you must enable our  yum repositories", 
            "title": "Installing Certificate Authorities Certificates and related RPMs"
        }, 
        {
            "location": "/common/ca/#install-ca-certificates-options", 
            "text": "Please choose one of the four options to install the CA certificates.", 
            "title": "Install CA certificates: Options"
        }, 
        {
            "location": "/common/ca/#option-1-install-an-rpm-for-a-specific-set-of-ca-certificates", 
            "text": "If you want to install an RPM for one of our predefined CA certificates, you have two choices to make:", 
            "title": "Option 1: Install an RPM for a specific set of CA certificates"
        }, 
        {
            "location": "/common/ca/#which-set-of-cas", 
            "text": "( recommended ) The OSG CA certificates. This is similar to the IGTF set, but may have a small number of additions or deletions. (See  here  for details)  The default  IGTF  CA certificates.   Depending on your choice, you select one of two RPMs:     Set of CAs  Format  --  RPM name  Installation command (as root)      OSG  OpenSSL-both  osg-ca-certs  yum install osg-ca-certs    IGTF  OpenSSL-both  igtf-ca-certs  yum install igtf-ca-certs", 
            "title": "Which set of CAs?"
        }, 
        {
            "location": "/common/ca/#how-do-i-keep-cas-updated", 
            "text": "Please follow the  update instructions  to make sure that the CAs are kept updated.", 
            "title": "How do I keep CAs updated?"
        }, 
        {
            "location": "/common/ca/#option-2-install-osg-update-certs", 
            "text": "Install this with:  [root@client ~]$ yum install osg-ca-scripts   You have the same choices for CA certificates as above. In order to choose, you will run  osg-ca-manage , which will install the CA certificates. Then (if desired) you need to enable periodic updating of the CA certificates.     Set of CAs  Format  CA certs name  Installation command (as root)      OSG  OpenSSL-both  osg  /usr/sbin/osg-ca-manage setupCA --location root --url osg    IGTF  OpenSSL-both  igtf  /usr/sbin/osg-ca-manage setupCA --location root --url igtf     Here is an example:  [root@client ~]$ /usr/sbin/osg-ca-manage setupCA --location root --url osg   Setting   up   CA   Certificates   for   OSG   installation  CA   Certificates   will   be   installed   into   / etc / grid - security / certificates  osg - update - certs \n   Log   file :   / var / log / osg - update - certs . log \n   Updates   from :   http : // software . grid . iu . edu / pacman / cadist / ca - certs - version - new  Will   update   CA   certificates   from   version   unknown   to   version   1.21 NEW .  Update   successful .  Setup   completed   successfully .   Initially the CA certificates will not be updated. You can tell by looking at:  [root@client ~]$ /sbin/service osg-update-certs-cron  status  Periodic   osg - update - certs   is   disabled .   You can enable the  cron  job that updates the CA certs with:  [root@client ~]$ /sbin/service osg-update-certs-cron  start  Enabling   periodic   osg - update - certs :                          [    OK   ]   A complete set of options available though  osg-ca-manage  command, including your interface to adding and removing CAs, could be found at  osg-ca-manage documentation", 
            "title": "Option 2: Install osg-update-certs"
        }, 
        {
            "location": "/common/ca/#option-3-install-an-rpm-that-installs-no-cas", 
            "text": "Install this with:  yum install empty-ca-certs \u2013-enablerepo=osg-empty   Warning  If you choose this option, you are responsible for installing the CA certificates yourself. You must install them in  /etc/grid-security/certificates , or make a symlink from that location to the directory that contains the CA certificates.", 
            "title": "Option 3: Install an RPM that installs no CAs"
        }, 
        {
            "location": "/common/ca/#option-4-make-no-choice-let-yum-decide-for-you", 
            "text": "If you use  yum  to install software that requires CA certificates but you haven\u2019t made one of these choices, yum will choose a default. Right now, it is Option #1 from above ( Install an RPM for a specific set of CA certificates ), and the osg-ca-certs RPM is chosen.", 
            "title": "Option 4: Make no choice, let yum decide for you"
        }, 
        {
            "location": "/common/ca/#install-other-cas", 
            "text": "In addition to the above CAs, you can install other CAs via RPM. These only work with the RPMs that provide CAs (that is,  osg-ca-certs  and the like, but not  osg-ca-scripts .) They are in addition to the above RPMs, so do not only install these extra CAs.     Set of CAs  Format  RPM name  Installation command (as root)      cilogon-basic   cilogon-openid  OpenSSL-both  cilogon-ca-certs  yum install cilogon-ca-certs", 
            "title": "Install other CAs"
        }, 
        {
            "location": "/common/ca/#managing-certificate-revocation-lists", 
            "text": "In addition to CA certificates, you normally need to have updated Certificate Revocation Lists (CRLs) which are are lists of certificates that have been revoked for any reason. Software in the OSG Software Stack use these to ensure that you are talking to valid clients or servers. We use a tool named  fetch-crl  that periodically updates the CRLs. Fetch CRL is a utility that updates Certificate Authority (CA) Certificate Revocation Lists (CRLs). These are lists of certificates that were granted by the CA, but have since been revoked. It is good practice to regularly update the CRL list for each CA to ensure that you do not authenticate any certificate that has been revoked.  fetch-crl  is installed as two different system services. The fetch-crl-boot service runs only\nat boot time. The  fetch-crl-cron  service runs  fetch-crl  every 6 hours (with a random sleep\ntime included) by default. Both services are disabled by default. At the very minimum, the fetch-crl-cron  service needs to be enabled otherwise services will begin to fail as the\nexisting CRLs expire.", 
            "title": "Managing Certificate Revocation Lists"
        }, 
        {
            "location": "/common/ca/#install-fetch-crl", 
            "text": "Normally  fetch-crl  is installed when you install the rest of the software and you do not need\nto specifically install it. If you do wish to install it, you can install it as:  # For RHEL 5, CentOS 5, and SL5   [root@client ~]$ yum install fetch-crl3  # For RHEL 6 or 7, CentOS 6 or 7, and SL6 or SL7   [root@client ~]$ yum install fetch-crl", 
            "title": "Install fetch-crl"
        }, 
        {
            "location": "/common/ca/#enable-and-start-fetch-crl", 
            "text": "To enable fetch-crl (fetch Certificate Revocation Lists) services by default on the node:  # For RHEL 5, CentOS 5, and SL5   [root@client ~]$ /sbin/chkconfig fetch-crl3-boot on  [root@client ~]$ /sbin/chkconfig fetch-crl3-cron on  # For RHEL 6 or 7, CentOS 6 or 7, and SL6 or SL7     [root@client ~]$ /sbin/chkconfig fetch-crl-boot on  [root@client ~]$ /sbin/chkconfig fetch-crl-cron on   To start fetch-crl:  # For RHEL 5, CentOS 5, and SL5   [root@client ~]$ /sbin/service fetch-crl3-boot start  [root@client ~]$ /sbin/service fetch-crl3-cron start  # For RHEL 6 or 7, CentOS 6 or 7, and SL6 or SL7     [root@client ~]$ /sbin/service fetch-crl-boot start  [root@client ~]$ /sbin/service fetch-crl-cron start    Note  While it is necessary to start  fetch-crl-cron  in order to have it active,  fetch-crl-boot  is started automatically at boot time if enabled. The start command will run  fetch-crl-boot  at the moment when it is invoked and it may take some time to complete.", 
            "title": "Enable and Start fetch-crl"
        }, 
        {
            "location": "/common/ca/#configure-fetch-crl", 
            "text": "To modify the times that fetch-crl-cron runs, edit  /etc/cron.d/fetch-crl  (or  /etc/cron.d/fetch-crl3  depending on the version you have).  By default,  fetch-crl  connects directly to the remote CA; this is\ninefficient and potentially harmful if done simultaneously by many nodes\n(e.g. all the worker nodes of a big cluster). We recommend you provide a\nHTTP proxy (such as  squid ) the worker nodes can utilize; OSG provides packaging of squid .  To configure fetch-crl to use an HTTP proxy server:    If using  fetch-crl  version 2 (the  fetch-crl  package on RHEL5 only), then create the file  /etc/sysconfig/fetch-crl  and add the following line:  export http_proxy= http://your.squid.fqdn:port  Adjust the URL appropriately for your proxy server.    If using  fetch-crl  version 3 on RHEL5 via the  fetch-crl3  package\n    or on RHEL6/RHEL7 via the  fetch-crl  package, then create or edit the\n    file  /etc/fetch-crl3.conf  (RHEL5) or  /etc/fetch-crl.conf \n    (RHEL6/RHEL7) and add the following line:  http_proxy= http://your.squid.fqdn:port  Again, adjust the URL appropriately for your proxy server.    Note that the  nosymlinks  option in the configuration files refers\nto ignoring links within the certificates directory (e.g. two different\nnames for the same file). It is perfectly fine if the path of the CA\ncertificates directory itself ( infodir ) is a link to a directory.  Any modifications to the configuration file will be preserved during an RPM update.  Current versions of  fetch-crl  and  fetch-crl3  produce more output.\nIt is possible to send the output to syslog instead of the default email system. To do so:    Change the configuration file to enable syslog:  logmode = syslog\n  syslogfacility = daemon\\ /pre\\    Make sure the file  /var/log/daemon  exists, e.g. touching the file   Change  /etc/logrotate.d  files to rotate it", 
            "title": "Configure fetch-crl"
        }, 
        {
            "location": "/common/ca/#startstop-fetch-crl-a-quick-guide", 
            "text": "You need to fetch the latest CA Certificate Revocation Lists (CRLs) and you should enable the fetch-crl service to keep the CRLs up to date:  # For RHEL 5, CentOS 5, and SL5   [root@client ~]$ /usr/sbin/fetch-crl3 # This fetches the CRLs  [root@client ~]$ /sbin/service fetch-crl3-boot start  [root@client ~]$ /sbin/service fetch-crl3-cron start  # For RHEL 6 or 7, CentOS 6 or 7, and SL6 or SL7  [root@client ~]$ /usr/sbin/fetch-crl # This fetches the CRLs  [root@client ~]$ /sbin/service fetch-crl-boot start  [root@client ~]$ /sbin/service fetch-crl-cron start   To enable the  fetch-crl  service to keep the CRLs up to date after reboots:  # For RHEL 5, CentOS 5, and SL5   [root@client ~]$ /sbin/chkconfig fetch-crl3-boot on  [root@client ~]$ /sbin/chkconfig fetch-crl3-cron on  # For RHEL 6 or 7, CentOS 6 or 7, and SL6 or SL7   [root@client ~]$ /sbin/chkconfig fetch-crl-boot on  [root@client ~]$ /sbin/chkconfig fetch-crl-cron on   To stop  fetch-crl :  # For RHEL 5, CentOS 5, and SL5   [root@client ~]$ /sbin/service fetch-crl3-boot stop  [root@client ~]$ /sbin/service fetch-crl3-cron stop  # For RHEL 6 or 7, CentOS 6 or 7, and SL6 or SL7   [root@client ~]$ /sbin/service fetch-crl-boot stop  [root@client ~]$ /sbin/service fetch-crl-cron stop   To disable the fetch-crl service:  # For RHEL 5, CentOS 5, and SL5   [root@client ~]$ /sbin/chkconfig fetch-crl3-boot off  [root@client ~]$ /sbin/chkconfig fetch-crl3-cron off  # For RHEL 6 or 7, CentOS 6 or 7, and SL6 or SL7   [root@client ~]$ /sbin/chkconfig fetch-crl-boot off  [root@client ~]$ /sbin/chkconfig fetch-crl-cron off", 
            "title": "Start/Stop fetch-crl: A quick guide"
        }, 
        {
            "location": "/common/ca/#updating-cascrls", 
            "text": "", 
            "title": "Updating CAs/CRLs"
        }, 
        {
            "location": "/common/ca/#why-maintain-up-to-date-trusted-ca-crl-information", 
            "text": "The Trusted Certificate Authority (CA) certificates, and their associated Certificate Revocation Lists (CRLs), are used for every transaction on a resource that establishes an authenticated network connection based on end user\u2019s certificate. In order for the authentication to succeed, the user\u2019s certificate must have been issued by one of the CAs in the Trusted CA directory, and the user\u2019s certificate must not be listed in the CRL for that CA. CRLs can be thought of as a black list of certificates. CAs are the trust authorities, similar to DMV that issues you the driving license. (Another way of thinking CRLs is the do-not-fly lists at the airports. if your certificate shows up in CRLs, you are not allowed access.) This is handled at the certificate validation stage even before the authorization check (which will provide the mapping of an authenticated user to a local account UID/GID). So you do not need to do worry about it; the grid software will do this for you. However, you should make sure that your site has the most up-to-date list of Trusted CAs. There are multiple trust authorities in OSG (think of it as a different DMV for each state). If you do not have an up-to-date list of CAs it is possible that some of your users transactions at your site will start to fail. A current CRL list for each CA is also necessary, since without one transactions for users of that CA will fail.", 
            "title": "Why maintain up-to-date Trusted CA /CRL information"
        }, 
        {
            "location": "/common/ca/#how-to-ensure-you-are-get-up-to-date-cacrl-information", 
            "text": "If you installed CAs using rpm packages ( osg-ca-certs , igtf-ca-certs ) (Options 1, 4), you will need to install the software described in  the CA update document , and enable  osg-ca-certs-updater  service to keep the CAs automatically updated. If you do not install the updater, you will have to regularly run yum update to keep the CAs updated.  If you use Option 2 (i.e.  osg-update-certs ) then make sure that you have the corresponding service enabled.   [root@client ~]$ /sbin/service osg-update-certs-cron  status\n   Periodic osg-update-certs is enabled.   Ensure that fetch-crl cron is enabled\\   [root@client ~]$ /sbin/service fetch-crl-cron  status\n  Periodic fetch-crl is enabled.", 
            "title": "How to ensure you are get up-to-date CA/CRL information"
        }, 
        {
            "location": "/common/ca/#troubleshooting", 
            "text": "", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/common/ca/#useful-configuration-and-log-files", 
            "text": "Configuration files:     Package  File Description  Location  Comment      All CA Packages  CA File Location  /etc/grid-security/certificates     All CA Packages  Index files  /etc/grid-security/certificates/INDEX.html  or  /etc/grid-security/certificates/INDEX.txt  Latest version also available at  http://software.grid.iu.edu/pacman/cadist/    All CA Packages  Change Log  /etc/grid-security/certificates/CHANGES  Latest version also available at  http://software.grid.iu.edu/pacman/cadist/CHANGES    osg-ca-certs or igtf-ca-certs  contain only CA files      osg-ca-scripts  Configuration File for osg-update-certs  /etc/osg/osg-update-certs.conf  This file may be edited by hand, though it is recommended to use osg-ca-manage to set configuration parameters.    fetch-crl-2.x  Configuration file  /etc/fetch-crl.conf     fetch-crl-3.x  Configuration file  /etc/fetch-crl3.conf      The index and change log files contain a summary of all the CA distributed and their version.  Logs files:     Package  File Description  Location      osg-ca-scripts  Log file of osg-update-certs  /var/log/osg-update-certs.log    osg-ca-scripts  Stdout of osg-update-certs  /var/log/osg-ca-certs-status.system.out    osg-ca-scripts  Stdout of osg-ca-manage  /var/log/osg-ca-manage.system.out    osg-ca-scripts  Stdout of initial CA setup  /var/log/osg-setup-ca-certificates.system.out", 
            "title": "Useful configuration and log files"
        }, 
        {
            "location": "/common/ca/#tests", 
            "text": "To test the host certificate of a server  openssl s_client  can be used. Here is an example with the gatekeeper:  UCL_PROMPT  openssl s_client -showcerts -cert /etc/grid-security/hostcert.pem -key /etc/grid-security/hostkey.pem -CApath /etc/grid-security/certificates/ -debug -connect osg-gk.mwt2.org:2119", 
            "title": "Tests"
        }, 
        {
            "location": "/common/ca/#frequently-asked-questions", 
            "text": "", 
            "title": "Frequently Asked Questions"
        }, 
        {
            "location": "/common/ca/#location-of-certificates", 
            "text": "/etc/grid-security/certificates", 
            "title": "Location of Certificates?"
        }, 
        {
            "location": "/common/ca/#what-is-the-version-of-osg-ca-package-i-have-installed-and-what-are-its-contents", 
            "text": "The version of the CA package ca be found at  /etc/grid-security/certificates/INDEX.html  or  /etc/grid-security/certificates/INDEX.txt . The changes file can be found at  /etc/grid-security/certificates/CHANGES .", 
            "title": "What is the version of OSG CA package I have installed and what are its contents?"
        }, 
        {
            "location": "/common/ca/#contents-of-osg-ca-package", 
            "text": "The OSG CA Distribution contains:   IGTF Distribution of Authority Root Certificates  (CAs accredited by the  International Grid Trust Federation )  Purdue TeraGrid CA   Details of CAs in OSG distribution can be found  here . For additional details what is in the current release, see the  distribution site  and  change log .", 
            "title": "Contents of OSG CA package?"
        }, 
        {
            "location": "/common/ca/#how-can-i-add-or-remove-a-particular-ca-file", 
            "text": "Add and remove of CA files are supported only if you CA files are being installed using  osg-update-certs , which is included in the  osg-ca-scripts  package (option 2), for all other options no support for adding and removing a particular CA file is provided by OSG. The preferred approach to add or remove a CA is to use  osg-ca-manage . For adding a new CA  osg-ca-manage add [--dir  local_dir ] --hash  CA_hash  may be used, while a CA is removed using  osg-ca-manage remove --hash  CA_hash .", 
            "title": "How can I add or remove a particular CA file?"
        }, 
        {
            "location": "/common/ca/#are-there-any-log-files-or-configuration-files-associated-with-ca-certificate-package", 
            "text": "If CA files are installed using  osg-ca-certs  or  igtf-ca-certs  rpms (i.e. options 1, 4) no log or configuration files are present.  Log and configuration files are however present for  osg-ca-scripts  rpm package (option 2).  Config files:  /etc/osg/osg-update-certs.conf  Log files:  /var/log/osg-update-certs.log ,  /var/log/osg-ca-certs-status.system.out ,  /var/log/osg-ca-manage.system.out ,  /var/log/osg-setup-ca-certificates.system.out", 
            "title": "Are there any log files or configuration files associated with CA certificate package?"
        }, 
        {
            "location": "/common/ca/#are-ca-packages-automatically-updated", 
            "text": "If CA files are installed using  osg-ca-certs  or  igtf-ca-certs  rpms (i.e. options 1, 4), you will need to install the software described in OsgCaCertsUpdater, and enable osg-ca-certs-updater service to keep the CAs automatically updated.  If CA files are being installed using  osg-ca-scripts  rpm package (option 2), CA files are kept up-to-date as long as  osg-update-certs-cron  service the package provides has been started.", 
            "title": "Are CA packages automatically updated?"
        }, 
        {
            "location": "/common/ca/#how-do-i-manually-update-my-ca-package", 
            "text": "For Option 1: run one of the following  yum update osg-ca-certs  or  yum update igtf-ca-certs  depending on the rpm package you installed.  For Option 4: run  yum update osg-ca-certs  For Option 2: You do not need to do a manual update, make sure  osg-update-certs-cron  is enabled using  [root@client ~]$ /sbin/service osg-update-certs-cron  status   If the service is disabled, enable it using  [root@client ~]$ /sbin/service osg-update-certs-cron  start   If for some extraordinary reason you need to manually update the CA you could run  osg-ca-manage [--force] refreshCA .", 
            "title": "How do I manually update my CA package?"
        }, 
        {
            "location": "/common/ca/#where-are-the-configuration-files-for-fetch-crl", 
            "text": "/etc/fetch-crl.conf  or  /etc/fetch-crl3.conf  for fetch-crl 2.x or 3.x respectively", 
            "title": "Where are the configuration files for fetch-crl?"
        }, 
        {
            "location": "/common/ca/#references", 
            "text": "Some guides on x509 certificates:   Useful commands:  http://security.ncsa.illinois.edu/research/grid-howtos/usefulopenssl.html  Install GSI authentication on a server:  http://security.ncsa.illinois.edu/research/wssec/gsihttps/  Certificates how-to:  http://www.nordugrid.org/documents/certificate_howto.html   Some examples about verifying the certificates:   http://gagravarr.org/writing/openssl-certs/others.shtml  http://www.cyberciti.biz/faq/test-ssl-certificates-diagnosis-ssl-certificate/  http://www.cyberciti.biz/tips/debugging-ssl-communications-from-unix-shell-prompt.html   Related software:   Description, manual and examples of OsgCaManage  OsgCaCertsUpdater  Upgrading Fetch-Crl 2 to Fetch-Crl 3 on EL5", 
            "title": "References"
        }, 
        {
            "location": "/compute-element/htcondor-ce-overview/", 
            "text": "HTCondor-CE Overview\n\n\nAbout this Document\n\n\nThis document serves as an introduction to HTCondor-CE, how it works, and how it differs from a GRAM CE.\n\n\nDocument Requirements\n\n\nBefore continuing with this document, make sure that you are familiar with the following concepts:\n\n\n\n\nAn OSG site plan\n\n\nWhat is a batch system and which one will you use (\nHTCondor\n, PBS, LSF, SGE, or SLURM)?\n\n\nSecurity in the OSG via \nGSI\n (i.e., \nCertificate authorities\n, user and host \ncertificates\n, proxies)\n\n\n\n\n\n\nPilot jobs, frontends, and factories (i.e., \nGlideinWMS\n, \nAutoPyFactory\n)\n\n\n\n\nWhat is a Compute Element?\n\n\nAn OSG Compute Element (CE) is the entry point for the OSG to your local resources: a layer of software that you install on a machine that can submit jobs into your local batch system. At the heart of the CE is the \njob gateway\n software, which is responsible for handling incoming jobs, authorizing them, and delegating them to your batch system for execution. Historically, the OSG only had one option for a job gateway solution, Globus Toolkit\u2019s GRAM-based gatekeeper, but now offers the HTCondor-CE as an alternative.\n\n\nToday in OSG, most jobs that arrive at a CE (called \ngrid jobs\n) are \nnot\n end-user jobs, but rather pilot jobs submitted from factories. Successful pilot jobs create and make available an environment for actual end-user jobs to match and ultimately run within the pilot job container. Eventually pilot jobs remove themselves, typically after a period of inactivity.\n\n\nWhat is HTCondor-CE?\n\n\nHTCondor-CE is a special configuration of the HTCondor software designed to be a job gateway solution for the OSG. It is configured to use the \nJobRouter daemon\n to delegate jobs by transforming and submitting them to the site\u2019s batch system.\n\n\nHow is HTCondor-CE different from a GRAM CE?\n\n\nThe biggest difference you will see between an HTCondor-CE and a GRAM CE is in the way that jobs are submitted to your batch system; HTCondor-CE uses the built-in JobRouter daemon whereas GRAM CE uses jobmanager scripts written in Perl. Customizing your site\u2019s CE now requires editing configuration files instead of editing jobmanager scripts.\n\n\nListed below are some other benefits to switching to HTCondor-CE:\n\n\n\n\nScalability:\n HTCondor-CE is capable of supporting job workloads of large sites (see \nscale testing results\n)\n\n\nDebugging tools:\n HTCondor-CE offers \nmany tools to help troubleshoot\n issues with jobs\n\n\nRouting as configuration:\n HTCondor-CE\u2019s mechanism to transform and submit jobs is customized via configuration variables, which means that customizations will persist across upgrades and will not involve modification of software internals to route jobs\n\n\n\n\nHow Jobs Run\n\n\nOnce an incoming grid job is authorized, it is placed into HTCondor-CE\u2019s scheduler where the JobRouter creates a transformed copy (called the \nrouted job\n) and submits the copy to the batch system (called the \nbatch system job\n). After submission, HTCondor-CE monitors the batch system job and communicates its status to the original grid job, which in turn notifies the original submitter (e.g., job factory) of any updates. When the job completes, files are transferred along the same chain: from the batch system to the CE, then from the CE to the original submitter.\n\n\nOn HTCondor batch systems\n\n\nFor a site with an HTCondor \nbatch system\n, the JobRouter can use HTCondor protocols to place a transformed copy of the grid job directly into the batch system\u2019s scheduler, meaning that the routed and batch system jobs are one and the same. Thus, there are three representations of your job, each with its own ID (see diagram below):\n\n\n\n\nSubmit host: the HTCondor job ID in the original queue\n\n\nHTCondor-CE: the grid job\u2019s ID\n\n\nHTCondor batch system: the routed job\u2019s ID\n\n\n\n\n\n\nIn an HTCondor-CE/HTCondor setup, files are transferred from HTCondor-CE\u2019s spool directory to the batch system\u2019s spool directory using internal HTCondor protocols.\n\n\n\n\nNote\n\n\nThe JobRouter copies the job directly into the batch system and does not make use of \ncondor_submit\n. This means that if the HTCondor batch system is configured to add attributes to incoming jobs when they are submitted (i.e., \nSUBMIT_EXPRS\n), these attributes will not be added to the routed jobs.\n\n\n\n\nOn other batch systems\n\n\nFor non-HTCondor batch systems, the JobRouter transforms the grid job into a routed job on the CE and the routed job submits a job into the batch system via a process called the BLAHP. Thus, there are four representations of your job, each with its own ID (see diagram below):\n\n\n\n\nSubmit host: the HTCondor job ID in the original queue\n\n\nHTCondor-CE: the grid job\u2019s ID and the routed job\u2019s ID\n\n\nHTCondor batch system: the batch system\u2019s job ID\n\n\n\n\nAlthough the following figure specifies the PBS case, it applies to all non-HTCondor batch systems:\n\n\n\n\nWith non-HTCondor batch systems, HTCondor-CE cannot use internal HTCondor protocols to transfer files so its spool directory must be exported to a shared file system that is mounted on the batch system\u2019s worker nodes.\n\n\nOver SSH\n\n\nHTCondor-CE-Bosco\n is a special configuration of HTCondor-CE that can submit jobs to a remote cluster over SSH. The HTCondor-CE-Bosco provides a simple starting point for opportunistic resource owners that want to start contributing to the OSG with minimal effort: an organization will be able to accept OSG jobs by allowing SSH access to a submit node in their cluster.\n\n\n\n\nHTCondor-CE-Bosco is intended for small sites or as an introduction to the OSG. If your site intends to run thousands of OSG jobs, you will need to host a standard \nHTCondor-CE\n because HTCondor-CE-Bosco has not yet been optimized for such loads.\n\n\nHow the CE is Customized\n\n\nAside from the \nbasic configuration\n required in the CE installation, there are two main ways to customize your CE (if you decide any customization is required at all):\n\n\n\n\nDeciding which VOs are allowed to run at your site:\n The method of limiting the VOs that are allowed to run on your site has not changed between GRAM and HTCondor-CE\u2019s: select an authorization system, GUMS or edg-mkgridmap, and configure it accordingly.\n\n\nHow to filter and transform the grid jobs to be run on your batch system:\n Filtering and transforming grid jobs (i.e., setting site-specific attributes or resource limits), requires configuration of your site\u2019s job routes. For examples of common job routes, consult the \nJobRouter recipes\n page.\n\n\n\n\n\n\nNote\n\n\nIf you are running HTCondor as your batch system, you will have two HTCondor configurations side-by-side (one residing in \n/etc/condor/\n and the other in \n/etc/condor-ce\n) and will need to make sure to differentiate the two when editing any configuration.\n\n\n\n\nHow Security Works\n\n\nIn the OSG, security depends on a PKI infrastructure involving Certificate Authorities (CAs) where CAs sign and issue certifcates to users and hosts. When these users and hosts wish to communicate with each other, the identities of each party is confirmed by cross-checking their certificates with the signing CA and establishing trust.\n\n\nDue to the OSG's distributed nature, a user's job may end up at any number of sites, potentially needing to re-authenticate at multiple points. Instead of sending the user's certificate with the job for this re-authentication, trust can be delegated to a proxy that is generated from the user certificate, which is then attached to the job and expires after some set time for added security.\n\n\nIn its default configuration, HTCondor-CE uses GSI-based authentication and authorization (the same as Globus GRAM) to verify the certificate chain, which will work with existing GUMS servers or grid mapfiles. Additionally, it can be reconfigured to provide alternate authentication mechanisms such as Kerberos, SSL, shared secret, or even IP-based authentication. More information about authorization methods can be found \nhere\n.\n\n\nNext steps\n\n\nIf you're transitioning from a GRAM CE to HTCondor-CE, the process is the same as if you were setting up a completely new CE, whether you're installing it on a new machine or alongside your GRAM CE.\n\n\n\n\nInstall \nHTCondor-CE\n or \nHTCondor-CE-Bosco\n\n\nSetting up \njob routes\n\n\nSubmitting\n jobs to HTCondor-CE\n\n\nTroubleshooting\n HTCondor-CE\n\n\nRegister the CE with OIM\n\n\nRegister with the OSG GlideinWMS factories and/or the ATLAS AutoPyFactory", 
            "title": "Overview"
        }, 
        {
            "location": "/compute-element/htcondor-ce-overview/#htcondor-ce-overview", 
            "text": "", 
            "title": "HTCondor-CE Overview"
        }, 
        {
            "location": "/compute-element/htcondor-ce-overview/#about-this-document", 
            "text": "This document serves as an introduction to HTCondor-CE, how it works, and how it differs from a GRAM CE.", 
            "title": "About this Document"
        }, 
        {
            "location": "/compute-element/htcondor-ce-overview/#document-requirements", 
            "text": "Before continuing with this document, make sure that you are familiar with the following concepts:   An OSG site plan  What is a batch system and which one will you use ( HTCondor , PBS, LSF, SGE, or SLURM)?  Security in the OSG via  GSI  (i.e.,  Certificate authorities , user and host  certificates , proxies)    Pilot jobs, frontends, and factories (i.e.,  GlideinWMS ,  AutoPyFactory )", 
            "title": "Document Requirements"
        }, 
        {
            "location": "/compute-element/htcondor-ce-overview/#what-is-a-compute-element", 
            "text": "An OSG Compute Element (CE) is the entry point for the OSG to your local resources: a layer of software that you install on a machine that can submit jobs into your local batch system. At the heart of the CE is the  job gateway  software, which is responsible for handling incoming jobs, authorizing them, and delegating them to your batch system for execution. Historically, the OSG only had one option for a job gateway solution, Globus Toolkit\u2019s GRAM-based gatekeeper, but now offers the HTCondor-CE as an alternative.  Today in OSG, most jobs that arrive at a CE (called  grid jobs ) are  not  end-user jobs, but rather pilot jobs submitted from factories. Successful pilot jobs create and make available an environment for actual end-user jobs to match and ultimately run within the pilot job container. Eventually pilot jobs remove themselves, typically after a period of inactivity.", 
            "title": "What is a Compute Element?"
        }, 
        {
            "location": "/compute-element/htcondor-ce-overview/#what-is-htcondor-ce", 
            "text": "HTCondor-CE is a special configuration of the HTCondor software designed to be a job gateway solution for the OSG. It is configured to use the  JobRouter daemon  to delegate jobs by transforming and submitting them to the site\u2019s batch system.", 
            "title": "What is HTCondor-CE?"
        }, 
        {
            "location": "/compute-element/htcondor-ce-overview/#how-is-htcondor-ce-different-from-a-gram-ce", 
            "text": "The biggest difference you will see between an HTCondor-CE and a GRAM CE is in the way that jobs are submitted to your batch system; HTCondor-CE uses the built-in JobRouter daemon whereas GRAM CE uses jobmanager scripts written in Perl. Customizing your site\u2019s CE now requires editing configuration files instead of editing jobmanager scripts.  Listed below are some other benefits to switching to HTCondor-CE:   Scalability:  HTCondor-CE is capable of supporting job workloads of large sites (see  scale testing results )  Debugging tools:  HTCondor-CE offers  many tools to help troubleshoot  issues with jobs  Routing as configuration:  HTCondor-CE\u2019s mechanism to transform and submit jobs is customized via configuration variables, which means that customizations will persist across upgrades and will not involve modification of software internals to route jobs", 
            "title": "How is HTCondor-CE different from a GRAM CE?"
        }, 
        {
            "location": "/compute-element/htcondor-ce-overview/#how-jobs-run", 
            "text": "Once an incoming grid job is authorized, it is placed into HTCondor-CE\u2019s scheduler where the JobRouter creates a transformed copy (called the  routed job ) and submits the copy to the batch system (called the  batch system job ). After submission, HTCondor-CE monitors the batch system job and communicates its status to the original grid job, which in turn notifies the original submitter (e.g., job factory) of any updates. When the job completes, files are transferred along the same chain: from the batch system to the CE, then from the CE to the original submitter.", 
            "title": "How Jobs Run"
        }, 
        {
            "location": "/compute-element/htcondor-ce-overview/#on-htcondor-batch-systems", 
            "text": "For a site with an HTCondor  batch system , the JobRouter can use HTCondor protocols to place a transformed copy of the grid job directly into the batch system\u2019s scheduler, meaning that the routed and batch system jobs are one and the same. Thus, there are three representations of your job, each with its own ID (see diagram below):   Submit host: the HTCondor job ID in the original queue  HTCondor-CE: the grid job\u2019s ID  HTCondor batch system: the routed job\u2019s ID    In an HTCondor-CE/HTCondor setup, files are transferred from HTCondor-CE\u2019s spool directory to the batch system\u2019s spool directory using internal HTCondor protocols.   Note  The JobRouter copies the job directly into the batch system and does not make use of  condor_submit . This means that if the HTCondor batch system is configured to add attributes to incoming jobs when they are submitted (i.e.,  SUBMIT_EXPRS ), these attributes will not be added to the routed jobs.", 
            "title": "On HTCondor batch systems"
        }, 
        {
            "location": "/compute-element/htcondor-ce-overview/#on-other-batch-systems", 
            "text": "For non-HTCondor batch systems, the JobRouter transforms the grid job into a routed job on the CE and the routed job submits a job into the batch system via a process called the BLAHP. Thus, there are four representations of your job, each with its own ID (see diagram below):   Submit host: the HTCondor job ID in the original queue  HTCondor-CE: the grid job\u2019s ID and the routed job\u2019s ID  HTCondor batch system: the batch system\u2019s job ID   Although the following figure specifies the PBS case, it applies to all non-HTCondor batch systems:   With non-HTCondor batch systems, HTCondor-CE cannot use internal HTCondor protocols to transfer files so its spool directory must be exported to a shared file system that is mounted on the batch system\u2019s worker nodes.", 
            "title": "On other batch systems"
        }, 
        {
            "location": "/compute-element/htcondor-ce-overview/#over-ssh", 
            "text": "HTCondor-CE-Bosco  is a special configuration of HTCondor-CE that can submit jobs to a remote cluster over SSH. The HTCondor-CE-Bosco provides a simple starting point for opportunistic resource owners that want to start contributing to the OSG with minimal effort: an organization will be able to accept OSG jobs by allowing SSH access to a submit node in their cluster.   HTCondor-CE-Bosco is intended for small sites or as an introduction to the OSG. If your site intends to run thousands of OSG jobs, you will need to host a standard  HTCondor-CE  because HTCondor-CE-Bosco has not yet been optimized for such loads.", 
            "title": "Over SSH"
        }, 
        {
            "location": "/compute-element/htcondor-ce-overview/#how-the-ce-is-customized", 
            "text": "Aside from the  basic configuration  required in the CE installation, there are two main ways to customize your CE (if you decide any customization is required at all):   Deciding which VOs are allowed to run at your site:  The method of limiting the VOs that are allowed to run on your site has not changed between GRAM and HTCondor-CE\u2019s: select an authorization system, GUMS or edg-mkgridmap, and configure it accordingly.  How to filter and transform the grid jobs to be run on your batch system:  Filtering and transforming grid jobs (i.e., setting site-specific attributes or resource limits), requires configuration of your site\u2019s job routes. For examples of common job routes, consult the  JobRouter recipes  page.    Note  If you are running HTCondor as your batch system, you will have two HTCondor configurations side-by-side (one residing in  /etc/condor/  and the other in  /etc/condor-ce ) and will need to make sure to differentiate the two when editing any configuration.", 
            "title": "How the CE is Customized"
        }, 
        {
            "location": "/compute-element/htcondor-ce-overview/#how-security-works", 
            "text": "In the OSG, security depends on a PKI infrastructure involving Certificate Authorities (CAs) where CAs sign and issue certifcates to users and hosts. When these users and hosts wish to communicate with each other, the identities of each party is confirmed by cross-checking their certificates with the signing CA and establishing trust.  Due to the OSG's distributed nature, a user's job may end up at any number of sites, potentially needing to re-authenticate at multiple points. Instead of sending the user's certificate with the job for this re-authentication, trust can be delegated to a proxy that is generated from the user certificate, which is then attached to the job and expires after some set time for added security.  In its default configuration, HTCondor-CE uses GSI-based authentication and authorization (the same as Globus GRAM) to verify the certificate chain, which will work with existing GUMS servers or grid mapfiles. Additionally, it can be reconfigured to provide alternate authentication mechanisms such as Kerberos, SSL, shared secret, or even IP-based authentication. More information about authorization methods can be found  here .", 
            "title": "How Security Works"
        }, 
        {
            "location": "/compute-element/htcondor-ce-overview/#next-steps", 
            "text": "If you're transitioning from a GRAM CE to HTCondor-CE, the process is the same as if you were setting up a completely new CE, whether you're installing it on a new machine or alongside your GRAM CE.   Install  HTCondor-CE  or  HTCondor-CE-Bosco  Setting up  job routes  Submitting  jobs to HTCondor-CE  Troubleshooting  HTCondor-CE  Register the CE with OIM  Register with the OSG GlideinWMS factories and/or the ATLAS AutoPyFactory", 
            "title": "Next steps"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/", 
            "text": "Installing and Maintaining HTCondor-CE\n\n\nAbout This Guide\n\n\nThe \nHTCondor-CE\n software is a \njob gateway\n for an OSG Compute Element (CE). As such, HTCondor-CE is the entry point for jobs coming from the OSG \u2014 it handles authorization and delegation of jobs to your local batch system. In OSG today, most CEs accept \npilot jobs\n from a factory, which in turn are able to accept and run end-user jobs.\n\n\nUse this page to learn how to install, configure, run, test, and troubleshoot HTCondor-CE from the OSG software repositories.\n\n\nBefore Starting\n\n\nBefore starting the installation process, consider the following points (consulting \nthe Reference section below\n as needed):\n\n\n\n\nUser IDs:\n If they do not exist already, the installation will create the Linux users \ncondor\n (UID 4716) and \ngratia\n (UID 42401)\n\n\nService certificate:\n The HTCondor-CE service uses a host certificate at \n/etc/grid-security/hostcert.pem\n and an accompanying key at \n/etc/grid-security/hostkey.pem\n\n\nNetwork ports:\n The pilot factories must be able to contact your HTCondor-CE service on ports 9619 and 9620 for condor versions \n 8.3.2 (TCP)\n\n\nHost choice:\n HTCondor-CE should be installed on a host that already has the ability to submit jobs into your local cluster\n\n\n\n\nAs with all OSG software installations, there are some one-time (per host) steps to prepare in advance:\n\n\n\n\nEnsure the host has \na supported operating system\n\n\nObtain root access to the host\n\n\nPrepare the \nrequired Yum repositories\n\n\nInstall \nCA certificates\n\n\n\n\nInstalling HTCondor-CE\n\n\nAn HTCondor-CE installation consists of the job gateway (i.e., the HTCondor-CE job router) and other support software (e.g., GridFTP, a Gratia probe, authentication software). To simplify installation, OSG provides convenience RPMs that install all required software with a single command.\n\n\n\n\n\n\nClean yum cache:\n\n\n[root@client ~ ] $\n yum clean all --enablerepo\n=\n*\n\n\n\n\n\n\n\n\n\nUpdate software:\n\n\n[root@client ~ ] $\n yum update\n\n\n\n\n\nThis command will update \nall\n packages\n\n\n\n\n\n\nIf your batch system is already installed via non-RPM means and is in the following list, install the appropriate 'empty' RPM. Otherwise, skip to the next step.\n\n\n\n\n\n\n\n\nIf your batch system is\u2026\n\n\nThen run the following command\u2026\n\n\n\n\n\n\n\n\n\n\nHTCondor\n\n\nyum install empty-condor --enablerepo=osg-empty\n\n\n\n\n\n\nPBS\n\n\nyum install empty-torque --enablerepo=osg-empty\n\n\n\n\n\n\nSGE\n\n\nyum install empty-gridengine --enablerepo=osg-empty\n\n\n\n\n\n\nSLURM\n\n\nyum install empty-slurm --enablerepo=osg-empty\n\n\n\n\n\n\n\n\n\n\n\n\nIf your HTCondor batch system is already installed via non-OSG RPM means, add the line below to \n/etc/yum.repos.d/osg.repo\n. Otherwise, skip to the next step.\n\n\nexclude=condor empty-condor\n\n\n\n\n\n\n\n\n\nSelect the appropriate convenience RPM(s):\n\n\n\n\n\n\n\n\nIf your batch system is\u2026\n\n\nThen use the following package(s)\u2026\n\n\n\n\n\n\n\n\n\n\nHTCondor\n\n\nosg-ce-condor\n\n\n\n\n\n\nLSF\n\n\nosg-ce-lsf\n\n\n\n\n\n\nPBS\n\n\nosg-ce-pbs\n\n\n\n\n\n\nSGE\n\n\nosg-ce-sge\n\n\n\n\n\n\nSLURM\n\n\nosg-ce-slurm\n\n\n\n\n\n\n\n\n\n\n\n\nInstall the CE software:\n\n\n[root@client ~] $ yum install *PACKAGE(S)*\n\n\n\n\n\n\n\n\n\nConfiguring HTCondor-CE\n\n\nThere are a few required configuration steps to connect HTCondor-CE with your batch system and authentication method. For more advanced configuration, see the section on \noptional configurations\n.\n\n\nEnabling HTCondor-CE\n\n\nIf you are installing HTCondor-CE on a new host, the default configuration is correct and you can skip this step and continue onto \nConfiguring the batch system\n! However, if you are updating a host that used a Globus GRAM job gateway (aka the Globus gatekeeper), you must disable GRAM and enable the HTCondor job gateway. Edit the gateway configuration file \n/etc/osg/config.d/10-gateway.ini\n so that it reads:\n\n\ngram_gateway_enabled = False\nhtcondor_gateway_enabled = True\n\n\n\n\n\nConfiguring the batch system\n\n\nEnable your batch system by editing the \nenabled\n field in the \n/etc/osg/config.d/20-\nYOUR BATCH SYSTEM\n.ini\n\n\nenabled = \nTrue\n\n\n\n\n\n\nIf you are using HTCondor as your \nlocal batch system\n (i.e., in addition to your HTCondor-CE), skip to the \nconfiguring authentication\n section. For other batch systems (e.g., PBS, LSF, SGE, SLURM), keep reading.\n\n\nBatch systems other than HTCondor\n\n\nNon-HTCondor batch systems require additional configuration to support file transfer to your site's worker nodes.\n\n\nSharing the spool directory\n\n\nTo transfer files between the CE and the batch system, HTCondor-CE requires a shared file system. The current recommendation is to run a dedicated NFS server (whose installation is beyond the scope of this document) on the \nCE host\n. In this setup, HTCondor-CE writes to the local spool directory and the NFS server shares the directory with all of the worker nodes.\n\n\n\n\nNote\n\n\nIf you choose not to host the NFS server on your CE, you will need to turn off root squash so that the HTCondor-CE daemons can write to the spool directory.\n\n\n\n\nBy default, the spool directory is \n/var/lib/condor-ce\n but you can control this by setting \nSPOOL\n in \n/etc/condor-ce/config.d/99-local.conf\n (create this file if it doesn't exist). For example, the following sets the \nSPOOL\n directory to \n/home/condor\n:\n\n\nSPOOL=/home/condor\n\n\n\n\n\n\n\nNote\n\n\nThe shared spool directory must be readable and writeable by the \ncondor\n user for HTCondor-CE to function correctly.\n\n\n\n\nDisable worker node proxy renewal\n\n\nWorker node proxy renewal is not used by HTCondor-CE and leaving it on will cause some jobs to be held. Edit \n/etc/blah.config\n on the HTCondor-CE host and set the following values:\n\n\nblah_disable_wn_proxy_renewal=yes\nblah_delegate_renewed_proxies=no\nblah_disable_limited_proxy=yes\n\n\n\n\n\n\n\nNote\n\n\nThere should be no whitespace around the \n=\n.\n\n\n\n\nConfiguring authentication\n\n\nIn OSG 3.3, there are three methods to manage authentication for incoming jobs: the \nLCMAPS VOMS plugin\n, \nedg-mkgridmap\n and \nGUMS\n. edg-mkgridmap is easy to set up and maintain, and GUMS has more features and capabilities. The LCMAPS VOMS plugin is the new OSG-preferred authentication, offering the simplicity of edg-mkgridmap and many of GUMS' rich feature set. If you need to support \npool accounts\n, GUMS is the only software with that capability.\n\n\nIn OSG 3.4, the LCMAPS VOMS plugin is the only available authentication solution.\n\n\nAuthentication with the LCMAPS VOMS plugin\n\n\nTo configure your CE to use the LCMAPS VOMS plugin:\n\n\n\n\n\n\nIf you are using OSG 3.3, add the following line to \n/etc/sysconfig/condor-ce\n:\n\n\nexport LLGT_VOMS_ENABLE_CREDENTIAL_CHECK=1\n\n\n\n\n\n\n\n\n\nFollow the instructions in \nthe LCMAPS VOMS plugin installation and configuration document\n to prepare the LCMAPS VOMS plugin\n\n\n\n\n\n\n\n\nNote\n\n\nIf your local batch system is HTCondor, it will attempt to utilize the LCMAPS callouts if enabled in the \ncondor_mapfile\n. If this is not the desired behavior, set \nGSI_AUTHZ_CONF=/dev/null\n in the local HTCondor configuration.\n\n\n\n\nAuthentication with edg-mkgridmap\n\n\n\n\nWarning\n\n\nedg-mkgridmap is unavailable in OSG 3.4\n\n\n\n\nTo configure your CE to use edg-mkgridmap:\n\n\n\n\nFollow the configuration instructions in \nthe edg-mkgridmap document\n to define the VOs that your site accepts\n\n\nSet some critical gridmap attributes by editing the \n/etc/osg/config.d/10-misc.ini\n file on the HTCondor-CE host:\nauthorization_method = gridmap\n\n\n\n\n\n\n\n\n\nAuthentication with GUMS\n\n\n\n\nWarning\n\n\nGUMS is unavailable in OSG 3.4\n\n\n\n\n\n\nFollow the instructions in \nthe GUMS installation and configuration document\n to prepare GUMS\n\n\nSet some critical GUMS attributes by editing the \n/etc/osg/config.d/10-misc.ini\n file on the HTCondor-CE host:\nauthorization_method = xacml\ngums_host = \nYOUR GUMS HOSTNAME\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nIf your local batch system is HTCondor, it will attempt to utilize the LCMAPS callouts if enabled in the \ncondor_mapfile\n. If this is not the desired behavior, set \nGSI_AUTHZ_CONF=/dev/null\n in the local HTCondor configuration.\n\n\n\n\nConfiguring CE collector advertising\n\n\nTo split jobs between the various sites of the OSG, information about each site's capabilities are uploaded to a central collector. The job factories then query the central collector for idle resources and submit pilot jobs to the available sites. To advertise your site, you will need to enter some information about the worker nodes of your clusters.\n\n\nPlease see the \nSubcluster / Resource Entry configuration document\n about configuring the data that will be uploaded to the central collector.\n\n\nApplying configuration settings\n\n\nMaking changes to the OSG configuration files in the \n/etc/osg/config.d\n directory does not apply those settings to software automatically. Settings that are made outside of the OSG directory take effect immediately or at least when the relevant service is restarted. For the OSG settings, use the \nosg-configure\n tool to validate (to a limited extent) and apply the settings to the relevant software components. The \nosg-configure\n software is included automatically in an HTCondor-CE installation.\n\n\n\n\n\n\nMake all changes to \n.ini\n files in the \n/etc/osg/config.d\n directory\n\n\n\n\nNote\n\n\nThis document describes the critical settings for HTCondor-CE and related software. You may need to configure other software that is installed on your HTCondor-CE host, too.\n\n\n\n\n\n\n\n\nValidate the configuration settings\n\n\n[root@client ~ ] $\n osg-configure -v\n\n\n\n\n\n\n\n\n\nFix any errors (at least) that \nosg-configure\n reports.\n\n\n\n\n\n\nOnce the validation command succeeds without errors, apply the configuration settings:\n\n\n[root@client ~ ] $ osg-configure -c\n\n\n\n\n\n\n\n\n\nGenerate a \nuser-vo-map\n file with your authentication set up (skip this step if you're using the LCMAPS VOMS plugin):\n\n\n\n\n\n\nIf you're using edg-mkgridmap, run the following:\n\n\n[root@client ~ ] $\n edg-mkgridmap\n\n\n\n\n\n\n\n\n\nIf you're using GUMS, run the following:\n\n\n[root@client ~ ] $\n gums-host-cron\n\n\n\n\n\n\n\n\n\n\n\n\n\nOptional configuration\n\n\nThe following configuration steps are optional and will likely not be required for setting up a small site. If you do not need any of the following special configurations, skip to \nthe section on using HTCondor-CE\n.\n\n\n\n\nTransforming and filtering jobs\n\n\nConfiguring for multiple network interfaces\n\n\nLimiting or disabling locally running jobs on the CE\n\n\nAccounting with multiple CEs or local user jobs\n\n\nHTCondor accounting groups\n\n\nInstalling the HTCondor-CE View\n\n\n\n\nTransforming and filtering jobs\n\n\nIf you need to modify or filter jobs, more information can be found in the \nJob Router Recipes\n document.\n\n\n\n\nNote\n\n\nIf you need to assign jobs to HTCondor accounting groups, refer to \nthis\n section.\n\n\n\n\nConfiguring for multiple network interfaces\n\n\nIf you have multiple network interfaces with different hostnames, the HTCondor-CE daemons need to know which hostname and interface to use when communicating to each other. Set \nNETWORK_HOSTNAME\n and \nNETWORK_INTERFACE\n to the hostname and IP address of your public interface, respectively, in \n/etc/condor-ce/config.d/99-local.conf\n directory with the line:\n\n\nNETWORK_HOSTNAME = \ncondorce.example.com\n\nNETWORK_INTERFACE = \n127.0.0.1\n\n\n\n\n\n\nReplacing \ncondorce.example.com\n text with your public interface\u2019s hostname and \n127.0.0.1\n with your public interface\u2019s IP address.\n\n\nLimiting or disabling locally running jobs on the CE\n\n\nIf you want to limit or disable jobs running locally on your CE, you will need to configure HTCondor-CE's local and scheduler universes. Local and scheduler universes are HTCondor-CE\u2019s analogue to GRAM\u2019s managed fork: they allow jobs to be run on the CE itself, mainly for remote troubleshooting. Pilot jobs will not run as local/scheduler universe jobs so leaving them enabled does NOT turn your CE into another worker node.\n\n\nThe two universes are effectively the same (scheduler universe launches a starter process for each job), so we will be configuring them in unison.\n\n\n\n\n\n\nTo change the default limit\n on the number of locally run jobs (the current default is 20), add the following to \n/etc/condor-ce/config.d/99-local.conf\n: \n\n\nSTART_LOCAL_UNIVERSE\n \n=\n TotalLocalJobsRunning + TotalSchedulerJobsRunning \n \nJOB-LIMIT\n\n\nSTART_SCHEDULER_UNIVERSE\n \n=\n \n$(\nSTART_LOCAL_UNIVERSE\n)\n\n\n\n\n\n\n\n\n\n\nTo only allow a specific user\n to start locally run jobs, add the following to \n/etc/condor-ce/config.d/99-local.conf\n: \n\n\nSTART_LOCAL_UNIVERSE\n \n=\n target.Owner \n=\n?\n=\n \nUSERNAME\n\n\nSTART_SCHEDULER_UNIVERSE\n \n=\n \n$(\nSTART_LOCAL_UNIVERSE\n)\n\n\n\n\n\n\n\n\n\n\nTo disable\n locally run jobs, add the following to \n/etc/condor-ce/config.d/99-local.conf\n: \n\n\nSTART_LOCAL_UNIVERSE\n \n=\n False\n\nSTART_SCHEDULER_UNIVERSE\n \n=\n \n$(\nSTART_LOCAL_UNIVERSE\n)\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nRSV requires the ability to start local universe jobs so if you are using RSV, you need to allow local universe jobs from the \nrsv\n user.\n\n\n\n\nAccounting with multiple CEs or local user jobs\n\n\n\n\nNote\n\n\nFor non-HTCondor batch systems only\n\n\n\n\nIf your site has multiple CEs or you have non-grid users submitting to the same local batch system, the OSG accounting software needs to be configured so that it doesn't over report the number of jobs. Use the following table to determine which file requires editing:\n\n\n\n\n\n\n\n\nIf your batch system is\u2026\n\n\nThen edit the following file on your CE(s)\u2026\n\n\n\n\n\n\n\n\n\n\nLSF\n\n\n/etc/gratia/pbs-lsf/ProbeConfig\n\n\n\n\n\n\nPBS\n\n\n/etc/gratia/pbs-lsf/ProbeConfig\n\n\n\n\n\n\nSGE\n\n\n/etc/gratia/sge/ProbeConfig\n\n\n\n\n\n\nSLURM\n\n\n/etc/gratia/slurm/ProbeConfig\n\n\n\n\n\n\n\n\nThen edit the value of \nSuppressNoDNRecords\n so that it reads:\n\n\nSuppressNoDNRecords=\n1\n\n\n\n\n\n\nHTCondor accounting groups\n\n\n\n\nNote\n\n\nFor HTCondor batch systems only\n\n\n\n\nIf you want to provide fairshare on a group basis, as opposed to a Unix user basis, you can use HTCondor accounting groups. They are independent of the Unix groups the user may already be in and are \ndocumented in the HTCondor manual\n. If you are using HTCondor accounting groups, you can map jobs from the CE into HTCondor accounting groups based on their UID, their DN, or their VOMS attributes.\n\n\n\n\n\n\nTo map UIDs to an accounting group,\n add entries to \n/etc/osg/uid_table.txt\n with the following form:\n\n\nuid GroupName\n\n\n\n\n\nThe following is an example \nuid_table.txt\n:\n\n\nuscms02 TestGroup\nosg     other.osgedu\n\n\n\n\n\n\n\n\n\nTo map DNs or VOMS attributes to an accounting group,\n add lines to \n/etc/osg/extattr_table.txt\n with the following form:\n\n\nSubjectOrAttribute\n GroupName\n\n\n\n\n\n\nThe \nSubjectOrAttribute\n can be a Perl regular expression. The following is an example \nextattr_table.txt\n:\n\n\ncmsprio cms.other.prio\ncms\\/Role=production cms.prod\n\\/DC=com\\/DC=DigiCert-Grid\\/O=Open\\ Science\\ Grid\\/OU=People\\/CN=Brian\\ Lin\\ 1047 osg.test\n.* other\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nEntries in \n/etc/osg/uid_table.txt\n are honored over \n/etc/osg/extattr_table.txt\n if a job would match to lines in both files.\n\n\n\n\nInstall and run the HTCondor-CE View\n\n\nThe HTCondor-CE View is an optional web interface to the status of your CE. To run the View,\n\n\n\n\n\n\nBegin by installing the package htcondor-ce-view:\n\n\n[root@client ~ ] $\n yum install htcondor-ce-view\n\n\n\n\n\n\n\n\n\nNext, uncomment the \nDAEMON_LIST\n configuration located at \n/etc/condor-ce/config.d/05-ce-view.conf\n:\n\n\nDAEMON_LIST\n \n=\n \n$(\nDAEMON_LIST\n)\n, CEVIEW, GANGLIAD\n\n\n\n\n\n\n\n\n\nRestart the CE service:\n\n\n[root@client ~ ] $\n service condor-ce restart\n\n\n\n\n\n\n\n\n\nVerify the service by entering your CE's hostname into your web browser\n\n\n\n\n\n\nThe website is served on port 80 by default. To change this default, edit the value of \nHTCONDORCE_VIEW_PORT\n in \n/etc/condor-ce/config.d/05-ce-view.conf\n.\n\n\nUsing HTCondor-CE\n\n\nAs a site administrator, there are a few ways in which you might use the HTCondor-CE:\n\n\n\n\nManaging the HTCondor-CE and associated services\n\n\nUsing HTCondor-CE administrative tools to monitor and maintain the job gateway\n\n\nUsing HTCondor-CE user tools to test gateway operations\n\n\n\n\nManaging HTCondor-CE and associated services\n\n\nIn addition to the HTCondor-CE job gateway service itself, there are a number of supporting services in your installation. The specific services are:\n\n\n\n\n\n\n\n\nSoftware\n\n\nService name\n\n\nNotes\n\n\n\n\n\n\n\n\n\n\nFetch CRL\n\n\nfetch-crl-boot\n and \nfetch-crl-cron\n\n\nSee \nCA documentation\n for more info\n\n\n\n\n\n\nGratia\n\n\ngratia-probes-cron\n\n\nAccounting software\n\n\n\n\n\n\nYour batch system\n\n\ncondor\n or \npbs_server\n or \u2026\n\n\n\n\n\n\n\n\nHTCondor-CE\n\n\ncondor-ce\n\n\n\n\n\n\n\n\n\n\nStart the services in the order listed and stop them in reverse order. As a reminder, here are common service commands (all run as \nroot\n):\n\n\n\n\n\n\n\n\nTo...\n\n\nOn EL6, run the command...\n\n\nOn EL7, run the command...\n\n\n\n\n\n\n\n\n\n\nStart a service\n\n\nservice \nSERVICE-NAME\n start\n\n\nsystemctl start \nSERVICE-NAME\n\n\n\n\n\n\nStop a  service\n\n\nservice \nSERVICE-NAME\n stop\n\n\nsystemctl stop \nSERVICE-NAME\n\n\n\n\n\n\nEnable a service to start on boot\n\n\nchkconfig \nSERVICE-NAME\n on\n\n\nsystemctl enable \nSERVICE-NAME\n\n\n\n\n\n\nDisable a service from starting on boot\n\n\nchkconfig \nSERVICE-NAME\n off\n\n\nsystemctl disable \nSERVICE-NAME\n\n\n\n\n\n\n\n\nUsing HTCondor-CE tools\n\n\nSome of the HTCondor-CE administrative and user tools are documented in \nthe HTCondor-CE troubleshooting guide\n.\n\n\nValidating HTCondor-CE\n\n\nThere are different ways to make sure that your HTCondor-CE host is working well:\n\n\n\n\nPerform automated validation by running \nRSV\n\n\nManually verify your HTCondor-CE using \nHTCondor-CE troubleshooting guide\n; useful tools include:\n\n\ncondor_ce_run\n\n\ncondor_ce_trace\n\n\ncondor_submit\n\n\n\n\n\n\n\n\nTroubleshooting HTCondor-CE\n\n\nFor information on how to troubleshoot your HTCondor-CE, please refer to \nthe HTCondor-CE troubleshooting guide\n.\n\n\nRegistering the CE\n\n\nTo be part of the OSG Production Grid, your CE must be registered in the \nOSG Information Management System\n (OIM). To register your resource:\n\n\n\n\nObtain, install, and verify your user certificate\n (which you may have done already)\n\n\nRegister your site and CE in OIM\n\n\n\n\nGetting Help\n\n\nTo get assistance, please use the \nthis page\n.\n\n\nReference\n\n\nHere are some other HTCondor-CE documents that might be helpful:\n\n\n\n\nHTCondor-CE overview and architecture\n\n\nInstalling and maintaining HTCondor-CE-Bosco\n\n\nConfiguring HTCondor-CE job routes\n\n\nThe HTCondor-CE troubleshooting guide\n\n\nSubmitting jobs to HTCondor-CE\n\n\n\n\nConfiguration\n\n\nThe following directories contain the configuration for HTCondor-CE. The directories are parsed in the order presented and thus configuration within the final directory will override configuration specified in the previous directories.\n\n\n\n\n\n\n\n\nLocation\n\n\nComment\n\n\n\n\n\n\n\n\n\n\n/usr/share/condor-ce/config.d/\n\n\nConfiguration defaults (overwritten on package updates)\n\n\n\n\n\n\n/etc/condor-ce/config.d/\n\n\nFiles in this directory are parsed in alphanumeric order (i.e., \n99-local.conf\n will override values in \n01-ce-auth.conf\n)\n\n\n\n\n\n\n\n\nFor a detailed order of the way configuration files are parsed, run the following command:\n\n\n[user@client ~ ] $\n condor_ce_config_val -config\n\n\n\n\n\nUsers\n\n\nThe following users are needed by HTCondor-CE at all sites:\n\n\n\n\n\n\n\n\nUser\n\n\nComment\n\n\n\n\n\n\n\n\n\n\ncondor\n\n\nThe HTCondor-CE will be run as root, but perform most of its operations as the \ncondor\n user.\n\n\n\n\n\n\ngratia\n\n\nRuns the Gratia probes to collect accounting data\n\n\n\n\n\n\n\n\nCertificates\n\n\n\n\n\n\n\n\nFile\n\n\nUser that owns certificate\n\n\nPath to certificate\n\n\n\n\n\n\n\n\n\n\nHost certificate\n\n\nroot\n\n\n/etc/grid-security/hostcert.pem\n\n\n\n\n\n\nHost key\n\n\nroot\n\n\n/etc/grid-security/hostkey.pem\n\n\n\n\n\n\n\n\nFind instructions to request a host certificate \nhere\n.\n\n\nNetworking\n\n\n\n\n\n\n\n\nService Name\n\n\nProtocol\n\n\nPort Number\n\n\nInbound\n\n\nOutbound\n\n\nComment\n\n\n\n\n\n\n\n\n\n\nHtcondor-CE\n\n\ntcp\n\n\n9619\n\n\nX\n\n\n\n\nHTCondor-CE shared port\n\n\n\n\n\n\n\n\nAllow inbound and outbound network connection to all internal site servers, such as GUMS and the batch system head-node only ephemeral outgoing ports are necessary.", 
            "title": "Install Guide"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#installing-and-maintaining-htcondor-ce", 
            "text": "", 
            "title": "Installing and Maintaining HTCondor-CE"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#about-this-guide", 
            "text": "The  HTCondor-CE  software is a  job gateway  for an OSG Compute Element (CE). As such, HTCondor-CE is the entry point for jobs coming from the OSG \u2014 it handles authorization and delegation of jobs to your local batch system. In OSG today, most CEs accept  pilot jobs  from a factory, which in turn are able to accept and run end-user jobs.  Use this page to learn how to install, configure, run, test, and troubleshoot HTCondor-CE from the OSG software repositories.", 
            "title": "About This Guide"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#before-starting", 
            "text": "Before starting the installation process, consider the following points (consulting  the Reference section below  as needed):   User IDs:  If they do not exist already, the installation will create the Linux users  condor  (UID 4716) and  gratia  (UID 42401)  Service certificate:  The HTCondor-CE service uses a host certificate at  /etc/grid-security/hostcert.pem  and an accompanying key at  /etc/grid-security/hostkey.pem  Network ports:  The pilot factories must be able to contact your HTCondor-CE service on ports 9619 and 9620 for condor versions   8.3.2 (TCP)  Host choice:  HTCondor-CE should be installed on a host that already has the ability to submit jobs into your local cluster   As with all OSG software installations, there are some one-time (per host) steps to prepare in advance:   Ensure the host has  a supported operating system  Obtain root access to the host  Prepare the  required Yum repositories  Install  CA certificates", 
            "title": "Before Starting"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#installing-htcondor-ce", 
            "text": "An HTCondor-CE installation consists of the job gateway (i.e., the HTCondor-CE job router) and other support software (e.g., GridFTP, a Gratia probe, authentication software). To simplify installation, OSG provides convenience RPMs that install all required software with a single command.    Clean yum cache:  [root@client ~ ] $  yum clean all --enablerepo = *    Update software:  [root@client ~ ] $  yum update  This command will update  all  packages    If your batch system is already installed via non-RPM means and is in the following list, install the appropriate 'empty' RPM. Otherwise, skip to the next step.     If your batch system is\u2026  Then run the following command\u2026      HTCondor  yum install empty-condor --enablerepo=osg-empty    PBS  yum install empty-torque --enablerepo=osg-empty    SGE  yum install empty-gridengine --enablerepo=osg-empty    SLURM  yum install empty-slurm --enablerepo=osg-empty       If your HTCondor batch system is already installed via non-OSG RPM means, add the line below to  /etc/yum.repos.d/osg.repo . Otherwise, skip to the next step.  exclude=condor empty-condor    Select the appropriate convenience RPM(s):     If your batch system is\u2026  Then use the following package(s)\u2026      HTCondor  osg-ce-condor    LSF  osg-ce-lsf    PBS  osg-ce-pbs    SGE  osg-ce-sge    SLURM  osg-ce-slurm       Install the CE software:  [root@client ~] $ yum install *PACKAGE(S)*", 
            "title": "Installing HTCondor-CE"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#configuring-htcondor-ce", 
            "text": "There are a few required configuration steps to connect HTCondor-CE with your batch system and authentication method. For more advanced configuration, see the section on  optional configurations .", 
            "title": "Configuring HTCondor-CE"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#enabling-htcondor-ce", 
            "text": "If you are installing HTCondor-CE on a new host, the default configuration is correct and you can skip this step and continue onto  Configuring the batch system ! However, if you are updating a host that used a Globus GRAM job gateway (aka the Globus gatekeeper), you must disable GRAM and enable the HTCondor job gateway. Edit the gateway configuration file  /etc/osg/config.d/10-gateway.ini  so that it reads:  gram_gateway_enabled = False\nhtcondor_gateway_enabled = True", 
            "title": "Enabling HTCondor-CE"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#configuring-the-batch-system", 
            "text": "Enable your batch system by editing the  enabled  field in the  /etc/osg/config.d/20- YOUR BATCH SYSTEM .ini  enabled =  True   If you are using HTCondor as your  local batch system  (i.e., in addition to your HTCondor-CE), skip to the  configuring authentication  section. For other batch systems (e.g., PBS, LSF, SGE, SLURM), keep reading.", 
            "title": "Configuring the batch system"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#batch-systems-other-than-htcondor", 
            "text": "Non-HTCondor batch systems require additional configuration to support file transfer to your site's worker nodes.", 
            "title": "Batch systems other than HTCondor"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#sharing-the-spool-directory", 
            "text": "To transfer files between the CE and the batch system, HTCondor-CE requires a shared file system. The current recommendation is to run a dedicated NFS server (whose installation is beyond the scope of this document) on the  CE host . In this setup, HTCondor-CE writes to the local spool directory and the NFS server shares the directory with all of the worker nodes.   Note  If you choose not to host the NFS server on your CE, you will need to turn off root squash so that the HTCondor-CE daemons can write to the spool directory.   By default, the spool directory is  /var/lib/condor-ce  but you can control this by setting  SPOOL  in  /etc/condor-ce/config.d/99-local.conf  (create this file if it doesn't exist). For example, the following sets the  SPOOL  directory to  /home/condor :  SPOOL=/home/condor   Note  The shared spool directory must be readable and writeable by the  condor  user for HTCondor-CE to function correctly.", 
            "title": "Sharing the spool directory"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#disable-worker-node-proxy-renewal", 
            "text": "Worker node proxy renewal is not used by HTCondor-CE and leaving it on will cause some jobs to be held. Edit  /etc/blah.config  on the HTCondor-CE host and set the following values:  blah_disable_wn_proxy_renewal=yes\nblah_delegate_renewed_proxies=no\nblah_disable_limited_proxy=yes   Note  There should be no whitespace around the  = .", 
            "title": "Disable worker node proxy renewal"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#configuring-authentication", 
            "text": "In OSG 3.3, there are three methods to manage authentication for incoming jobs: the  LCMAPS VOMS plugin ,  edg-mkgridmap  and  GUMS . edg-mkgridmap is easy to set up and maintain, and GUMS has more features and capabilities. The LCMAPS VOMS plugin is the new OSG-preferred authentication, offering the simplicity of edg-mkgridmap and many of GUMS' rich feature set. If you need to support  pool accounts , GUMS is the only software with that capability.  In OSG 3.4, the LCMAPS VOMS plugin is the only available authentication solution.", 
            "title": "Configuring authentication"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#authentication-with-the-lcmaps-voms-plugin", 
            "text": "To configure your CE to use the LCMAPS VOMS plugin:    If you are using OSG 3.3, add the following line to  /etc/sysconfig/condor-ce :  export LLGT_VOMS_ENABLE_CREDENTIAL_CHECK=1    Follow the instructions in  the LCMAPS VOMS plugin installation and configuration document  to prepare the LCMAPS VOMS plugin     Note  If your local batch system is HTCondor, it will attempt to utilize the LCMAPS callouts if enabled in the  condor_mapfile . If this is not the desired behavior, set  GSI_AUTHZ_CONF=/dev/null  in the local HTCondor configuration.", 
            "title": "Authentication with the LCMAPS VOMS plugin"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#authentication-with-edg-mkgridmap", 
            "text": "Warning  edg-mkgridmap is unavailable in OSG 3.4   To configure your CE to use edg-mkgridmap:   Follow the configuration instructions in  the edg-mkgridmap document  to define the VOs that your site accepts  Set some critical gridmap attributes by editing the  /etc/osg/config.d/10-misc.ini  file on the HTCondor-CE host: authorization_method = gridmap", 
            "title": "Authentication with edg-mkgridmap"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#authentication-with-gums", 
            "text": "Warning  GUMS is unavailable in OSG 3.4    Follow the instructions in  the GUMS installation and configuration document  to prepare GUMS  Set some critical GUMS attributes by editing the  /etc/osg/config.d/10-misc.ini  file on the HTCondor-CE host: authorization_method = xacml\ngums_host =  YOUR GUMS HOSTNAME      Note  If your local batch system is HTCondor, it will attempt to utilize the LCMAPS callouts if enabled in the  condor_mapfile . If this is not the desired behavior, set  GSI_AUTHZ_CONF=/dev/null  in the local HTCondor configuration.", 
            "title": "Authentication with GUMS"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#configuring-ce-collector-advertising", 
            "text": "To split jobs between the various sites of the OSG, information about each site's capabilities are uploaded to a central collector. The job factories then query the central collector for idle resources and submit pilot jobs to the available sites. To advertise your site, you will need to enter some information about the worker nodes of your clusters.  Please see the  Subcluster / Resource Entry configuration document  about configuring the data that will be uploaded to the central collector.", 
            "title": "Configuring CE collector advertising"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#applying-configuration-settings", 
            "text": "Making changes to the OSG configuration files in the  /etc/osg/config.d  directory does not apply those settings to software automatically. Settings that are made outside of the OSG directory take effect immediately or at least when the relevant service is restarted. For the OSG settings, use the  osg-configure  tool to validate (to a limited extent) and apply the settings to the relevant software components. The  osg-configure  software is included automatically in an HTCondor-CE installation.    Make all changes to  .ini  files in the  /etc/osg/config.d  directory   Note  This document describes the critical settings for HTCondor-CE and related software. You may need to configure other software that is installed on your HTCondor-CE host, too.     Validate the configuration settings  [root@client ~ ] $  osg-configure -v    Fix any errors (at least) that  osg-configure  reports.    Once the validation command succeeds without errors, apply the configuration settings:  [root@client ~ ] $ osg-configure -c    Generate a  user-vo-map  file with your authentication set up (skip this step if you're using the LCMAPS VOMS plugin):    If you're using edg-mkgridmap, run the following:  [root@client ~ ] $  edg-mkgridmap    If you're using GUMS, run the following:  [root@client ~ ] $  gums-host-cron", 
            "title": "Applying configuration settings"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#optional-configuration", 
            "text": "The following configuration steps are optional and will likely not be required for setting up a small site. If you do not need any of the following special configurations, skip to  the section on using HTCondor-CE .   Transforming and filtering jobs  Configuring for multiple network interfaces  Limiting or disabling locally running jobs on the CE  Accounting with multiple CEs or local user jobs  HTCondor accounting groups  Installing the HTCondor-CE View", 
            "title": "Optional configuration"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#transforming-and-filtering-jobs", 
            "text": "If you need to modify or filter jobs, more information can be found in the  Job Router Recipes  document.   Note  If you need to assign jobs to HTCondor accounting groups, refer to  this  section.", 
            "title": "Transforming and filtering jobs"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#configuring-for-multiple-network-interfaces", 
            "text": "If you have multiple network interfaces with different hostnames, the HTCondor-CE daemons need to know which hostname and interface to use when communicating to each other. Set  NETWORK_HOSTNAME  and  NETWORK_INTERFACE  to the hostname and IP address of your public interface, respectively, in  /etc/condor-ce/config.d/99-local.conf  directory with the line:  NETWORK_HOSTNAME =  condorce.example.com \nNETWORK_INTERFACE =  127.0.0.1   Replacing  condorce.example.com  text with your public interface\u2019s hostname and  127.0.0.1  with your public interface\u2019s IP address.", 
            "title": "Configuring for multiple network interfaces"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#limiting-or-disabling-locally-running-jobs-on-the-ce", 
            "text": "If you want to limit or disable jobs running locally on your CE, you will need to configure HTCondor-CE's local and scheduler universes. Local and scheduler universes are HTCondor-CE\u2019s analogue to GRAM\u2019s managed fork: they allow jobs to be run on the CE itself, mainly for remote troubleshooting. Pilot jobs will not run as local/scheduler universe jobs so leaving them enabled does NOT turn your CE into another worker node.  The two universes are effectively the same (scheduler universe launches a starter process for each job), so we will be configuring them in unison.    To change the default limit  on the number of locally run jobs (the current default is 20), add the following to  /etc/condor-ce/config.d/99-local.conf :   START_LOCAL_UNIVERSE   =  TotalLocalJobsRunning + TotalSchedulerJobsRunning    JOB-LIMIT  START_SCHEDULER_UNIVERSE   =   $( START_LOCAL_UNIVERSE )     To only allow a specific user  to start locally run jobs, add the following to  /etc/condor-ce/config.d/99-local.conf :   START_LOCAL_UNIVERSE   =  target.Owner  = ? =   USERNAME  START_SCHEDULER_UNIVERSE   =   $( START_LOCAL_UNIVERSE )     To disable  locally run jobs, add the following to  /etc/condor-ce/config.d/99-local.conf :   START_LOCAL_UNIVERSE   =  False START_SCHEDULER_UNIVERSE   =   $( START_LOCAL_UNIVERSE )      Note  RSV requires the ability to start local universe jobs so if you are using RSV, you need to allow local universe jobs from the  rsv  user.", 
            "title": "Limiting or disabling locally running jobs on the CE"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#accounting-with-multiple-ces-or-local-user-jobs", 
            "text": "Note  For non-HTCondor batch systems only   If your site has multiple CEs or you have non-grid users submitting to the same local batch system, the OSG accounting software needs to be configured so that it doesn't over report the number of jobs. Use the following table to determine which file requires editing:     If your batch system is\u2026  Then edit the following file on your CE(s)\u2026      LSF  /etc/gratia/pbs-lsf/ProbeConfig    PBS  /etc/gratia/pbs-lsf/ProbeConfig    SGE  /etc/gratia/sge/ProbeConfig    SLURM  /etc/gratia/slurm/ProbeConfig     Then edit the value of  SuppressNoDNRecords  so that it reads:  SuppressNoDNRecords= 1", 
            "title": "Accounting with multiple CEs or local user jobs"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#htcondor-accounting-groups", 
            "text": "Note  For HTCondor batch systems only   If you want to provide fairshare on a group basis, as opposed to a Unix user basis, you can use HTCondor accounting groups. They are independent of the Unix groups the user may already be in and are  documented in the HTCondor manual . If you are using HTCondor accounting groups, you can map jobs from the CE into HTCondor accounting groups based on their UID, their DN, or their VOMS attributes.    To map UIDs to an accounting group,  add entries to  /etc/osg/uid_table.txt  with the following form:  uid GroupName  The following is an example  uid_table.txt :  uscms02 TestGroup\nosg     other.osgedu    To map DNs or VOMS attributes to an accounting group,  add lines to  /etc/osg/extattr_table.txt  with the following form:  SubjectOrAttribute  GroupName   The  SubjectOrAttribute  can be a Perl regular expression. The following is an example  extattr_table.txt :  cmsprio cms.other.prio\ncms\\/Role=production cms.prod\n\\/DC=com\\/DC=DigiCert-Grid\\/O=Open\\ Science\\ Grid\\/OU=People\\/CN=Brian\\ Lin\\ 1047 osg.test\n.* other     Note  Entries in  /etc/osg/uid_table.txt  are honored over  /etc/osg/extattr_table.txt  if a job would match to lines in both files.", 
            "title": "HTCondor accounting groups"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#install-and-run-the-htcondor-ce-view", 
            "text": "The HTCondor-CE View is an optional web interface to the status of your CE. To run the View,    Begin by installing the package htcondor-ce-view:  [root@client ~ ] $  yum install htcondor-ce-view    Next, uncomment the  DAEMON_LIST  configuration located at  /etc/condor-ce/config.d/05-ce-view.conf :  DAEMON_LIST   =   $( DAEMON_LIST ) , CEVIEW, GANGLIAD    Restart the CE service:  [root@client ~ ] $  service condor-ce restart    Verify the service by entering your CE's hostname into your web browser    The website is served on port 80 by default. To change this default, edit the value of  HTCONDORCE_VIEW_PORT  in  /etc/condor-ce/config.d/05-ce-view.conf .", 
            "title": "Install and run the HTCondor-CE View"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#using-htcondor-ce", 
            "text": "As a site administrator, there are a few ways in which you might use the HTCondor-CE:   Managing the HTCondor-CE and associated services  Using HTCondor-CE administrative tools to monitor and maintain the job gateway  Using HTCondor-CE user tools to test gateway operations", 
            "title": "Using HTCondor-CE"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#managing-htcondor-ce-and-associated-services", 
            "text": "In addition to the HTCondor-CE job gateway service itself, there are a number of supporting services in your installation. The specific services are:     Software  Service name  Notes      Fetch CRL  fetch-crl-boot  and  fetch-crl-cron  See  CA documentation  for more info    Gratia  gratia-probes-cron  Accounting software    Your batch system  condor  or  pbs_server  or \u2026     HTCondor-CE  condor-ce      Start the services in the order listed and stop them in reverse order. As a reminder, here are common service commands (all run as  root ):     To...  On EL6, run the command...  On EL7, run the command...      Start a service  service  SERVICE-NAME  start  systemctl start  SERVICE-NAME    Stop a  service  service  SERVICE-NAME  stop  systemctl stop  SERVICE-NAME    Enable a service to start on boot  chkconfig  SERVICE-NAME  on  systemctl enable  SERVICE-NAME    Disable a service from starting on boot  chkconfig  SERVICE-NAME  off  systemctl disable  SERVICE-NAME", 
            "title": "Managing HTCondor-CE and associated services"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#using-htcondor-ce-tools", 
            "text": "Some of the HTCondor-CE administrative and user tools are documented in  the HTCondor-CE troubleshooting guide .", 
            "title": "Using HTCondor-CE tools"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#validating-htcondor-ce", 
            "text": "There are different ways to make sure that your HTCondor-CE host is working well:   Perform automated validation by running  RSV  Manually verify your HTCondor-CE using  HTCondor-CE troubleshooting guide ; useful tools include:  condor_ce_run  condor_ce_trace  condor_submit", 
            "title": "Validating HTCondor-CE"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#troubleshooting-htcondor-ce", 
            "text": "For information on how to troubleshoot your HTCondor-CE, please refer to  the HTCondor-CE troubleshooting guide .", 
            "title": "Troubleshooting HTCondor-CE"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#registering-the-ce", 
            "text": "To be part of the OSG Production Grid, your CE must be registered in the  OSG Information Management System  (OIM). To register your resource:   Obtain, install, and verify your user certificate  (which you may have done already)  Register your site and CE in OIM", 
            "title": "Registering the CE"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#getting-help", 
            "text": "To get assistance, please use the  this page .", 
            "title": "Getting Help"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#reference", 
            "text": "Here are some other HTCondor-CE documents that might be helpful:   HTCondor-CE overview and architecture  Installing and maintaining HTCondor-CE-Bosco  Configuring HTCondor-CE job routes  The HTCondor-CE troubleshooting guide  Submitting jobs to HTCondor-CE", 
            "title": "Reference"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#configuration", 
            "text": "The following directories contain the configuration for HTCondor-CE. The directories are parsed in the order presented and thus configuration within the final directory will override configuration specified in the previous directories.     Location  Comment      /usr/share/condor-ce/config.d/  Configuration defaults (overwritten on package updates)    /etc/condor-ce/config.d/  Files in this directory are parsed in alphanumeric order (i.e.,  99-local.conf  will override values in  01-ce-auth.conf )     For a detailed order of the way configuration files are parsed, run the following command:  [user@client ~ ] $  condor_ce_config_val -config", 
            "title": "Configuration"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#users", 
            "text": "The following users are needed by HTCondor-CE at all sites:     User  Comment      condor  The HTCondor-CE will be run as root, but perform most of its operations as the  condor  user.    gratia  Runs the Gratia probes to collect accounting data", 
            "title": "Users"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#certificates", 
            "text": "File  User that owns certificate  Path to certificate      Host certificate  root  /etc/grid-security/hostcert.pem    Host key  root  /etc/grid-security/hostkey.pem     Find instructions to request a host certificate  here .", 
            "title": "Certificates"
        }, 
        {
            "location": "/compute-element/install-htcondor-ce/#networking", 
            "text": "Service Name  Protocol  Port Number  Inbound  Outbound  Comment      Htcondor-CE  tcp  9619  X   HTCondor-CE shared port     Allow inbound and outbound network connection to all internal site servers, such as GUMS and the batch system head-node only ephemeral outgoing ports are necessary.", 
            "title": "Networking"
        }, 
        {
            "location": "/other/gsissh/", 
            "text": "Installing GSI OpenSSH\n\n\nThis document gives instructions on installing and using the GSI OpenSSH server available in the OSG repository and configuring it so that you can use on your cluster.\n\n\nRequirements\n\n\nHost and OS\n\n\nThe GSI OpenSSH rpms will require an user account and group in order for the privilege separation to work.\n\n\nUsers and Groups\n\n\nThe RPM installation will try to create the \ngsisshd\n user and group and the \n/var/empty/gsisshd\n directory with the correct ownership if they are not present. If you are using a configuration management system or ROCKS, you should make sure that these users and groups are created before installing the RPMs to avoid potential issues. The gsisshd user should have an empty home directory. By default, this is home directory set to \n/var/empty/gsisshd\n and belongs to the \ngsisshd\n user and group. You may change it if needed to something else as long as the ownerships remain the same.\n\n\nNetworking\n\n\nYou'll find more client specific details also in the \nFirewall section\n of this document.\n\n\nInstallation procedure\n\n\nPrior to install, make sure you have:\n\n \nYum repositories correctly configured\n for OSG.\n\n \nCA certificates installed\n\n\nGSI OpenSSH Installation\n\n\nStart with installing GSI OpenSSH from the repository\n\n\nyum install gsi-openssh-server gsi-openssh-clients\n\n\n\n\n\nIn addition, you'll need to install CA certificates in order for GSIOpenSSH to work. You can follow the instructions below in order to install them:\n\n\nConfiguration and Operations\n\n\nUseful configuration and log files\n\n\nConfiguration Files\n\n\n\n\n\n\n\n\nService or Process\n\n\nConfiguration File\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ngsisshd\n\n\n/etc/gsissh/sshd_config\n\n\nConfiguration file\n\n\n\n\n\n\ngsisshd\n\n\n/etc/sysconfig/gsisshd\n\n\nEnvironment variables for gsisshd\n\n\n\n\n\n\ngsisshd\n\n\n/etc/lcmaps.db\n\n\nLCMAPS configuration\n\n\n\n\n\n\n\n\nLog Files\n\n\n\n\n\n\n\n\nService or Process\n\n\nLog File\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ngsisshd\n\n\n/var/log/messages\n\n\nAll log messages\n\n\n\n\n\n\n\n\nOther Files\n\n\n\n\n\n\n\n\nService or Process\n\n\nFile\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ngsisshd\n\n\n/etc/grid-security/hostcert.pem\n\n\nHost certificate\n\n\n\n\n\n\ngsisshd\n\n\n/etc/grid-security/hostcert.pem\n\n\nKey certificate\n\n\n\n\n\n\ngsisshd\n\n\n/etc/gsissh/ssh_host_rsa_key\n\n\nRSA Host key\n\n\n\n\n\n\n\n\nConfiguration\n\n\nConfiguration\n\n\nIn order to get a running instance of the GSI OpenSSH server, you'll\nneed to change the default configuration. However, before you go any\nfurther, you'll need to decide whether you want GSI OpenSSH to be your \nprimary ssh service or not (e.g. whether the GSI OpenSSH service will \nreplace your existing SSH service). If you choose not to replace your \nexisting service, you'll need to change the port setting in the GSI \nOpenSSH configuration to another port (e.g. 2222) so that you can run \nboth SSH services at the same time. Regardless of your choice, you \nshould probably have both services use the same host key. In order \nto do this, symlink \n/etc/gsissh/ssh_host_dsa_key\n and \n/etc/gsissh/ssh_host_rsa_key\n \nto \n/etc/ssh/ssh_host_dsa_key\n and \n/etc/ssh/ssh_host_rsa_key\n respectively. \n\n\n\n\nNote\n\n\nRegardless of the authorization method used for the user, any \naccount that will be used with GSI OpenSSH must have a shell \nassigned to it and not be locked (have ! in the password field of \n/etc/shadow\n).\n\n\n\n\nUsing a gridmap file for authorization\n\n\nIn order to use gsissh, you'll need to create mappings in your \n\n/etc/grid-security/grid-mapfile\n for the DNs that you will \nallow to login. The mappings should be entered one to a line, \nwith each line consisting of DN followed by the account the DN \nshould map to. Also, you should ensure that the \n\n/etc/grid-security/gsi-authz.conf\n file is empty or that all \nof the lines in the file are commented out using a \n#\n at the beginning of the line.\n\n\n\n\nNote\n\n\nThe mappings will not consider VOMS extensions so the first mapping that matches will be used regardless of the VO role or VO present in the users proxy\n\n\n\n\nAn example of the \n/etc/grid-security/grid-mapfile\n follows:\n\n\n/DC=org/DC=doegrids/OU=People/CN=USER NAME 123456\n useraccount\n\n\n\n\n\nUsing LCMAPS and GUMS for authorization\n\n\nIn order to use LCMAPS callouts with GSI OpenSSH, you'll first need to edit \n/etc/grid-security/gsi-authz.conf\n to indicate that Globus should do a GSI callout for authorization. The file should contain the following:\n\n\nglobus_mapping liblcas_lcmaps_gt4_mapping.so lcmaps_callout\n\n\n\n\n\nso that LCMAPS is used. Next, install the lcmaps rpms:\n\n\nyum install lcmaps lcas-lcmaps-gt4-interface\n\n\n\n\n\nFinally, you'll need to modify \n/etc/lcmaps.db\n so that the \ngumsclient\n entry has the correct endpoint for your gums server.\n\n\nStarting and Enabling Services\n\n\nTo start the services:\n\n\n\n\n\n\nTo start GSI OpenSSH you can use the service command, e.g.:\n\n\nservice gsisshd start\n\n\n\n\n\n\nYou should also enable the appropriate services so that they are automatically started when your system is powered on:\n\n\n\n\n\n\nTo enable OpenSSH by default on the node:\n\n\nchkconfig gsisshd on\n\n\n\n\n\n\nStopping and Disabling Services\n\n\nTo stop the services:\n\n\n\n\n\n\nTo stop OpenSSH you can use: \\\npre class=\u201crootscreen\u201d>\n\n\nservice gsisshd stop\n\n\n\n\n\n\nIn addition, you can disable services by running the following commands. However, you don't need to do this normally.\n\n\n\n\n\n\nOptionally, to disable OpenSSH:\n\n\nchkconfig gsisshd off\n\n\n\n\n\n\nTroubleshooting\n\n\nYou can get information on troubleshooting errors on the \nNCSA page\n.\n\n\nTo troubleshoot LCMAPS authorization, you can add the following to \n/etc/sysconfig/gsisshd\n and choose a higher debug level:\n\n\n# level 0: no messages, 1: errors, 2: also warnings, 3: also notices,\n#  4: also info, 5: maximum debug\nLCMAPS_DEBUG_LEVEL=2\n\n\n\n\n\nOutput goes to \n/var/log/messages\n by default.\n\n\nTest GSI OpenSSH\n\n\nAfter starting the \ngsisshd\n service you can check if it is running correctly\n\n\n$ grid-proxy-init\nYour identity: /DC\n=\nch/DC\n=\ncern/OU\n=\nOrganic Units/OU\n=\nUsers/CN\n=\nUser Name\nEnter GRID pass phrase \nfor\n this identity:\nCreating proxy ............................................................................................... Done\nYour proxy is valid \nuntil\n: Sat Apr \n23\n \n08\n:18:27 \n2016\n\n$ gsissh localhost -p \n2222\n\nLast login: Tue Sep \n18\n \n16\n:08:03 \n2012\n from itb4.uchicago.edu\n$\n\n\n\n\n\nHow to get Help?\n\n\nTo get assistance please use this \nHelp Procedure\n.", 
            "title": "GSI-enabled SSH"
        }, 
        {
            "location": "/other/gsissh/#installing-gsi-openssh", 
            "text": "This document gives instructions on installing and using the GSI OpenSSH server available in the OSG repository and configuring it so that you can use on your cluster.", 
            "title": "Installing GSI OpenSSH"
        }, 
        {
            "location": "/other/gsissh/#requirements", 
            "text": "", 
            "title": "Requirements"
        }, 
        {
            "location": "/other/gsissh/#host-and-os", 
            "text": "The GSI OpenSSH rpms will require an user account and group in order for the privilege separation to work.", 
            "title": "Host and OS"
        }, 
        {
            "location": "/other/gsissh/#users-and-groups", 
            "text": "The RPM installation will try to create the  gsisshd  user and group and the  /var/empty/gsisshd  directory with the correct ownership if they are not present. If you are using a configuration management system or ROCKS, you should make sure that these users and groups are created before installing the RPMs to avoid potential issues. The gsisshd user should have an empty home directory. By default, this is home directory set to  /var/empty/gsisshd  and belongs to the  gsisshd  user and group. You may change it if needed to something else as long as the ownerships remain the same.", 
            "title": "Users and Groups"
        }, 
        {
            "location": "/other/gsissh/#networking", 
            "text": "You'll find more client specific details also in the  Firewall section  of this document.", 
            "title": "Networking"
        }, 
        {
            "location": "/other/gsissh/#installation-procedure", 
            "text": "Prior to install, make sure you have:   Yum repositories correctly configured  for OSG.   CA certificates installed", 
            "title": "Installation procedure"
        }, 
        {
            "location": "/other/gsissh/#gsi-openssh-installation", 
            "text": "Start with installing GSI OpenSSH from the repository  yum install gsi-openssh-server gsi-openssh-clients  In addition, you'll need to install CA certificates in order for GSIOpenSSH to work. You can follow the instructions below in order to install them:", 
            "title": "GSI OpenSSH Installation"
        }, 
        {
            "location": "/other/gsissh/#configuration-and-operations", 
            "text": "", 
            "title": "Configuration and Operations"
        }, 
        {
            "location": "/other/gsissh/#useful-configuration-and-log-files", 
            "text": "Configuration Files     Service or Process  Configuration File  Description      gsisshd  /etc/gsissh/sshd_config  Configuration file    gsisshd  /etc/sysconfig/gsisshd  Environment variables for gsisshd    gsisshd  /etc/lcmaps.db  LCMAPS configuration     Log Files     Service or Process  Log File  Description      gsisshd  /var/log/messages  All log messages     Other Files     Service or Process  File  Description      gsisshd  /etc/grid-security/hostcert.pem  Host certificate    gsisshd  /etc/grid-security/hostcert.pem  Key certificate    gsisshd  /etc/gsissh/ssh_host_rsa_key  RSA Host key", 
            "title": "Useful configuration and log files"
        }, 
        {
            "location": "/other/gsissh/#configuration", 
            "text": "", 
            "title": "Configuration"
        }, 
        {
            "location": "/other/gsissh/#configuration_1", 
            "text": "In order to get a running instance of the GSI OpenSSH server, you'll\nneed to change the default configuration. However, before you go any\nfurther, you'll need to decide whether you want GSI OpenSSH to be your \nprimary ssh service or not (e.g. whether the GSI OpenSSH service will \nreplace your existing SSH service). If you choose not to replace your \nexisting service, you'll need to change the port setting in the GSI \nOpenSSH configuration to another port (e.g. 2222) so that you can run \nboth SSH services at the same time. Regardless of your choice, you \nshould probably have both services use the same host key. In order \nto do this, symlink  /etc/gsissh/ssh_host_dsa_key  and  /etc/gsissh/ssh_host_rsa_key  \nto  /etc/ssh/ssh_host_dsa_key  and  /etc/ssh/ssh_host_rsa_key  respectively.    Note  Regardless of the authorization method used for the user, any \naccount that will be used with GSI OpenSSH must have a shell \nassigned to it and not be locked (have ! in the password field of  /etc/shadow ).", 
            "title": "Configuration"
        }, 
        {
            "location": "/other/gsissh/#using-a-gridmap-file-for-authorization", 
            "text": "In order to use gsissh, you'll need to create mappings in your  /etc/grid-security/grid-mapfile  for the DNs that you will \nallow to login. The mappings should be entered one to a line, \nwith each line consisting of DN followed by the account the DN \nshould map to. Also, you should ensure that the  /etc/grid-security/gsi-authz.conf  file is empty or that all \nof the lines in the file are commented out using a  #  at the beginning of the line.   Note  The mappings will not consider VOMS extensions so the first mapping that matches will be used regardless of the VO role or VO present in the users proxy   An example of the  /etc/grid-security/grid-mapfile  follows:  /DC=org/DC=doegrids/OU=People/CN=USER NAME 123456  useraccount", 
            "title": "Using a gridmap file for authorization"
        }, 
        {
            "location": "/other/gsissh/#using-lcmaps-and-gums-for-authorization", 
            "text": "In order to use LCMAPS callouts with GSI OpenSSH, you'll first need to edit  /etc/grid-security/gsi-authz.conf  to indicate that Globus should do a GSI callout for authorization. The file should contain the following:  globus_mapping liblcas_lcmaps_gt4_mapping.so lcmaps_callout  so that LCMAPS is used. Next, install the lcmaps rpms:  yum install lcmaps lcas-lcmaps-gt4-interface  Finally, you'll need to modify  /etc/lcmaps.db  so that the  gumsclient  entry has the correct endpoint for your gums server.", 
            "title": "Using LCMAPS and GUMS for authorization"
        }, 
        {
            "location": "/other/gsissh/#starting-and-enabling-services", 
            "text": "To start the services:    To start GSI OpenSSH you can use the service command, e.g.:  service gsisshd start    You should also enable the appropriate services so that they are automatically started when your system is powered on:    To enable OpenSSH by default on the node:  chkconfig gsisshd on", 
            "title": "Starting and Enabling Services"
        }, 
        {
            "location": "/other/gsissh/#stopping-and-disabling-services", 
            "text": "To stop the services:    To stop OpenSSH you can use: \\ pre class=\u201crootscreen\u201d>  service gsisshd stop    In addition, you can disable services by running the following commands. However, you don't need to do this normally.    Optionally, to disable OpenSSH:  chkconfig gsisshd off", 
            "title": "Stopping and Disabling Services"
        }, 
        {
            "location": "/other/gsissh/#troubleshooting", 
            "text": "You can get information on troubleshooting errors on the  NCSA page .  To troubleshoot LCMAPS authorization, you can add the following to  /etc/sysconfig/gsisshd  and choose a higher debug level:  # level 0: no messages, 1: errors, 2: also warnings, 3: also notices,\n#  4: also info, 5: maximum debug\nLCMAPS_DEBUG_LEVEL=2  Output goes to  /var/log/messages  by default.", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/other/gsissh/#test-gsi-openssh", 
            "text": "After starting the  gsisshd  service you can check if it is running correctly  $ grid-proxy-init\nYour identity: /DC = ch/DC = cern/OU = Organic Units/OU = Users/CN = User Name\nEnter GRID pass phrase  for  this identity:\nCreating proxy ............................................................................................... Done\nYour proxy is valid  until : Sat Apr  23   08 :18:27  2016 \n$ gsissh localhost -p  2222 \nLast login: Tue Sep  18   16 :08:03  2012  from itb4.uchicago.edu\n$", 
            "title": "Test GSI OpenSSH"
        }, 
        {
            "location": "/other/gsissh/#how-to-get-help", 
            "text": "To get assistance please use this  Help Procedure .", 
            "title": "How to get Help?"
        }, 
        {
            "location": "/client/cvmfs/", 
            "text": "Install CVMFS\n\n\nHere we describe how to install the \nCVMFS\n (Cern-VM file system) client.\nThis document is intended for system administrators who wish to install this client to have access to files distributed\nby cvmfs servers via HTTP.\n\n\n\n\nApplicable versions\n\n\nThe applicable software versions for this document are OSG Version \n= 3.2.22.\nThe version of cvmfs installed should be \n= 2.1.20-1.osg or greater.\n\n\n\n\nRequirements\n\n\nHost and OS\n\n\n\n\nOS is RedHat 5, 6, 7 or variants\n\n\nroot\n access\n\n\nautofs\n should be installed\n\n\nfuse\n should be installed (or will be as part of the installation)\n\n\nSufficient (~20GB+20%) cache space reserved, preferably in a separate filesystem (details \nbelow\n)\n\n\n\n\nUsers and Groups\n\n\nThis installation will create one user unless it already exists:\n\n\n\n\n\n\n\n\nUser\n\n\nComment\n\n\n\n\n\n\n\n\n\n\ncvmfs\n\n\nCernVM-FS service account\n\n\n\n\n\n\n\n\nThe installation will also create a cvmfs group and default the cvmfs user to that group. In addition, if the fuse rpm is not for some reason already installed, installing cvmfs will also install fuse and that will create another group:\n\n\n\n\n\n\n\n\nGroup\n\n\nComment\n\n\nGroup members\n\n\n\n\n\n\n\n\n\n\ncvmfs\n\n\nCernVM-FS service account\n\n\nnone\n\n\n\n\n\n\nfuse\n\n\nFUSE service account\n\n\ncvmfs\n\n\n\n\n\n\n\n\nNetworking\n\n\nYou will need network access to a local squid server such as the \nsquid distributed by OSG\n. The squid will need out-bound access to cvmfs stratum 1 servers.\n\n\nUpgrading\n\n\nWhen upgrading to cvmfs 2.1.20, delete the setting of \nCVMFS_SERVER_URL\n in \n/etc/cvmfs/domain.d/cern.ch.local\n. If that's the only thing in the file (which is likely) then delete the whole file.\n\n\nWhen upgrading from a cvmfs 2.0.X version, all \n/cvmfs\n repositories must be unmounted in order to upgrade. When upgrading between 2.1.X versions, repositories may be mounted.\n\n\nNote that version 2.1 removed the \n/etc/init.d/cvmfs\n script. Starting it didn't actually do anything anyway (it is automatically starts when mounted), and the stop function has been moved to \ncvmfs_config umount\n.\nThe \nrestartautofs\n function is instead done by \nservice autofs restart\n. The \nprobe\n function has also been moved to \ncvmfs_config probe\n. Since 2.1.X enables shared cache by default, so in order to reclaim the previous cache space when upgrading from 2.0.X you must manually remove the old caches. For example\n\n\nrm -rf /var/cache/cvmfs/*.*\n\n\n\n\n\nInstall Instructions\n\n\nPrior to installing CVMFS, make sure the \nyum repositories\n are correctly configured for OSG.\n\n\nThe following will install cvmfs from the OSG repository. It will also install cern public keys as well as fuse and autofs if you do not have them, and it will install the configuration for the OSG CVMFS distribution, OASIS.\n\n\nyum install osg-oasis\n\n\n\n\n\nCreate or edit \n/etc/fuse.conf\n. It should contain the following in order to allow fuse to do proper file ownership:\n\n\nuser_allow_other\n\n\n\n\n\nCreate or edit \n/etc/auto.master\n. It should contain the following in order to allow cvmfs to automount:\n\n\n/cvmfs /etc/auto.cvmfs\n\n\n\n\n\nRestart autofs to make the change take effect:\n\n\nservice autofs restart\nStopping automount:                       [  OK  ]\nStarting automount:                       [  OK  ]\n\n\n\n\n\nCreate or edit \n/etc/cvmfs/default.local\n, a file that controls the cvmfs configuration.\nBelow is a sample configuration, \nbut please note\n that you will need to customize this for your site. (In particular, the \nCVMFS_HTTP_PROXY\n line below only works within the .fnal.gov domain.)\n\n\nCVMFS_REPOSITORIES=\n`echo $((echo oasis.opensciencegrid.org;echo cms.cern.ch;ls /cvmfs)|sort -u)|tr \n \n ,`\n\nCVMFS_CACHE_BASE=/var/cache/cvmfs\nCVMFS_QUOTA_LIMIT=20000\nCVMFS_HTTP_PROXY=\nhttp://squid.fnal.gov:3128\n\n\n\n\n\n\nCVMFS 2.1 by default allows any repository to be mounted. The recommended CVMFS_REPOSITORIES setting is what it is above so that tools such as \ncvmfs_config\n and \ncvmfs_talk\n that use known repositories will use two common repositories plus any additional that have been mounted. You may want to choose a different set of always-known repositories. A full list of cern.ch repositories is found at \nhttp://cernvm.cern.ch/portal/cvmfs/examples\n. The only opensciencegrid.org repository is currently oasis.\n\n\nSet up a list of cvmfs HTTP proxies to retrieve from in CVMFS_HTTP_PROXY. Vertical bars separating proxies means to load balance between them and try them all before continuing. A semicolon between proxies means to try that one only after the previous ones have failed. A special proxy called DIRECT can be placed last in the list to indicate directly connecting to servers if all other proxies fail. This is acceptable for small sites but discouraged for large sites because of the potential load that could be put upon the stratum one servers.\n\n\nSet up the cache limit in \nCVMFS_QUOTA_LIMIT\n (in MB). Recommended for most applications is 20GB. This is the combined limit for all repositories. This cache will be stored in \n$CVMFS_CACHE_BASE\n. Make sure that at least 20% more than that amount of space stays available for cvmfs in that filesystem. This is very important, since if that space is not available it can cause many I/O errors and application crashes. Many system administrators choose to put the cache space in a separate filesystem.\n\n\nVerifying cvmfs\n\n\nAfter CVMFS is installed, you should be able to see the \n/cvmfs\n directory. But note that it will initially appear to be empty:\n\n\n$ ls /cvmfs\n\n\n\n\n\nDirectories within \n/cvmfs\n will not be mounted until you examine them. For instance:\n\n\n# ls -l /cvmfs/atlas.cern.ch\n/cvmfs/atlas.cern.ch:\ntotal 5\ndrwxr-xr-x 1 cvmfs cvmfs 4096 Mar  5  2012 repo\n# ls -l /cvmfs/oasis.opensciencegrid.org/cmssoft\n/cvmfs/oasis.opensciencegrid.org/cmssoft:\ntotal 1\nlrwxrwxrwx 1 cvmfs cvmfs 18 May 28 10:33 cms -\n /cvmfs/cms.cern.ch\n# ls -l /cvmfs/glast.egi.eu\ntotal 5\ndrwxr-xr-x 9 cvmfs cvmfs 4096 Feb  7  2014 glast\n# ls /cvmfs\natlas.cern.ch  cms.cern.ch  glast.egi.eu  oasis.opensciencegrid.org\n\n\n\n\n\nTroubleshooting problems\n\n\nIf no directories exist under \n/cvmfs/\n, you can try the following steps to debug:\n\n\n\n\nMount it manually \nmkdir /mnt/cvmfs\n then \nmount -t cvmfs REPOSITORYNAME /mnt/cvmfs\n where \nREPOSITORYNAME\n is the repository, for example \noasis.opensciencegrid.org\n. If this works, then cvmfs is working, but there is a problem with automount.\n\n\nIf that doesn't work and doesn't give any explanatory errors, try \ncvmfs_config chksetup\n or \ncvmfs_config showconfig REPOSITORYNAME\n to verify your setup.\n\n\nIf chksetup reports access problems to proxies, it may be caused by access control settings in the squids.\n\n\nIf you have changed settings in \n/etc/cvmfs/default.local\n, and they do not seem to be taking effect, note that there are other configuration files that can override the settings. See the comments at the beginning of \n/etc/cvmfs/default.conf\n regarding the order in which configuration files are evaluated and look for old files that may have been left from a previous installation.\n\n\nMore things to try are in the \nupstream documentation\n.\n\n\n\n\nStarting and Stopping services\n\n\nOnce it is set up, cvmfs is always automatically started when one of the repositories are accessed.\n\n\ncvmfs can be stopped via:\n\n\n# cvmfs_config umount\nUnmounting /cvmfs/atlas.cern.ch: OK\nUnmounting /cvmfs/oasis.opensciencegrid.org: OK\nUnmounting /cvmfs/cms.cern.ch: OK\nUnmounting /cvmfs/glast.egi.eu: OK\n\n\n\n\n\nScreendump of Install\n\n\n[root@fermicloud044 ~]# rpm -Uvh http://download.fedoraproject.org/pub/epel/6/i386/epel-release-6-8.noarch.rpm\nRetrieving http://download.fedoraproject.org/pub/epel/6/i386/epel-release-6-8.noarch.rpm\nPreparing...                ########################################### [100%]\n   1:epel-release           ########################################### [100%]\n[root@fermicloud044 ~]# yum install yum-priorities\nLoaded plugins: security\nepel/metalink                                            |  15 kB     00:00     \nepel                                                     | 4.4 kB     00:00     \nepel/primary_db                                          | 6.5 MB     00:02     \nSetting up Install Process\nResolving Dependencies\n--\n Running transaction check\n---\n Package yum-plugin-priorities.noarch 0:1.1.30-14.el6 will be installed\n--\n Finished Dependency Resolution\n\nDependencies Resolved\n\n================================================================================\n Package                     Arch         Version               Repository\n                                                                           Size\n================================================================================\nInstalling:\n yum-plugin-priorities       noarch       1.1.30-14.el6         slf        21 k\n\nTransaction Summary\n================================================================================\nInstall       1 Package(s)\n\nTotal download size: 21 k\nInstalled size: 28 k\nIs this ok [y/N]: y\nDownloading Packages:\nyum-plugin-priorities-1.1.30-14.el6.noarch.rpm           |  21 kB     00:00     \nRunning rpm_check_debug\nRunning Transaction Test\nTransaction Test Succeeded\nRunning Transaction\n  Installing : yum-plugin-priorities-1.1.30-14.el6.noarch                   1/1 \n  Verifying  : yum-plugin-priorities-1.1.30-14.el6.noarch                   1/1 \n\nInstalled:\n  yum-plugin-priorities.noarch 0:1.1.30-14.el6                                  \n\nComplete!\n[root@fermicloud044 ~]# grep plugins /etc/yum.conf\nplugins=1\n[root@fermicloud044 ~]# rpm -Uvh http://repo.grid.iu.edu/osg/3.2/osg-3.2-el6-release-latest.rpm\nRetrieving http://repo.grid.iu.edu/osg/3.2/osg-3.2-el6-release-latest.rpm\nwarning: /var/tmp/rpm-tmp.C1YSbQ: Header V3 DSA/SHA1 Signature, key ID 824b8603: NOKEY\nPreparing...                ########################################### [100%]\n   1:osg-release            ########################################### [100%]\n[root@fermicloud044 ~]# yum install osg-oasis\nLoaded plugins: priorities, security\nosg                                                      | 1.9 kB     00:00     \nosg/primary_db                                           | 1.9 MB     00:00     \n342 packages excluded due to repository priority protections\nSetting up Install Process\nResolving Dependencies\n--\n Running transaction check\n---\n Package osg-oasis.noarch 0:5-1.osg32.el6 will be installed\n--\n Processing Dependency: cvmfs-config-osg \n= 1.1 for package: osg-oasis-5-1.osg32.el6.noarch\n--\n Processing Dependency: cvmfs \n= 2.1.20 for package: osg-oasis-5-1.osg32.el6.noarch\n--\n Running transaction check\n---\n Package cvmfs.x86_64 0:2.1.20-1.osg32.el6 will be installed\n--\n Processing Dependency: libfuse.so.2(FUSE_2.4)(64bit) for package: cvmfs-2.1.20-1.osg32.el6.x86_64\n--\n Processing Dependency: /usr/sbin/semanage for package: cvmfs-2.1.20-1.osg32.el6.x86_64\n--\n Processing Dependency: libfuse.so.2(FUSE_2.6)(64bit) for package: cvmfs-2.1.20-1.osg32.el6.x86_64\n--\n Processing Dependency: fuse-libs for package: cvmfs-2.1.20-1.osg32.el6.x86_64\n--\n Processing Dependency: gdb for package: cvmfs-2.1.20-1.osg32.el6.x86_64\n--\n Processing Dependency: libfuse.so.2(FUSE_2.5)(64bit) for package: cvmfs-2.1.20-1.osg32.el6.x86_64\n--\n Processing Dependency: fuse for package: cvmfs-2.1.20-1.osg32.el6.x86_64\n--\n Processing Dependency: libfuse.so.2()(64bit) for package: cvmfs-2.1.20-1.osg32.el6.x86_64\n---\n Package cvmfs-config-osg.noarch 0:1.1-5.osg32.el6 will be installed\n--\n Running transaction check\n---\n Package fuse.x86_64 0:2.8.3-4.el6 will be installed\n---\n Package fuse-libs.x86_64 0:2.8.3-4.el6 will be installed\n---\n Package gdb.x86_64 0:7.2-60.el6 will be installed\n---\n Package policycoreutils-python.x86_64 0:2.0.83-19.30.el6 will be installed\n--\n Processing Dependency: libsemanage-python \n= 2.0.43-4 for package: policycoreutils-python-2.0.83-19.30.el6.x86_64\n--\n Processing Dependency: audit-libs-python \n= 1.4.2-1 for package: policycoreutils-python-2.0.83-19.30.el6.x86_64\n--\n Processing Dependency: setools-libs-python for package: policycoreutils-python-2.0.83-19.30.el6.x86_64\n--\n Processing Dependency: libselinux-python for package: policycoreutils-python-2.0.83-19.30.el6.x86_64\n--\n Processing Dependency: libcgroup for package: policycoreutils-python-2.0.83-19.30.el6.x86_64\n--\n Running transaction check\n---\n Package audit-libs-python.x86_64 0:2.2-2.el6 will be installed\n---\n Package libcgroup.x86_64 0:0.37-7.el6 will be installed\n---\n Package libselinux-python.x86_64 0:2.0.94-5.3.el6 will be installed\n---\n Package libsemanage-python.x86_64 0:2.0.43-4.2.el6 will be installed\n---\n Package setools-libs-python.x86_64 0:3.3.7-4.el6 will be installed\n--\n Processing Dependency: setools-libs = 3.3.7-4.el6 for package: setools-libs-python-3.3.7-4.el6.x86_64\n--\n Processing Dependency: libqpol.so.1(VERS_1.3)(64bit) for package: setools-libs-python-3.3.7-4.el6.x86_64\n--\n Processing Dependency: libpoldiff.so.1(VERS_1.3)(64bit) for package: setools-libs-python-3.3.7-4.el6.x86_64\n--\n Processing Dependency: libapol.so.4(VERS_4.1)(64bit) for package: setools-libs-python-3.3.7-4.el6.x86_64\n--\n Processing Dependency: libqpol.so.1(VERS_1.2)(64bit) for package: setools-libs-python-3.3.7-4.el6.x86_64\n--\n Processing Dependency: libqpol.so.1(VERS_1.4)(64bit) for package: setools-libs-python-3.3.7-4.el6.x86_64\n--\n Processing Dependency: libseaudit.so.4(VERS_4.2)(64bit) for package: setools-libs-python-3.3.7-4.el6.x86_64\n--\n Processing Dependency: libpoldiff.so.1(VERS_1.2)(64bit) for package: setools-libs-python-3.3.7-4.el6.x86_64\n--\n Processing Dependency: libsefs.so.4(VERS_4.0)(64bit) for package: setools-libs-python-3.3.7-4.el6.x86_64\n--\n Processing Dependency: libapol.so.4(VERS_4.0)(64bit) for package: setools-libs-python-3.3.7-4.el6.x86_64\n--\n Processing Dependency: libseaudit.so.4(VERS_4.1)(64bit) for package: setools-libs-python-3.3.7-4.el6.x86_64\n--\n Processing Dependency: libseaudit.so.4()(64bit) for package: setools-libs-python-3.3.7-4.el6.x86_64\n--\n Processing Dependency: libqpol.so.1()(64bit) for package: setools-libs-python-3.3.7-4.el6.x86_64\n--\n Processing Dependency: libapol.so.4()(64bit) for package: setools-libs-python-3.3.7-4.el6.x86_64\n--\n Processing Dependency: libpoldiff.so.1()(64bit) for package: setools-libs-python-3.3.7-4.el6.x86_64\n--\n Processing Dependency: libsefs.so.4()(64bit) for package: setools-libs-python-3.3.7-4.el6.x86_64\n--\n Running transaction check\n---\n Package setools-libs.x86_64 0:3.3.7-4.el6 will be installed\n--\n Finished Dependency Resolution\n\nDependencies Resolved\n\n================================================================================\n Package                     Arch        Version                 Repository\n                                                                           Size\n================================================================================\nInstalling:\n osg-oasis                   noarch      5-1.osg32.el6           osg      2.4 k\nInstalling for dependencies:\n audit-libs-python           x86_64      2.2-2.el6               slf       58 k\n cvmfs                       x86_64      2.1.20-1.osg32.el6      osg      5.9 M\n cvmfs-config-osg            noarch      1.1-5.osg32.el6         osg      8.0 k\n fuse                        x86_64      2.8.3-4.el6             slf       70 k\n fuse-libs                   x86_64      2.8.3-4.el6             slf       73 k\n gdb                         x86_64      7.2-60.el6              slf      2.3 M\n libcgroup                   x86_64      0.37-7.el6              slf      110 k\n libselinux-python           x86_64      2.0.94-5.3.el6          slf      201 k\n libsemanage-python          x86_64      2.0.43-4.2.el6          slf       80 k\n policycoreutils-python      x86_64      2.0.83-19.30.el6        slf      341 k\n setools-libs                x86_64      3.3.7-4.el6             slf      399 k\n setools-libs-python         x86_64      3.3.7-4.el6             slf      221 k\n\nTransaction Summary\n================================================================================\nInstall      13 Package(s)\n\nTotal download size: 9.8 M\nInstalled size: 35 M\nIs this ok [y/N]: y\nDownloading Packages:\n(1/13): audit-libs-python-2.2-2.el6.x86_64.rpm           |  58 kB     00:00     \n(2/13): cvmfs-2.1.20-1.osg32.el6.x86_64.rpm              | 5.9 MB     00:00     \n(3/13): cvmfs-config-osg-1.1-5.osg32.el6.noarch.rpm      | 8.0 kB     00:00     \n(4/13): fuse-2.8.3-4.el6.x86_64.rpm                      |  70 kB     00:00     \n(5/13): fuse-libs-2.8.3-4.el6.x86_64.rpm                 |  73 kB     00:00     \n(6/13): gdb-7.2-60.el6.x86_64.rpm                        | 2.3 MB     00:00     \n(7/13): libcgroup-0.37-7.el6.x86_64.rpm                  | 110 kB     00:00     \n(8/13): libselinux-python-2.0.94-5.3.el6.x86_64.rpm      | 201 kB     00:00     \n(9/13): libsemanage-python-2.0.43-4.2.el6.x86_64.rpm     |  80 kB     00:00     \n(10/13): osg-oasis-5-1.osg32.el6.noarch.rpm              | 2.4 kB     00:00     \n(11/13): policycoreutils-python-2.0.83-19.30.el6.x86_64. | 341 kB     00:00     \n(12/13): setools-libs-3.3.7-4.el6.x86_64.rpm             | 399 kB     00:00     \n(13/13): setools-libs-python-3.3.7-4.el6.x86_64.rpm      | 221 kB     00:00     \n--------------------------------------------------------------------------------\nTotal                                           9.7 MB/s | 9.8 MB     00:01     \nwarning: rpmts_HdrFromFdno: Header V4 DSA/SHA1 Signature, key ID 824b8603: NOKEY\nRetrieving key from file:///etc/pki/rpm-gpg/RPM-GPG-KEY-OSG\nImporting GPG key 0x824B8603:\n Userid : OSG Software Team (RPM Signing Key for Koji Packages) \nvdt-support@opensciencegrid.org\n\n Package: osg-release-3.2-7.osg32.el6.noarch (installed)\n From   : /etc/pki/rpm-gpg/RPM-GPG-KEY-OSG\nIs this ok [y/N]: y\nRunning rpm_check_debug\nRunning Transaction Test\nTransaction Test Succeeded\nRunning Transaction\nWarning: RPMDB altered outside of yum.\n  Installing : cvmfs-config-osg-1.1-5.osg32.el6.noarch                     1/13 \n  Installing : setools-libs-3.3.7-4.el6.x86_64                             2/13 \n  Installing : setools-libs-python-3.3.7-4.el6.x86_64                      3/13 \n  Installing : fuse-libs-2.8.3-4.el6.x86_64                                4/13 \n  Installing : libsemanage-python-2.0.43-4.2.el6.x86_64                    5/13 \n  Installing : gdb-7.2-60.el6.x86_64                                       6/13 \n  Installing : fuse-2.8.3-4.el6.x86_64                                     7/13 \n  Installing : audit-libs-python-2.2-2.el6.x86_64                          8/13 \n  Installing : libselinux-python-2.0.94-5.3.el6.x86_64                     9/13 \n  Installing : libcgroup-0.37-7.el6.x86_64                                10/13 \n  Installing : policycoreutils-python-2.0.83-19.30.el6.x86_64             11/13 \n  Installing : cvmfs-2.1.20-1.osg32.el6.x86_64                            12/13 \n  Installing : osg-oasis-5-1.osg32.el6.noarch                             13/13 \n  Verifying  : libcgroup-0.37-7.el6.x86_64                                 1/13 \n  Verifying  : libselinux-python-2.0.94-5.3.el6.x86_64                     2/13 \n  Verifying  : audit-libs-python-2.2-2.el6.x86_64                          3/13 \n  Verifying  : policycoreutils-python-2.0.83-19.30.el6.x86_64              4/13 \n  Verifying  : fuse-2.8.3-4.el6.x86_64                                     5/13 \n  Verifying  : cvmfs-config-osg-1.1-5.osg32.el6.noarch                     6/13 \n  Verifying  : setools-libs-python-3.3.7-4.el6.x86_64                      7/13 \n  Verifying  : gdb-7.2-60.el6.x86_64                                       8/13 \n  Verifying  : osg-oasis-5-1.osg32.el6.noarch                              9/13 \n  Verifying  : libsemanage-python-2.0.43-4.2.el6.x86_64                   10/13 \n  Verifying  : cvmfs-2.1.20-1.osg32.el6.x86_64                            11/13 \n  Verifying  : fuse-libs-2.8.3-4.el6.x86_64                               12/13 \n  Verifying  : setools-libs-3.3.7-4.el6.x86_64                            13/13 \n\nInstalled:\n  osg-oasis.noarch 0:5-1.osg32.el6                                              \n\nDependency Installed:\n  audit-libs-python.x86_64 0:2.2-2.el6                                          \n  cvmfs.x86_64 0:2.1.20-1.osg32.el6                                             \n  cvmfs-config-osg.noarch 0:1.1-5.osg32.el6                                     \n  fuse.x86_64 0:2.8.3-4.el6                                                     \n  fuse-libs.x86_64 0:2.8.3-4.el6                                                \n  gdb.x86_64 0:7.2-60.el6                                                       \n  libcgroup.x86_64 0:0.37-7.el6                                                 \n  libselinux-python.x86_64 0:2.0.94-5.3.el6                                     \n  libsemanage-python.x86_64 0:2.0.43-4.2.el6                                    \n  policycoreutils-python.x86_64 0:2.0.83-19.30.el6                              \n  setools-libs.x86_64 0:3.3.7-4.el6                                             \n  setools-libs-python.x86_64 0:3.3.7-4.el6                                      \n\nComplete!\n[root@fermicloud044 ~]# echo user_allow_other \n/etc/fuse.conf\n[root@fermicloud044 ~]# echo \n/cvmfs /etc/auto.cvmfs\n \n/etc/auto.master\n[root@fermicloud044 ~]# service autofs restart\nStopping automount:                                        [  OK  ]\nStarting automount:                                        [  OK  ]\n[root@fermicloud044 ~]# cat \n/etc/cvmfs/default.local\nCVMFS_REPOSITORIES=\n`echo $((echo oasis.opensciencegrid.org;echo cms.cern.ch;ls /cvmfs)|sort -u)|tr \n \n ,`\n\nCVMFS_CACHE_BASE=/var/cache/cvmfs\nCVMFS_QUOTA_LIMIT=20000\nCVMFS_HTTP_PROXY=\nhttp://squid.fnal.gov:3128\n\n[root@fermicloud044 ~]# ls /cvmfs\n[root@fermicloud044 ~]# ls -l /cvmfs/atlas.cern.ch\ntotal 5\ndrwxr-xr-x 6 cvmfs cvmfs 4096 Sep 12  2014 repo\n[root@fermicloud044 ~]# ls -l /cvmfs/oasis.opensciencegrid.org/cmssoft\ntotal 1\nlrwxrwxrwx 1 cvmfs cvmfs 18 Mar 11  2014 cms -\n /cvmfs/cms.cern.ch\n[root@fermicloud044 ~]# ls -l /cvmfs/glast.egi.eu\ntotal 5\ndrwxr-xr-x 9 cvmfs cvmfs 4096 Feb  7  2014 glast\n[root@fermicloud044 ~]# ls /cvmfs\natlas.cern.ch  cms.cern.ch  glast.egi.eu  oasis.opensciencegrid.org\n[root@fermicloud044 ~]# cvmfs_config umount\nUnmounting /cvmfs/atlas.cern.ch: OK\nUnmounting /cvmfs/oasis.opensciencegrid.org: OK\nUnmounting /cvmfs/cms.cern.ch: OK\nUnmounting /cvmfs/glast.egi.eu: OK\n[root@fermicloud044 ~]# \n\n\n\n\n\nFile Locations\n\n\n\n\n\n\n\n\nService/Process\n\n\nConfiguration File\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ncvmfs\n\n\n/etc/cvmfs/default.local\n\n\ncvmfs environment settings and repository setup\n\n\n\n\n\n\nfuse\n\n\n/etc/fuse.conf\n\n\nfuse settings\n\n\n\n\n\n\nautomount\n\n\n/etc/auto.master\n\n\nautomount settings\n\n\n\n\n\n\n\n\nHow to get Help?\n\n\nIf you cannot resolve the problem, there are several ways to receive help:\n\n\n\n\nFor bug reporting and OSG-specific issues, submit a ticket to the \nGrid Operations Center\n.\n\n\nFor community support and best-effort software team support contact \n.\n\n\nFor general CERN VM FileSystem support contact \n.\n\n\n\n\nFor a full set of help options, see \nHelp Procedure\n.\n\n\nReferences\n\n\n\n\nhttp://cernvm.cern.ch/portal/filesystem/techinformation\n\n\nhttps://ecsft.cern.ch/dist/cvmfs/cvmfstech-2.1-6.pdf", 
            "title": "CVMFS"
        }, 
        {
            "location": "/client/cvmfs/#install-cvmfs", 
            "text": "Here we describe how to install the  CVMFS  (Cern-VM file system) client.\nThis document is intended for system administrators who wish to install this client to have access to files distributed\nby cvmfs servers via HTTP.   Applicable versions  The applicable software versions for this document are OSG Version  = 3.2.22.\nThe version of cvmfs installed should be  = 2.1.20-1.osg or greater.", 
            "title": "Install CVMFS"
        }, 
        {
            "location": "/client/cvmfs/#requirements", 
            "text": "", 
            "title": "Requirements"
        }, 
        {
            "location": "/client/cvmfs/#host-and-os", 
            "text": "OS is RedHat 5, 6, 7 or variants  root  access  autofs  should be installed  fuse  should be installed (or will be as part of the installation)  Sufficient (~20GB+20%) cache space reserved, preferably in a separate filesystem (details  below )", 
            "title": "Host and OS"
        }, 
        {
            "location": "/client/cvmfs/#users-and-groups", 
            "text": "This installation will create one user unless it already exists:     User  Comment      cvmfs  CernVM-FS service account     The installation will also create a cvmfs group and default the cvmfs user to that group. In addition, if the fuse rpm is not for some reason already installed, installing cvmfs will also install fuse and that will create another group:     Group  Comment  Group members      cvmfs  CernVM-FS service account  none    fuse  FUSE service account  cvmfs", 
            "title": "Users and Groups"
        }, 
        {
            "location": "/client/cvmfs/#networking", 
            "text": "You will need network access to a local squid server such as the  squid distributed by OSG . The squid will need out-bound access to cvmfs stratum 1 servers.", 
            "title": "Networking"
        }, 
        {
            "location": "/client/cvmfs/#upgrading", 
            "text": "When upgrading to cvmfs 2.1.20, delete the setting of  CVMFS_SERVER_URL  in  /etc/cvmfs/domain.d/cern.ch.local . If that's the only thing in the file (which is likely) then delete the whole file.  When upgrading from a cvmfs 2.0.X version, all  /cvmfs  repositories must be unmounted in order to upgrade. When upgrading between 2.1.X versions, repositories may be mounted.  Note that version 2.1 removed the  /etc/init.d/cvmfs  script. Starting it didn't actually do anything anyway (it is automatically starts when mounted), and the stop function has been moved to  cvmfs_config umount .\nThe  restartautofs  function is instead done by  service autofs restart . The  probe  function has also been moved to  cvmfs_config probe . Since 2.1.X enables shared cache by default, so in order to reclaim the previous cache space when upgrading from 2.0.X you must manually remove the old caches. For example  rm -rf /var/cache/cvmfs/*.*", 
            "title": "Upgrading"
        }, 
        {
            "location": "/client/cvmfs/#install-instructions", 
            "text": "Prior to installing CVMFS, make sure the  yum repositories  are correctly configured for OSG.  The following will install cvmfs from the OSG repository. It will also install cern public keys as well as fuse and autofs if you do not have them, and it will install the configuration for the OSG CVMFS distribution, OASIS.  yum install osg-oasis  Create or edit  /etc/fuse.conf . It should contain the following in order to allow fuse to do proper file ownership:  user_allow_other  Create or edit  /etc/auto.master . It should contain the following in order to allow cvmfs to automount:  /cvmfs /etc/auto.cvmfs  Restart autofs to make the change take effect:  service autofs restart\nStopping automount:                       [  OK  ]\nStarting automount:                       [  OK  ]  Create or edit  /etc/cvmfs/default.local , a file that controls the cvmfs configuration.\nBelow is a sample configuration,  but please note  that you will need to customize this for your site. (In particular, the  CVMFS_HTTP_PROXY  line below only works within the .fnal.gov domain.)  CVMFS_REPOSITORIES= `echo $((echo oasis.opensciencegrid.org;echo cms.cern.ch;ls /cvmfs)|sort -u)|tr     ,` \nCVMFS_CACHE_BASE=/var/cache/cvmfs\nCVMFS_QUOTA_LIMIT=20000\nCVMFS_HTTP_PROXY= http://squid.fnal.gov:3128   CVMFS 2.1 by default allows any repository to be mounted. The recommended CVMFS_REPOSITORIES setting is what it is above so that tools such as  cvmfs_config  and  cvmfs_talk  that use known repositories will use two common repositories plus any additional that have been mounted. You may want to choose a different set of always-known repositories. A full list of cern.ch repositories is found at  http://cernvm.cern.ch/portal/cvmfs/examples . The only opensciencegrid.org repository is currently oasis.  Set up a list of cvmfs HTTP proxies to retrieve from in CVMFS_HTTP_PROXY. Vertical bars separating proxies means to load balance between them and try them all before continuing. A semicolon between proxies means to try that one only after the previous ones have failed. A special proxy called DIRECT can be placed last in the list to indicate directly connecting to servers if all other proxies fail. This is acceptable for small sites but discouraged for large sites because of the potential load that could be put upon the stratum one servers.  Set up the cache limit in  CVMFS_QUOTA_LIMIT  (in MB). Recommended for most applications is 20GB. This is the combined limit for all repositories. This cache will be stored in  $CVMFS_CACHE_BASE . Make sure that at least 20% more than that amount of space stays available for cvmfs in that filesystem. This is very important, since if that space is not available it can cause many I/O errors and application crashes. Many system administrators choose to put the cache space in a separate filesystem.", 
            "title": "Install Instructions"
        }, 
        {
            "location": "/client/cvmfs/#verifying-cvmfs", 
            "text": "After CVMFS is installed, you should be able to see the  /cvmfs  directory. But note that it will initially appear to be empty:  $ ls /cvmfs  Directories within  /cvmfs  will not be mounted until you examine them. For instance:  # ls -l /cvmfs/atlas.cern.ch\n/cvmfs/atlas.cern.ch:\ntotal 5\ndrwxr-xr-x 1 cvmfs cvmfs 4096 Mar  5  2012 repo\n# ls -l /cvmfs/oasis.opensciencegrid.org/cmssoft\n/cvmfs/oasis.opensciencegrid.org/cmssoft:\ntotal 1\nlrwxrwxrwx 1 cvmfs cvmfs 18 May 28 10:33 cms -  /cvmfs/cms.cern.ch\n# ls -l /cvmfs/glast.egi.eu\ntotal 5\ndrwxr-xr-x 9 cvmfs cvmfs 4096 Feb  7  2014 glast\n# ls /cvmfs\natlas.cern.ch  cms.cern.ch  glast.egi.eu  oasis.opensciencegrid.org", 
            "title": "Verifying cvmfs"
        }, 
        {
            "location": "/client/cvmfs/#troubleshooting-problems", 
            "text": "If no directories exist under  /cvmfs/ , you can try the following steps to debug:   Mount it manually  mkdir /mnt/cvmfs  then  mount -t cvmfs REPOSITORYNAME /mnt/cvmfs  where  REPOSITORYNAME  is the repository, for example  oasis.opensciencegrid.org . If this works, then cvmfs is working, but there is a problem with automount.  If that doesn't work and doesn't give any explanatory errors, try  cvmfs_config chksetup  or  cvmfs_config showconfig REPOSITORYNAME  to verify your setup.  If chksetup reports access problems to proxies, it may be caused by access control settings in the squids.  If you have changed settings in  /etc/cvmfs/default.local , and they do not seem to be taking effect, note that there are other configuration files that can override the settings. See the comments at the beginning of  /etc/cvmfs/default.conf  regarding the order in which configuration files are evaluated and look for old files that may have been left from a previous installation.  More things to try are in the  upstream documentation .", 
            "title": "Troubleshooting problems"
        }, 
        {
            "location": "/client/cvmfs/#starting-and-stopping-services", 
            "text": "Once it is set up, cvmfs is always automatically started when one of the repositories are accessed.  cvmfs can be stopped via:  # cvmfs_config umount\nUnmounting /cvmfs/atlas.cern.ch: OK\nUnmounting /cvmfs/oasis.opensciencegrid.org: OK\nUnmounting /cvmfs/cms.cern.ch: OK\nUnmounting /cvmfs/glast.egi.eu: OK", 
            "title": "Starting and Stopping services"
        }, 
        {
            "location": "/client/cvmfs/#screendump-of-install", 
            "text": "[root@fermicloud044 ~]# rpm -Uvh http://download.fedoraproject.org/pub/epel/6/i386/epel-release-6-8.noarch.rpm\nRetrieving http://download.fedoraproject.org/pub/epel/6/i386/epel-release-6-8.noarch.rpm\nPreparing...                ########################################### [100%]\n   1:epel-release           ########################################### [100%]\n[root@fermicloud044 ~]# yum install yum-priorities\nLoaded plugins: security\nepel/metalink                                            |  15 kB     00:00     \nepel                                                     | 4.4 kB     00:00     \nepel/primary_db                                          | 6.5 MB     00:02     \nSetting up Install Process\nResolving Dependencies\n--  Running transaction check\n---  Package yum-plugin-priorities.noarch 0:1.1.30-14.el6 will be installed\n--  Finished Dependency Resolution\n\nDependencies Resolved\n\n================================================================================\n Package                     Arch         Version               Repository\n                                                                           Size\n================================================================================\nInstalling:\n yum-plugin-priorities       noarch       1.1.30-14.el6         slf        21 k\n\nTransaction Summary\n================================================================================\nInstall       1 Package(s)\n\nTotal download size: 21 k\nInstalled size: 28 k\nIs this ok [y/N]: y\nDownloading Packages:\nyum-plugin-priorities-1.1.30-14.el6.noarch.rpm           |  21 kB     00:00     \nRunning rpm_check_debug\nRunning Transaction Test\nTransaction Test Succeeded\nRunning Transaction\n  Installing : yum-plugin-priorities-1.1.30-14.el6.noarch                   1/1 \n  Verifying  : yum-plugin-priorities-1.1.30-14.el6.noarch                   1/1 \n\nInstalled:\n  yum-plugin-priorities.noarch 0:1.1.30-14.el6                                  \n\nComplete!\n[root@fermicloud044 ~]# grep plugins /etc/yum.conf\nplugins=1\n[root@fermicloud044 ~]# rpm -Uvh http://repo.grid.iu.edu/osg/3.2/osg-3.2-el6-release-latest.rpm\nRetrieving http://repo.grid.iu.edu/osg/3.2/osg-3.2-el6-release-latest.rpm\nwarning: /var/tmp/rpm-tmp.C1YSbQ: Header V3 DSA/SHA1 Signature, key ID 824b8603: NOKEY\nPreparing...                ########################################### [100%]\n   1:osg-release            ########################################### [100%]\n[root@fermicloud044 ~]# yum install osg-oasis\nLoaded plugins: priorities, security\nosg                                                      | 1.9 kB     00:00     \nosg/primary_db                                           | 1.9 MB     00:00     \n342 packages excluded due to repository priority protections\nSetting up Install Process\nResolving Dependencies\n--  Running transaction check\n---  Package osg-oasis.noarch 0:5-1.osg32.el6 will be installed\n--  Processing Dependency: cvmfs-config-osg  = 1.1 for package: osg-oasis-5-1.osg32.el6.noarch\n--  Processing Dependency: cvmfs  = 2.1.20 for package: osg-oasis-5-1.osg32.el6.noarch\n--  Running transaction check\n---  Package cvmfs.x86_64 0:2.1.20-1.osg32.el6 will be installed\n--  Processing Dependency: libfuse.so.2(FUSE_2.4)(64bit) for package: cvmfs-2.1.20-1.osg32.el6.x86_64\n--  Processing Dependency: /usr/sbin/semanage for package: cvmfs-2.1.20-1.osg32.el6.x86_64\n--  Processing Dependency: libfuse.so.2(FUSE_2.6)(64bit) for package: cvmfs-2.1.20-1.osg32.el6.x86_64\n--  Processing Dependency: fuse-libs for package: cvmfs-2.1.20-1.osg32.el6.x86_64\n--  Processing Dependency: gdb for package: cvmfs-2.1.20-1.osg32.el6.x86_64\n--  Processing Dependency: libfuse.so.2(FUSE_2.5)(64bit) for package: cvmfs-2.1.20-1.osg32.el6.x86_64\n--  Processing Dependency: fuse for package: cvmfs-2.1.20-1.osg32.el6.x86_64\n--  Processing Dependency: libfuse.so.2()(64bit) for package: cvmfs-2.1.20-1.osg32.el6.x86_64\n---  Package cvmfs-config-osg.noarch 0:1.1-5.osg32.el6 will be installed\n--  Running transaction check\n---  Package fuse.x86_64 0:2.8.3-4.el6 will be installed\n---  Package fuse-libs.x86_64 0:2.8.3-4.el6 will be installed\n---  Package gdb.x86_64 0:7.2-60.el6 will be installed\n---  Package policycoreutils-python.x86_64 0:2.0.83-19.30.el6 will be installed\n--  Processing Dependency: libsemanage-python  = 2.0.43-4 for package: policycoreutils-python-2.0.83-19.30.el6.x86_64\n--  Processing Dependency: audit-libs-python  = 1.4.2-1 for package: policycoreutils-python-2.0.83-19.30.el6.x86_64\n--  Processing Dependency: setools-libs-python for package: policycoreutils-python-2.0.83-19.30.el6.x86_64\n--  Processing Dependency: libselinux-python for package: policycoreutils-python-2.0.83-19.30.el6.x86_64\n--  Processing Dependency: libcgroup for package: policycoreutils-python-2.0.83-19.30.el6.x86_64\n--  Running transaction check\n---  Package audit-libs-python.x86_64 0:2.2-2.el6 will be installed\n---  Package libcgroup.x86_64 0:0.37-7.el6 will be installed\n---  Package libselinux-python.x86_64 0:2.0.94-5.3.el6 will be installed\n---  Package libsemanage-python.x86_64 0:2.0.43-4.2.el6 will be installed\n---  Package setools-libs-python.x86_64 0:3.3.7-4.el6 will be installed\n--  Processing Dependency: setools-libs = 3.3.7-4.el6 for package: setools-libs-python-3.3.7-4.el6.x86_64\n--  Processing Dependency: libqpol.so.1(VERS_1.3)(64bit) for package: setools-libs-python-3.3.7-4.el6.x86_64\n--  Processing Dependency: libpoldiff.so.1(VERS_1.3)(64bit) for package: setools-libs-python-3.3.7-4.el6.x86_64\n--  Processing Dependency: libapol.so.4(VERS_4.1)(64bit) for package: setools-libs-python-3.3.7-4.el6.x86_64\n--  Processing Dependency: libqpol.so.1(VERS_1.2)(64bit) for package: setools-libs-python-3.3.7-4.el6.x86_64\n--  Processing Dependency: libqpol.so.1(VERS_1.4)(64bit) for package: setools-libs-python-3.3.7-4.el6.x86_64\n--  Processing Dependency: libseaudit.so.4(VERS_4.2)(64bit) for package: setools-libs-python-3.3.7-4.el6.x86_64\n--  Processing Dependency: libpoldiff.so.1(VERS_1.2)(64bit) for package: setools-libs-python-3.3.7-4.el6.x86_64\n--  Processing Dependency: libsefs.so.4(VERS_4.0)(64bit) for package: setools-libs-python-3.3.7-4.el6.x86_64\n--  Processing Dependency: libapol.so.4(VERS_4.0)(64bit) for package: setools-libs-python-3.3.7-4.el6.x86_64\n--  Processing Dependency: libseaudit.so.4(VERS_4.1)(64bit) for package: setools-libs-python-3.3.7-4.el6.x86_64\n--  Processing Dependency: libseaudit.so.4()(64bit) for package: setools-libs-python-3.3.7-4.el6.x86_64\n--  Processing Dependency: libqpol.so.1()(64bit) for package: setools-libs-python-3.3.7-4.el6.x86_64\n--  Processing Dependency: libapol.so.4()(64bit) for package: setools-libs-python-3.3.7-4.el6.x86_64\n--  Processing Dependency: libpoldiff.so.1()(64bit) for package: setools-libs-python-3.3.7-4.el6.x86_64\n--  Processing Dependency: libsefs.so.4()(64bit) for package: setools-libs-python-3.3.7-4.el6.x86_64\n--  Running transaction check\n---  Package setools-libs.x86_64 0:3.3.7-4.el6 will be installed\n--  Finished Dependency Resolution\n\nDependencies Resolved\n\n================================================================================\n Package                     Arch        Version                 Repository\n                                                                           Size\n================================================================================\nInstalling:\n osg-oasis                   noarch      5-1.osg32.el6           osg      2.4 k\nInstalling for dependencies:\n audit-libs-python           x86_64      2.2-2.el6               slf       58 k\n cvmfs                       x86_64      2.1.20-1.osg32.el6      osg      5.9 M\n cvmfs-config-osg            noarch      1.1-5.osg32.el6         osg      8.0 k\n fuse                        x86_64      2.8.3-4.el6             slf       70 k\n fuse-libs                   x86_64      2.8.3-4.el6             slf       73 k\n gdb                         x86_64      7.2-60.el6              slf      2.3 M\n libcgroup                   x86_64      0.37-7.el6              slf      110 k\n libselinux-python           x86_64      2.0.94-5.3.el6          slf      201 k\n libsemanage-python          x86_64      2.0.43-4.2.el6          slf       80 k\n policycoreutils-python      x86_64      2.0.83-19.30.el6        slf      341 k\n setools-libs                x86_64      3.3.7-4.el6             slf      399 k\n setools-libs-python         x86_64      3.3.7-4.el6             slf      221 k\n\nTransaction Summary\n================================================================================\nInstall      13 Package(s)\n\nTotal download size: 9.8 M\nInstalled size: 35 M\nIs this ok [y/N]: y\nDownloading Packages:\n(1/13): audit-libs-python-2.2-2.el6.x86_64.rpm           |  58 kB     00:00     \n(2/13): cvmfs-2.1.20-1.osg32.el6.x86_64.rpm              | 5.9 MB     00:00     \n(3/13): cvmfs-config-osg-1.1-5.osg32.el6.noarch.rpm      | 8.0 kB     00:00     \n(4/13): fuse-2.8.3-4.el6.x86_64.rpm                      |  70 kB     00:00     \n(5/13): fuse-libs-2.8.3-4.el6.x86_64.rpm                 |  73 kB     00:00     \n(6/13): gdb-7.2-60.el6.x86_64.rpm                        | 2.3 MB     00:00     \n(7/13): libcgroup-0.37-7.el6.x86_64.rpm                  | 110 kB     00:00     \n(8/13): libselinux-python-2.0.94-5.3.el6.x86_64.rpm      | 201 kB     00:00     \n(9/13): libsemanage-python-2.0.43-4.2.el6.x86_64.rpm     |  80 kB     00:00     \n(10/13): osg-oasis-5-1.osg32.el6.noarch.rpm              | 2.4 kB     00:00     \n(11/13): policycoreutils-python-2.0.83-19.30.el6.x86_64. | 341 kB     00:00     \n(12/13): setools-libs-3.3.7-4.el6.x86_64.rpm             | 399 kB     00:00     \n(13/13): setools-libs-python-3.3.7-4.el6.x86_64.rpm      | 221 kB     00:00     \n--------------------------------------------------------------------------------\nTotal                                           9.7 MB/s | 9.8 MB     00:01     \nwarning: rpmts_HdrFromFdno: Header V4 DSA/SHA1 Signature, key ID 824b8603: NOKEY\nRetrieving key from file:///etc/pki/rpm-gpg/RPM-GPG-KEY-OSG\nImporting GPG key 0x824B8603:\n Userid : OSG Software Team (RPM Signing Key for Koji Packages)  vdt-support@opensciencegrid.org \n Package: osg-release-3.2-7.osg32.el6.noarch (installed)\n From   : /etc/pki/rpm-gpg/RPM-GPG-KEY-OSG\nIs this ok [y/N]: y\nRunning rpm_check_debug\nRunning Transaction Test\nTransaction Test Succeeded\nRunning Transaction\nWarning: RPMDB altered outside of yum.\n  Installing : cvmfs-config-osg-1.1-5.osg32.el6.noarch                     1/13 \n  Installing : setools-libs-3.3.7-4.el6.x86_64                             2/13 \n  Installing : setools-libs-python-3.3.7-4.el6.x86_64                      3/13 \n  Installing : fuse-libs-2.8.3-4.el6.x86_64                                4/13 \n  Installing : libsemanage-python-2.0.43-4.2.el6.x86_64                    5/13 \n  Installing : gdb-7.2-60.el6.x86_64                                       6/13 \n  Installing : fuse-2.8.3-4.el6.x86_64                                     7/13 \n  Installing : audit-libs-python-2.2-2.el6.x86_64                          8/13 \n  Installing : libselinux-python-2.0.94-5.3.el6.x86_64                     9/13 \n  Installing : libcgroup-0.37-7.el6.x86_64                                10/13 \n  Installing : policycoreutils-python-2.0.83-19.30.el6.x86_64             11/13 \n  Installing : cvmfs-2.1.20-1.osg32.el6.x86_64                            12/13 \n  Installing : osg-oasis-5-1.osg32.el6.noarch                             13/13 \n  Verifying  : libcgroup-0.37-7.el6.x86_64                                 1/13 \n  Verifying  : libselinux-python-2.0.94-5.3.el6.x86_64                     2/13 \n  Verifying  : audit-libs-python-2.2-2.el6.x86_64                          3/13 \n  Verifying  : policycoreutils-python-2.0.83-19.30.el6.x86_64              4/13 \n  Verifying  : fuse-2.8.3-4.el6.x86_64                                     5/13 \n  Verifying  : cvmfs-config-osg-1.1-5.osg32.el6.noarch                     6/13 \n  Verifying  : setools-libs-python-3.3.7-4.el6.x86_64                      7/13 \n  Verifying  : gdb-7.2-60.el6.x86_64                                       8/13 \n  Verifying  : osg-oasis-5-1.osg32.el6.noarch                              9/13 \n  Verifying  : libsemanage-python-2.0.43-4.2.el6.x86_64                   10/13 \n  Verifying  : cvmfs-2.1.20-1.osg32.el6.x86_64                            11/13 \n  Verifying  : fuse-libs-2.8.3-4.el6.x86_64                               12/13 \n  Verifying  : setools-libs-3.3.7-4.el6.x86_64                            13/13 \n\nInstalled:\n  osg-oasis.noarch 0:5-1.osg32.el6                                              \n\nDependency Installed:\n  audit-libs-python.x86_64 0:2.2-2.el6                                          \n  cvmfs.x86_64 0:2.1.20-1.osg32.el6                                             \n  cvmfs-config-osg.noarch 0:1.1-5.osg32.el6                                     \n  fuse.x86_64 0:2.8.3-4.el6                                                     \n  fuse-libs.x86_64 0:2.8.3-4.el6                                                \n  gdb.x86_64 0:7.2-60.el6                                                       \n  libcgroup.x86_64 0:0.37-7.el6                                                 \n  libselinux-python.x86_64 0:2.0.94-5.3.el6                                     \n  libsemanage-python.x86_64 0:2.0.43-4.2.el6                                    \n  policycoreutils-python.x86_64 0:2.0.83-19.30.el6                              \n  setools-libs.x86_64 0:3.3.7-4.el6                                             \n  setools-libs-python.x86_64 0:3.3.7-4.el6                                      \n\nComplete!\n[root@fermicloud044 ~]# echo user_allow_other  /etc/fuse.conf\n[root@fermicloud044 ~]# echo  /cvmfs /etc/auto.cvmfs   /etc/auto.master\n[root@fermicloud044 ~]# service autofs restart\nStopping automount:                                        [  OK  ]\nStarting automount:                                        [  OK  ]\n[root@fermicloud044 ~]# cat  /etc/cvmfs/default.local\nCVMFS_REPOSITORIES= `echo $((echo oasis.opensciencegrid.org;echo cms.cern.ch;ls /cvmfs)|sort -u)|tr     ,` \nCVMFS_CACHE_BASE=/var/cache/cvmfs\nCVMFS_QUOTA_LIMIT=20000\nCVMFS_HTTP_PROXY= http://squid.fnal.gov:3128 \n[root@fermicloud044 ~]# ls /cvmfs\n[root@fermicloud044 ~]# ls -l /cvmfs/atlas.cern.ch\ntotal 5\ndrwxr-xr-x 6 cvmfs cvmfs 4096 Sep 12  2014 repo\n[root@fermicloud044 ~]# ls -l /cvmfs/oasis.opensciencegrid.org/cmssoft\ntotal 1\nlrwxrwxrwx 1 cvmfs cvmfs 18 Mar 11  2014 cms -  /cvmfs/cms.cern.ch\n[root@fermicloud044 ~]# ls -l /cvmfs/glast.egi.eu\ntotal 5\ndrwxr-xr-x 9 cvmfs cvmfs 4096 Feb  7  2014 glast\n[root@fermicloud044 ~]# ls /cvmfs\natlas.cern.ch  cms.cern.ch  glast.egi.eu  oasis.opensciencegrid.org\n[root@fermicloud044 ~]# cvmfs_config umount\nUnmounting /cvmfs/atlas.cern.ch: OK\nUnmounting /cvmfs/oasis.opensciencegrid.org: OK\nUnmounting /cvmfs/cms.cern.ch: OK\nUnmounting /cvmfs/glast.egi.eu: OK\n[root@fermicloud044 ~]#", 
            "title": "Screendump of Install"
        }, 
        {
            "location": "/client/cvmfs/#file-locations", 
            "text": "Service/Process  Configuration File  Description      cvmfs  /etc/cvmfs/default.local  cvmfs environment settings and repository setup    fuse  /etc/fuse.conf  fuse settings    automount  /etc/auto.master  automount settings", 
            "title": "File Locations"
        }, 
        {
            "location": "/client/cvmfs/#how-to-get-help", 
            "text": "If you cannot resolve the problem, there are several ways to receive help:   For bug reporting and OSG-specific issues, submit a ticket to the  Grid Operations Center .  For community support and best-effort software team support contact  .  For general CERN VM FileSystem support contact  .   For a full set of help options, see  Help Procedure .", 
            "title": "How to get Help?"
        }, 
        {
            "location": "/client/cvmfs/#references", 
            "text": "http://cernvm.cern.ch/portal/filesystem/techinformation  https://ecsft.cern.ch/dist/cvmfs/cvmfstech-2.1-6.pdf", 
            "title": "References"
        }, 
        {
            "location": "/client/wn/", 
            "text": "Installing and Using the Worker Node Client From RPMs\n\n\nAbout This Guide\n\n\nThe \nOSG Worker Node Client\n is a collection of software components that is expected to be added to every worker node that can run OSG jobs. It provides a common environment and a minimal set of common tools that all OSG jobs can expect to use. See the reference section below for contents of the Worker Node Client.\n\n\nIt is possible to install the Worker Node Client software in a variety of ways, depending on what works best for distributing and managing software at your site:\n\n\n\n\nInstall using RPMs and Yum (this guide) - useful when managing your worker nodes with a tool (e.g., Puppet, Chef) that can automate RPM installs\n\n\nInstall using a tarball\n - useful when installing onto a shared filesystem for distribution to worker nodes\n\n\nUse from OASIS\n - useful when worker nodes already mount OASIS on your worker nodes\n\n\n\n\nThis document is intended to guide system administrators through the process of configuring a site to make the Worker Node Client software available from an RPM.\n\n\nBefore Starting\n\n\nAs with all OSG software installations, there are some one-time (per host) steps to prepare in advance:\n\n\n\n\nEnsure the host has \na supported operating system\n\n\nObtain root access to the host\n\n\nPrepare \nthe required Yum repositories\n\n\nInstall \nCA certificates\n\n\n\n\nInstall the Worker Node Client\n\n\nInstall the Worker Node Client RPM:\n\n\n[root@client ~]#\n yum install osg-wn-client\n\n\n\n\n\nServices\n\n\nFetch-CRL is the only service required to support the WN Client.\n\n\n\n\n\n\n\n\nSoftware\n\n\nService name\n\n\nNotes\n\n\n\n\n\n\n\n\n\n\nFetch CRL\n\n\nfetch-crl-boot\n and \nfetch-crl-cron\n\n\nSee \nCA documentation\n for more info\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nfetch-crl-boot\n will begin fetching CRLS, which can take a few minutes and fail on transient errors. You can add configuration to ignore these transient errors in \n/etc/fetch-crl.conf\n: \n\n\nnoerrors\n\n\n\n\n\n\n\nAs a reminder, here are common service commands (all run as \nroot\n):\n\n\n\n\n\n\n\n\nTo \u2026\n\n\nRun the command \u2026\n\n\n\n\n\n\n\n\n\n\nStart a service\n\n\nservice SERVICE-NAME start\n\n\n\n\n\n\nStop a service\n\n\nservice SERVICE-NAME stop\n\n\n\n\n\n\nEnable a service to start during boot\n\n\nchkconfig SERVICE-NAME on\n\n\n\n\n\n\nDisable a service from starting during boot\n\n\nchkconfig SERVICE-NAME off\n\n\n\n\n\n\n\n\nValidating the Worker Node Client\n\n\nTo verify functionality of the worker node client, you will need to submit a test job against your CE and verify the job's output.\n\n\n\n\nSubmit a job that executes the \nenv\n command (e.g. Run \ncondor_ce_trace\n with the \n-d\n flag from your HTCondor CE)\n\n\nVerify that the value of \nOSG_GRID\n is set to \n/etc/osg/wn-client\n\n\n\n\nHow to get Help?\n\n\nTo get assistance please use this \nHelp Procedure\n.\n\n\nReference\n\n\nPlease see the documentation on using \nyum and RPM\n, \nthe best practices\n for using yum to install software, and using \nyum repositories\n.\n\n\nWorker node contents\n\n\nThe worker node may be updated from time to time. As of OSG 3.3.21 in February 2017, the OSG worker node client contains:\n\n\n\n\nOSG Certificates\n\n\ncurl\n\n\nFetch CRL\n\n\nFTS client\n\n\ngfal2\n\n\nglobus-url-copy (GridFTP client)\n\n\nglobus-xio-udt-driver\n\n\nldapsearch\n\n\nMyProxy\n\n\nosg-system-profiler\n\n\nosg-version\n\n\nUberFTP\n\n\nvo-client (includes /etc/vomses file)\n\n\nVOMS client\n\n\nwget\n\n\nxrdcp\n\n\n\n\nTo see the currently installed version of the worker node package, run the following command:\n\n\n[root@client ~]# rpm -q --requires osg-wn-client\n\n\n\n\n\nClick \nhere\n for more details on using RPM to see what was installed.", 
            "title": "Worker Node (RPM install)"
        }, 
        {
            "location": "/client/wn/#installing-and-using-the-worker-node-client-from-rpms", 
            "text": "", 
            "title": "Installing and Using the Worker Node Client From RPMs"
        }, 
        {
            "location": "/client/wn/#about-this-guide", 
            "text": "The  OSG Worker Node Client  is a collection of software components that is expected to be added to every worker node that can run OSG jobs. It provides a common environment and a minimal set of common tools that all OSG jobs can expect to use. See the reference section below for contents of the Worker Node Client.  It is possible to install the Worker Node Client software in a variety of ways, depending on what works best for distributing and managing software at your site:   Install using RPMs and Yum (this guide) - useful when managing your worker nodes with a tool (e.g., Puppet, Chef) that can automate RPM installs  Install using a tarball  - useful when installing onto a shared filesystem for distribution to worker nodes  Use from OASIS  - useful when worker nodes already mount OASIS on your worker nodes   This document is intended to guide system administrators through the process of configuring a site to make the Worker Node Client software available from an RPM.", 
            "title": "About This Guide"
        }, 
        {
            "location": "/client/wn/#before-starting", 
            "text": "As with all OSG software installations, there are some one-time (per host) steps to prepare in advance:   Ensure the host has  a supported operating system  Obtain root access to the host  Prepare  the required Yum repositories  Install  CA certificates", 
            "title": "Before Starting"
        }, 
        {
            "location": "/client/wn/#install-the-worker-node-client", 
            "text": "Install the Worker Node Client RPM:  [root@client ~]#  yum install osg-wn-client", 
            "title": "Install the Worker Node Client"
        }, 
        {
            "location": "/client/wn/#services", 
            "text": "Fetch-CRL is the only service required to support the WN Client.     Software  Service name  Notes      Fetch CRL  fetch-crl-boot  and  fetch-crl-cron  See  CA documentation  for more info      Note  fetch-crl-boot  will begin fetching CRLS, which can take a few minutes and fail on transient errors. You can add configuration to ignore these transient errors in  /etc/fetch-crl.conf :   noerrors   As a reminder, here are common service commands (all run as  root ):     To \u2026  Run the command \u2026      Start a service  service SERVICE-NAME start    Stop a service  service SERVICE-NAME stop    Enable a service to start during boot  chkconfig SERVICE-NAME on    Disable a service from starting during boot  chkconfig SERVICE-NAME off", 
            "title": "Services"
        }, 
        {
            "location": "/client/wn/#validating-the-worker-node-client", 
            "text": "To verify functionality of the worker node client, you will need to submit a test job against your CE and verify the job's output.   Submit a job that executes the  env  command (e.g. Run  condor_ce_trace  with the  -d  flag from your HTCondor CE)  Verify that the value of  OSG_GRID  is set to  /etc/osg/wn-client", 
            "title": "Validating the Worker Node Client"
        }, 
        {
            "location": "/client/wn/#how-to-get-help", 
            "text": "To get assistance please use this  Help Procedure .", 
            "title": "How to get Help?"
        }, 
        {
            "location": "/client/wn/#reference", 
            "text": "Please see the documentation on using  yum and RPM ,  the best practices  for using yum to install software, and using  yum repositories .", 
            "title": "Reference"
        }, 
        {
            "location": "/client/wn/#worker-node-contents", 
            "text": "The worker node may be updated from time to time. As of OSG 3.3.21 in February 2017, the OSG worker node client contains:   OSG Certificates  curl  Fetch CRL  FTS client  gfal2  globus-url-copy (GridFTP client)  globus-xio-udt-driver  ldapsearch  MyProxy  osg-system-profiler  osg-version  UberFTP  vo-client (includes /etc/vomses file)  VOMS client  wget  xrdcp   To see the currently installed version of the worker node package, run the following command:  [root@client ~]# rpm -q --requires osg-wn-client  Click  here  for more details on using RPM to see what was installed.", 
            "title": "Worker node contents"
        }, 
        {
            "location": "/client/wn-tarball/", 
            "text": "Installing and Using the Worker Node Client from Tarballs\n\n\nIntroduction\n\n\nThis document is intended to guide users through the process of installing the worker node software and configuring the installed worker node software. Contents of the worker node client can be found \nhere\n.  Although this document is oriented to system administrators, any unprivileged user may install and use the client.\n\n\nIf you are installing the OSG worker node client following these instruction, remember to configure the \ngrid_dir\n option on your CE - see \nbelow\n.\n\n\nAbout This Guide\n\n\nThe \nOSG Worker Node Client\n is a collection of software components that is expected to be added to every worker node that can run OSG jobs. It provides a common environment and a minimal set of common tools that all OSG jobs can expect to use.\n\n\nIt is possible to install the Worker Node Client software in a variety of ways, depending on what works best for distributing and managing software at your site:  This guide is useful when installing onto a shared filesystem for distribution to worker nodes.  Other options include installing \nvia RPMs\n or providing the client \nvia OASIS (CVMFS)\n.\n\n\nBefore starting, ensure the host has \na supported operating system\n.\n\n\nDownload, Installation and Configuration\n\n\nDownload the WN Client\n\n\nPlease pick the \nosg-wn-client\n tarball that is appropriate for your distribution and architecture. You will find them in \nhttps://repo.grid.iu.edu/tarball-install/\n .\n\n\nThe latest available the tarballs for OSG 3.3 are:\n\n\n\n\nBinaries for 32-bit RHEL6\n\n\nBinaries for 64-bit RHEL6\n\n\nBinaries for RHEL7\n\n\n\n\nFor OSG 3.4:\n\n\n\n\nBinaries for 64-bit RHEL6\n\n\nBinaries for RHEL7\n\n\n\n\nInstall the WN Client\n\n\n\n\nUnpack the tarball.\n\n\nMove the directory that was created to where you want the tarball client to be.\n\n\nRun \nosg-post-install\n (\nPATH_TO_CLIENT\n/osg/osg-post-install\n) to fix the directories in the installation.\n\n\nSource the setup \nsource \nPATH_TO_CLIENT\n/setup.sh\n (or \nsetup.csh\n depending on the shell).\n\n\nDownload and set up CA certificiates using \nosg-ca-manage\n (See the \nCA management documentation\n for the available options).\n\n\nDownload CRLs using \nfetch-crl\n.\n\n\n\n\n\n\nWarning\n\n\nOnce \nosg-post-install\n is run to relocate the install, it cannot be run again.  You will need to unpack a fresh copy.\n\n\n\n\nExample installation (in \n/home/user/test-install\n, the \nPATH_TO_CLIENT\n/\n is \n/home/user/test-install/osg-wn-client\n ):\n\n\n[root@client ~] #\n mkdir /home/user/test-install\n\n[root@client ~] #\n \ncd\n /home/user/test-install\n\n[root@client ~] #\n wget http://repo.grid.iu.edu/tarball-install/3.4/osg-wn-client-latest.el6.x86_64.tar.gz\n\n[root@client ~] #\n tar xzf osg-wn-client-latest.el6.x86_64.tar.gz\n\n[root@client ~] #\n \ncd\n osg-wn-client\n\n[root@client ~] #\n ./osg/osg-post-install\n\n[root@client ~] #\n \nsource\n setup.sh\n\n[root@client ~] #\n osg-ca-manage setupCA --url osg\n\n[root@client ~] #\n fetch-crl\n\n\n\n\n\nConfigure the CE\n\n\nUsing the wn-client software installed from the tarball will require a few changes on the compute element so that the resource's configuration can be correctly reported.\n\n\nSet \ngrid_dir\n in the \nStorage\n section of your OSG-Configure configs: \nCE configuration instructions\n. \ngrid_dir\n is used as the \n$OSG_GRID\n environment variable in running jobs - see \nthe environment variables document\n. Pilot jobs source \n$OSG_GRID/setup.sh\n before performing any work. The value set for \ngrid_dir\n must be the path of the wn-client installation directory. This is the path returned by \necho $OSG_LOCATION\n once you source the setup file created by this installation.\n\n\nServices\n\n\nThe WN client is a collection of client programs that do not require service startup or shutdown. The only services are \nosg-update-certs\n that keeps the CA certificates up-to-date and \nfetch-crl\n that keeps the CRLs up-to-date. Following the instructions below you'll add the services to your crontab that will take care to run them periodically until you remove them.\n\n\nAuto-updating certificates and CRLs\n\n\nYou must create cron jobs to run \nfetch-crl\n and \nosg-update-certs\n to update your CRLs and certificates automatically.\n\n\nHere is what they should look like. (Note: fill in \nOSG_LOCATION\n with the full path of your tarball install, including \nosg-wn-client\n that is created by the tarball).\n\n\n# Cron job to update certs.\n# Runs every hour by default, though does not update certs until they\nre at\n# least 24 hours old.  There is a random sleep time for up to 45 minutes (2700\n# seconds) to avoid overloading cert servers.\n10 * * * *   ( . \nOSG_LOCATION\n/setup.sh \n osg-update-certs --random-sleep 2700 --called-from-cron )\n\n\n\n\n\n# Cron job to update CRLs\n# Runs every 6 hours at, 45 minutes +/- 3 minutes.\n42 */6 * * *   ( . \nOSG_LOCATION\n/setup.sh \n fetch-crl -q -r 360 )\n\n\n\n\n\nYou might want to configure proxy settings in \n$OSG_LOCATION/etc/fetch-crl.conf\n.\n\n\nStarting and Enabling Services\n\n\nTo start the services you must edit your cron with \ncrontab -e\n and add the lines above.\n\n\nStopping and Disabling Services\n\n\nTo stop the services you must edit your cron with \ncrontab -e\n and remove or comment the lines above.\n\n\nValiding the Worker Node Client\n\n\nTo verify functionality of the worker node client, you will need to submit a test job against your CE and verify the job's output.\n\n\n\n\nSubmit a job that executes the \nenv\n command (e.g. Run \ncondor_ce_trace\n with the \n-d\n flag from your HTCondor CE)\n\n\nVerify that the value of \n$OSG_GRID\n is set to the directory of your worker node client installation\n\n\n\n\nHow to get Help?\n\n\nTo get assistance please use this \nHelp Procedure\n.", 
            "title": "Worker Node (tarball install)"
        }, 
        {
            "location": "/client/wn-tarball/#installing-and-using-the-worker-node-client-from-tarballs", 
            "text": "", 
            "title": "Installing and Using the Worker Node Client from Tarballs"
        }, 
        {
            "location": "/client/wn-tarball/#introduction", 
            "text": "This document is intended to guide users through the process of installing the worker node software and configuring the installed worker node software. Contents of the worker node client can be found  here .  Although this document is oriented to system administrators, any unprivileged user may install and use the client.  If you are installing the OSG worker node client following these instruction, remember to configure the  grid_dir  option on your CE - see  below .", 
            "title": "Introduction"
        }, 
        {
            "location": "/client/wn-tarball/#about-this-guide", 
            "text": "The  OSG Worker Node Client  is a collection of software components that is expected to be added to every worker node that can run OSG jobs. It provides a common environment and a minimal set of common tools that all OSG jobs can expect to use.  It is possible to install the Worker Node Client software in a variety of ways, depending on what works best for distributing and managing software at your site:  This guide is useful when installing onto a shared filesystem for distribution to worker nodes.  Other options include installing  via RPMs  or providing the client  via OASIS (CVMFS) .  Before starting, ensure the host has  a supported operating system .", 
            "title": "About This Guide"
        }, 
        {
            "location": "/client/wn-tarball/#download-installation-and-configuration", 
            "text": "", 
            "title": "Download, Installation and Configuration"
        }, 
        {
            "location": "/client/wn-tarball/#download-the-wn-client", 
            "text": "Please pick the  osg-wn-client  tarball that is appropriate for your distribution and architecture. You will find them in  https://repo.grid.iu.edu/tarball-install/  .  The latest available the tarballs for OSG 3.3 are:   Binaries for 32-bit RHEL6  Binaries for 64-bit RHEL6  Binaries for RHEL7   For OSG 3.4:   Binaries for 64-bit RHEL6  Binaries for RHEL7", 
            "title": "Download the WN Client"
        }, 
        {
            "location": "/client/wn-tarball/#install-the-wn-client", 
            "text": "Unpack the tarball.  Move the directory that was created to where you want the tarball client to be.  Run  osg-post-install  ( PATH_TO_CLIENT /osg/osg-post-install ) to fix the directories in the installation.  Source the setup  source  PATH_TO_CLIENT /setup.sh  (or  setup.csh  depending on the shell).  Download and set up CA certificiates using  osg-ca-manage  (See the  CA management documentation  for the available options).  Download CRLs using  fetch-crl .    Warning  Once  osg-post-install  is run to relocate the install, it cannot be run again.  You will need to unpack a fresh copy.   Example installation (in  /home/user/test-install , the  PATH_TO_CLIENT /  is  /home/user/test-install/osg-wn-client  ):  [root@client ~] #  mkdir /home/user/test-install [root@client ~] #   cd  /home/user/test-install [root@client ~] #  wget http://repo.grid.iu.edu/tarball-install/3.4/osg-wn-client-latest.el6.x86_64.tar.gz [root@client ~] #  tar xzf osg-wn-client-latest.el6.x86_64.tar.gz [root@client ~] #   cd  osg-wn-client [root@client ~] #  ./osg/osg-post-install [root@client ~] #   source  setup.sh [root@client ~] #  osg-ca-manage setupCA --url osg [root@client ~] #  fetch-crl", 
            "title": "Install the WN Client"
        }, 
        {
            "location": "/client/wn-tarball/#configure-the-ce", 
            "text": "Using the wn-client software installed from the tarball will require a few changes on the compute element so that the resource's configuration can be correctly reported.  Set  grid_dir  in the  Storage  section of your OSG-Configure configs:  CE configuration instructions .  grid_dir  is used as the  $OSG_GRID  environment variable in running jobs - see  the environment variables document . Pilot jobs source  $OSG_GRID/setup.sh  before performing any work. The value set for  grid_dir  must be the path of the wn-client installation directory. This is the path returned by  echo $OSG_LOCATION  once you source the setup file created by this installation.", 
            "title": "Configure the CE"
        }, 
        {
            "location": "/client/wn-tarball/#services", 
            "text": "The WN client is a collection of client programs that do not require service startup or shutdown. The only services are  osg-update-certs  that keeps the CA certificates up-to-date and  fetch-crl  that keeps the CRLs up-to-date. Following the instructions below you'll add the services to your crontab that will take care to run them periodically until you remove them.", 
            "title": "Services"
        }, 
        {
            "location": "/client/wn-tarball/#auto-updating-certificates-and-crls", 
            "text": "You must create cron jobs to run  fetch-crl  and  osg-update-certs  to update your CRLs and certificates automatically.  Here is what they should look like. (Note: fill in  OSG_LOCATION  with the full path of your tarball install, including  osg-wn-client  that is created by the tarball).  # Cron job to update certs.\n# Runs every hour by default, though does not update certs until they re at\n# least 24 hours old.  There is a random sleep time for up to 45 minutes (2700\n# seconds) to avoid overloading cert servers.\n10 * * * *   ( .  OSG_LOCATION /setup.sh   osg-update-certs --random-sleep 2700 --called-from-cron )  # Cron job to update CRLs\n# Runs every 6 hours at, 45 minutes +/- 3 minutes.\n42 */6 * * *   ( .  OSG_LOCATION /setup.sh   fetch-crl -q -r 360 )  You might want to configure proxy settings in  $OSG_LOCATION/etc/fetch-crl.conf .", 
            "title": "Auto-updating certificates and CRLs"
        }, 
        {
            "location": "/client/wn-tarball/#starting-and-enabling-services", 
            "text": "To start the services you must edit your cron with  crontab -e  and add the lines above.", 
            "title": "Starting and Enabling Services"
        }, 
        {
            "location": "/client/wn-tarball/#stopping-and-disabling-services", 
            "text": "To stop the services you must edit your cron with  crontab -e  and remove or comment the lines above.", 
            "title": "Stopping and Disabling Services"
        }, 
        {
            "location": "/client/wn-tarball/#validing-the-worker-node-client", 
            "text": "To verify functionality of the worker node client, you will need to submit a test job against your CE and verify the job's output.   Submit a job that executes the  env  command (e.g. Run  condor_ce_trace  with the  -d  flag from your HTCondor CE)  Verify that the value of  $OSG_GRID  is set to the directory of your worker node client installation", 
            "title": "Validing the Worker Node Client"
        }, 
        {
            "location": "/client/wn-tarball/#how-to-get-help", 
            "text": "To get assistance please use this  Help Procedure .", 
            "title": "How to get Help?"
        }, 
        {
            "location": "/client/wn-oasis/", 
            "text": "Configuring a Site to Use the Worker Node Client Software From OASIS\n\n\nAbout This Guide\n\n\nThe \nOSG Worker Node Client\n is a collection of software components that is expected to be added to every worker node that can run OSG jobs. It provides a common environment and a minimal set of common tools that all OSG jobs can expect to use.\n\n\nIt is possible to install the Worker Node Client software in a variety of ways, depending on what works best for distributing and managing software at your site:\n\n\n\n\nUse the Worker Node Client software from OASIS (this guide) - useful when \nOASIS\n is already mounted on your worker nodes\n\n\nInstall using RPMs and Yum\n - useful when managing your worker nodes with a tool (e.g., Puppet, Chef) that can automate RPM installs\n\n\nInstall using a tarball\n - useful when installing onto a shared filesystem for distribution to worker nodes\n\n\n\n\nThis document is intended to guide system administrators through the process of configuring a site to make the Worker Node Client software available from OASIS.\n\n\nBefore Starting\n\n\nAs with all OSG software installations, there are some one-time (per host) steps to prepare in advance:\n\n\n\n\nEnsure the host has \na supported operating system\n\n\n\n\nAlso note that, once configured to use OASIS, each use of Worker Node Client software will cause that software and its associated files to be downloaded from a CVMFS server or your local cache thereof. This may result in extra network activity, especially if Worker Node Client tools are used heavily.\n\n\nConfiguring Your Site to Use the Worker Node Client From OASIS\n\n\nBelow are the one-time steps that you must perform to configure your site to use the Worker Node Client software from OASIS.\n\n\nOn every worker node, \ninstall and configure OASIS\n\n\nDetermine the OASIS path to the Worker Node Client software for your worker nodes:\n\n\n\n\n\n\n\n\nWorker Node OS\n\n\nUse\u2026\n\n\n\n\n\n\n\n\n\n\nEL\u00a06 (32-bit)\n\n\n/cvmfs/oasis.opensciencegrid.org/osg-software/osg-wn-client/3.3/current/el6-i386\n\n\n\n\n\n\nEL\u00a06 (64-bit)\n\n\n/cvmfs/oasis.opensciencegrid.org/osg-software/osg-wn-client/3.3/current/el6-x86_64\n\n\n\n\n\n\nEL\u00a07 (64-bit)\n\n\n/cvmfs/oasis.opensciencegrid.org/osg-software/osg-wn-client/3.3/current/el7-x86_64\n\n\n\n\n\n\n\n\nOn the CE, in the \n/etc/osg/config.d/10-storage.ini\n file, set the \ngrid_dir\n configuration setting to the path from the previous step.\n\n\nFor more information, see the \nOSG environment variables reference page\n and the \nCE configuration instructions\n.\n\n\nOnce you finish making changes to configuration files on your CE, validate, fix, and apply the configuration:\n\n\n[root@client ~] #\n osg-configure -v \n\n[root@client ~] #\n osg-configure -c\n\n\n\n\n\nValidating the Worker Node Client\n\n\nTo verify functionality of the worker node client, you will need to submit a test job against your CE and verify the job's output.\n\n\n\n\nSubmit a job that executes the \nenv\n command (e.g. Run \ncondor_ce_trace\n with the \n-d\n flag from your HTCondor CE)\n\n\nVerify that the value of \nOSG_GRID\n is set to the directory of your WN Client installation\n\n\n\n\nManually Using the Worker Node Client From OASIS\n\n\nIf you must log onto a worker node and use the Worker Node Client software directly during your login session, consult the following table for the command to set up your environment:\n\n\n\n\n\n\n\n\nWorker Node OS\n\n\nRun the following command\u2026\n\n\n\n\n\n\n\n\n\n\nEL\u00a06 (32-bit)\n\n\nsource /cvmfs/oasis.opensciencegrid.org/osg-software/osg-wn-client/3.3/current/el6-i386/setup.sh\n\n\n\n\n\n\nEL\u00a06 (64-bit)\n\n\nsource /cvmfs/oasis.opensciencegrid.org/osg-software/osg-wn-client/3.3/current/el6-x86_64/setup.sh\n\n\n\n\n\n\nEL\u00a07 (64-bit)\n\n\nsource /cvmfs/oasis.opensciencegrid.org/osg-software/osg-wn-client/3.3/current/el7-x86_64/setup.sh\n\n\n\n\n\n\n\n\nTroubleshooting\n\n\nSome possible issues that may come up:\n\n\n\n\n\n\nA missing softlink to the CA certs directory. To check this, run:\n\n\n[user@client ~] $\n ls -l /cvmfs/oasis.opensciencegrid.org/mis/osg-wn-client/3.3/current/el6-x86_64/etc/grid-security/\n\n\n\n\n\nand check that \ncertificates\n is linked to somewhere. The fix is to yum update the \noasis-config\n package to version 4 or higher. A known workaround is to run:\n\n\n[user@client ~] $\n \nexport\n \nX509_CERT_DIR\n=\n/cvmfs/oasis.opensciencegrid.org/mis/certificates\n\n\n\n\n\nbefore any commands.\n\n\n\n\n\n\nHow to get Help?\n\n\nTo get assistance please use this \nHelp Procedure\n.", 
            "title": "Worker Node (OASIS install)"
        }, 
        {
            "location": "/client/wn-oasis/#configuring-a-site-to-use-the-worker-node-client-software-from-oasis", 
            "text": "", 
            "title": "Configuring a Site to Use the Worker Node Client Software From OASIS"
        }, 
        {
            "location": "/client/wn-oasis/#about-this-guide", 
            "text": "The  OSG Worker Node Client  is a collection of software components that is expected to be added to every worker node that can run OSG jobs. It provides a common environment and a minimal set of common tools that all OSG jobs can expect to use.  It is possible to install the Worker Node Client software in a variety of ways, depending on what works best for distributing and managing software at your site:   Use the Worker Node Client software from OASIS (this guide) - useful when  OASIS  is already mounted on your worker nodes  Install using RPMs and Yum  - useful when managing your worker nodes with a tool (e.g., Puppet, Chef) that can automate RPM installs  Install using a tarball  - useful when installing onto a shared filesystem for distribution to worker nodes   This document is intended to guide system administrators through the process of configuring a site to make the Worker Node Client software available from OASIS.", 
            "title": "About This Guide"
        }, 
        {
            "location": "/client/wn-oasis/#before-starting", 
            "text": "As with all OSG software installations, there are some one-time (per host) steps to prepare in advance:   Ensure the host has  a supported operating system   Also note that, once configured to use OASIS, each use of Worker Node Client software will cause that software and its associated files to be downloaded from a CVMFS server or your local cache thereof. This may result in extra network activity, especially if Worker Node Client tools are used heavily.", 
            "title": "Before Starting"
        }, 
        {
            "location": "/client/wn-oasis/#configuring-your-site-to-use-the-worker-node-client-from-oasis", 
            "text": "Below are the one-time steps that you must perform to configure your site to use the Worker Node Client software from OASIS.  On every worker node,  install and configure OASIS  Determine the OASIS path to the Worker Node Client software for your worker nodes:     Worker Node OS  Use\u2026      EL\u00a06 (32-bit)  /cvmfs/oasis.opensciencegrid.org/osg-software/osg-wn-client/3.3/current/el6-i386    EL\u00a06 (64-bit)  /cvmfs/oasis.opensciencegrid.org/osg-software/osg-wn-client/3.3/current/el6-x86_64    EL\u00a07 (64-bit)  /cvmfs/oasis.opensciencegrid.org/osg-software/osg-wn-client/3.3/current/el7-x86_64     On the CE, in the  /etc/osg/config.d/10-storage.ini  file, set the  grid_dir  configuration setting to the path from the previous step.  For more information, see the  OSG environment variables reference page  and the  CE configuration instructions .  Once you finish making changes to configuration files on your CE, validate, fix, and apply the configuration:  [root@client ~] #  osg-configure -v  [root@client ~] #  osg-configure -c", 
            "title": "Configuring Your Site to Use the Worker Node Client From OASIS"
        }, 
        {
            "location": "/client/wn-oasis/#validating-the-worker-node-client", 
            "text": "To verify functionality of the worker node client, you will need to submit a test job against your CE and verify the job's output.   Submit a job that executes the  env  command (e.g. Run  condor_ce_trace  with the  -d  flag from your HTCondor CE)  Verify that the value of  OSG_GRID  is set to the directory of your WN Client installation", 
            "title": "Validating the Worker Node Client"
        }, 
        {
            "location": "/client/wn-oasis/#manually-using-the-worker-node-client-from-oasis", 
            "text": "If you must log onto a worker node and use the Worker Node Client software directly during your login session, consult the following table for the command to set up your environment:     Worker Node OS  Run the following command\u2026      EL\u00a06 (32-bit)  source /cvmfs/oasis.opensciencegrid.org/osg-software/osg-wn-client/3.3/current/el6-i386/setup.sh    EL\u00a06 (64-bit)  source /cvmfs/oasis.opensciencegrid.org/osg-software/osg-wn-client/3.3/current/el6-x86_64/setup.sh    EL\u00a07 (64-bit)  source /cvmfs/oasis.opensciencegrid.org/osg-software/osg-wn-client/3.3/current/el7-x86_64/setup.sh", 
            "title": "Manually Using the Worker Node Client From OASIS"
        }, 
        {
            "location": "/client/wn-oasis/#troubleshooting", 
            "text": "Some possible issues that may come up:    A missing softlink to the CA certs directory. To check this, run:  [user@client ~] $  ls -l /cvmfs/oasis.opensciencegrid.org/mis/osg-wn-client/3.3/current/el6-x86_64/etc/grid-security/  and check that  certificates  is linked to somewhere. The fix is to yum update the  oasis-config  package to version 4 or higher. A known workaround is to run:  [user@client ~] $   export   X509_CERT_DIR = /cvmfs/oasis.opensciencegrid.org/mis/certificates  before any commands.", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/client/wn-oasis/#how-to-get-help", 
            "text": "To get assistance please use this  Help Procedure .", 
            "title": "How to get Help?"
        }, 
        {
            "location": "/frontier-squid/squid/", 
            "text": "Frontier Squid Caching Proxy Installation Guide\n\n\n\n\nAbout This Document\n\n\nThis document is intended for System Administrators who are installing\n\nfrontier-squid\n, the OSG distribution of the Frontier Squid software.\n\n\nApplicable Versions\n\n\nThe applicable software versions for this document are OSG Version \n=\n3.2.16. The version of frontier-squid installed should be \n= 2.7.STABLE9-19.1\n\n\nAbout Frontier Squid\n\n\nFrontier Squid is a distribution of the well-known \nsquid HTTP caching\nproxy software\n that is optimized for use with\napplications on the Worldwide LHC Computing Grid (WLCG). It has \nmany\nadvantages\n\nover regular squid for common grid applications, especially Frontier and\nCVMFS.\n\n\nThe OSG distribution of frontier-squid is a straight rebuild of the\nupstream frontier-squid package for the convenience of OSG users.\n\n\nFrontier Squid is Recommended\n\n\nOSG recommends that all sites run a caching proxy for HTTP and HTTPS to\nhelp reduce bandwidth and improve throughput. To that end, Compute\nElement (CE) installations include Frontier Squid automatically. We\nencourage all sites to configure and use this service, as described\nbelow.\n\n\nFor large sites that expect heavy load on the proxy, it may be best to\nrun the proxy on its own host. In that case, the Frontier Squid software\nstill will be installed on the CE, but it need not be enabled. Instead,\ninstall your proxy service on the separate host and then configure the\nCE host to refer to the proxy on that host.\n\n\nThe \nosg-configure\n configuration tool (version 1.0.45 and later) warns\nusers who have not added the proxy location to their CE configuration.\nIn the future, a proxy will be required and osg-configure will fail if\nthe proxy location is not set.\n\n\nEngineering Considerations\n\n\nIf you will be supporting the Frontier application at your site, review\nthe \nupstream documentation Hardware considerations\nsection\n\nto determine how to size your equipment.\n\n\nRequirements\n\n\nHost and OS\n\n\n\n\nOS is Red Hat Enterprise Linux 5, 6, 7, and variants\n\n\nRoot access\n\n\n\n\nUsers The frontier-squid installation will create one user account\n\n\nunless it already exists.\n\n\n\n\n\n\n\n\nUser\n\n\nComment\n\n\n\n\n\n\n\n\n\n\nsquid\n\n\nReduced privilege user that the squid process runs under. Set the default gid of the \u201csquid\u201d user to be a group that is also called \u201csquid\u201d.\n\n\n\n\n\n\n\n\nThe package can instead use another user name of your choice if you\ncreate a configuration file before installation. Details are in the\n\nupstream documentation Preparation\nsection\n.\n\n\nNetworking\n\n\n\n\n\n\n\n\nService Name\n\n\nProtocol\n\n\nPort Number\n\n\nInbound\n\n\nOutbound\n\n\nComment\n\n\n\n\n\n\n\n\n\n\nSquid\n\n\ntcp\n\n\n3128\n\n\n\u2713\n\n\n\u2713\n\n\nAlso limited in squid ACLs. Both in and outbound must not be wide open to internet simultaneously\n\n\n\n\n\n\nSquid monitor\n\n\nudp\n\n\n3401\n\n\n\u2713\n\n\n\n\nAlso limited in squid ACLs. Should be limited to monitoring server addresses\n\n\n\n\n\n\n\n\nThe addresses of the WLCG monitoring servers for use in firewalls are\nlisted in the \nupstream documentation Enabling monitoring\nsection\n.\n\n\nInstall Instructions\n\n\nPrior to installing squid, make sure the host's \nyum\n repositories are \nconfigured correctly\n for OSG.\n\n\nOnce configured, install \nfrontier-squid\n:\n\n\n[root@client ~]$ yum install frontier-squid\n\n\n\n\n\nThen enable it to start at boot:\n\n\n[root@client ~]$ chkconfig frontier-squid on\n\n\n\n\n\nConfiguring Frontier Squid\n\n\nConfiguring the Frontier Squid Service\n\n\nTo configure the Frontier Squid service itself:\n\n\n\n\nFollow the \noriginal Frontier Squid\n    documentation\n,\n    in \nthe Configuration\n    section\n\\\n\n\nEnable, start, and test the service (as described below)\n\n\nEnable WLCG monitoring as described in the \nupstream documentation\n    on enabling\n    monitoring\n\n    and \nregister the squid in\n    OIM\n.\n\n\n\n\n\n\nNote\n\n\nAn important difference between the standard Squid\nsoftware and the Frontier Squid variant is that Frontier Squid\nchanges are in \n/etc/squid/customize.sh\n instead of\n\n/etc/squid/squid.conf\n.\n\n\n\n\nConfiguring the OSG CE\n\n\nTo configure the OSG Compute Element (CE) to know about your Frontier\nSquid service:\n\n\n\n\n\n\nOn your CE host, edit \n/etc/osg/config.d/01-squid.ini\n\n\n\n\nMake sure that \nenabled\n is set to \nTrue\n\n\nSet \nlocation\n to the hostname and port of your Frontier Squid\n    service (e.g., \nmy.squid.host.edu:3128\n)\n\n\nLeave the other settings at \nDEFAULT\n unless you have specific\n    reasons to change them\n\n\n\n\n\n\n\n\nRun \nosg-configure\n to propagate the changes on your CE\n\n\n\n\n\n\n\n\nNote\n\n\nYou may want to finish other CE configuration tasks before running\n\nosg-configure\n. Just be sure to run it once before starting CE services.\n\n\n\n\nStarting and Stopping the Frontier Squid Service\n\n\nStarting frontier-squid:\n\n\nUCL_ROOT_PROMPT\n service frontier-squid start\n\n\n\n\n\n\nStopping frontier-squid:\n\n\nUCL_ROOT_PROMPT\n service frontier-squid stop\n\n\n\n\n\n\nTesting Frontier Squid\n\n\nAs any user on another computer, do the following (where\n\nyoursquid.your.domain\n is\nthe fully qualified domain name of your squid server):\n\n\n[user@client ~]$ export http_proxy=http://yoursquid.your.domain:3128\n[user@client ~]$ wget -qdO/dev/null http://frontier.cern.ch 2\n1|grep X-Cache\nX-Cache: MISS from yoursquid.your.domain\n[user@client ~]$ wget -qdO/dev/null http://frontier.cern.ch 2\n1|grep X-Cache\nX-Cache: HIT from yoursquid.your.domain\n\n\n\n\n\nIf the grep doesn\u2019t print anything, try removing it from the pipeline to\nsee if errors are obvious. If the second try says \nMISS\n again, something\nis probably wrong with the squid cache writes.\n\n\nIf your squid will be supporting the Frontier application, it is also\ngood to do the test in the \nupstream documentation Testing the\ninstallation\nsection\n.\n\n\nFrontier Squid Log Files\n\n\nLog file contents are explained in the \nupstream documentation Log file\ncontents section\n.\n\n\nGetting Help\n\n\nTo get assistance please use \nHelp Procedure\n.", 
            "title": "HTTP Cache"
        }, 
        {
            "location": "/frontier-squid/squid/#frontier-squid-caching-proxy-installation-guide", 
            "text": "", 
            "title": "Frontier Squid Caching Proxy Installation Guide"
        }, 
        {
            "location": "/frontier-squid/squid/#about-this-document", 
            "text": "This document is intended for System Administrators who are installing frontier-squid , the OSG distribution of the Frontier Squid software.", 
            "title": "About This Document"
        }, 
        {
            "location": "/frontier-squid/squid/#applicable-versions", 
            "text": "The applicable software versions for this document are OSG Version  =\n3.2.16. The version of frontier-squid installed should be  = 2.7.STABLE9-19.1", 
            "title": "Applicable Versions"
        }, 
        {
            "location": "/frontier-squid/squid/#about-frontier-squid", 
            "text": "Frontier Squid is a distribution of the well-known  squid HTTP caching\nproxy software  that is optimized for use with\napplications on the Worldwide LHC Computing Grid (WLCG). It has  many\nadvantages \nover regular squid for common grid applications, especially Frontier and\nCVMFS.  The OSG distribution of frontier-squid is a straight rebuild of the\nupstream frontier-squid package for the convenience of OSG users.", 
            "title": "About Frontier Squid"
        }, 
        {
            "location": "/frontier-squid/squid/#frontier-squid-is-recommended", 
            "text": "OSG recommends that all sites run a caching proxy for HTTP and HTTPS to\nhelp reduce bandwidth and improve throughput. To that end, Compute\nElement (CE) installations include Frontier Squid automatically. We\nencourage all sites to configure and use this service, as described\nbelow.  For large sites that expect heavy load on the proxy, it may be best to\nrun the proxy on its own host. In that case, the Frontier Squid software\nstill will be installed on the CE, but it need not be enabled. Instead,\ninstall your proxy service on the separate host and then configure the\nCE host to refer to the proxy on that host.  The  osg-configure  configuration tool (version 1.0.45 and later) warns\nusers who have not added the proxy location to their CE configuration.\nIn the future, a proxy will be required and osg-configure will fail if\nthe proxy location is not set.", 
            "title": "Frontier Squid is Recommended"
        }, 
        {
            "location": "/frontier-squid/squid/#engineering-considerations", 
            "text": "If you will be supporting the Frontier application at your site, review\nthe  upstream documentation Hardware considerations\nsection \nto determine how to size your equipment.", 
            "title": "Engineering Considerations"
        }, 
        {
            "location": "/frontier-squid/squid/#requirements", 
            "text": "", 
            "title": "Requirements"
        }, 
        {
            "location": "/frontier-squid/squid/#host-and-os", 
            "text": "OS is Red Hat Enterprise Linux 5, 6, 7, and variants  Root access", 
            "title": "Host and OS"
        }, 
        {
            "location": "/frontier-squid/squid/#users-the-frontier-squid-installation-will-create-one-user-account", 
            "text": "unless it already exists.     User  Comment      squid  Reduced privilege user that the squid process runs under. Set the default gid of the \u201csquid\u201d user to be a group that is also called \u201csquid\u201d.     The package can instead use another user name of your choice if you\ncreate a configuration file before installation. Details are in the upstream documentation Preparation\nsection .", 
            "title": "Users The frontier-squid installation will create one user account"
        }, 
        {
            "location": "/frontier-squid/squid/#networking", 
            "text": "Service Name  Protocol  Port Number  Inbound  Outbound  Comment      Squid  tcp  3128  \u2713  \u2713  Also limited in squid ACLs. Both in and outbound must not be wide open to internet simultaneously    Squid monitor  udp  3401  \u2713   Also limited in squid ACLs. Should be limited to monitoring server addresses     The addresses of the WLCG monitoring servers for use in firewalls are\nlisted in the  upstream documentation Enabling monitoring\nsection .", 
            "title": "Networking"
        }, 
        {
            "location": "/frontier-squid/squid/#install-instructions", 
            "text": "Prior to installing squid, make sure the host's  yum  repositories are  configured correctly  for OSG.  Once configured, install  frontier-squid :  [root@client ~]$ yum install frontier-squid  Then enable it to start at boot:  [root@client ~]$ chkconfig frontier-squid on", 
            "title": "Install Instructions"
        }, 
        {
            "location": "/frontier-squid/squid/#configuring-frontier-squid", 
            "text": "", 
            "title": "Configuring Frontier Squid"
        }, 
        {
            "location": "/frontier-squid/squid/#configuring-the-frontier-squid-service", 
            "text": "To configure the Frontier Squid service itself:   Follow the  original Frontier Squid\n    documentation ,\n    in  the Configuration\n    section \\  Enable, start, and test the service (as described below)  Enable WLCG monitoring as described in the  upstream documentation\n    on enabling\n    monitoring \n    and  register the squid in\n    OIM .    Note  An important difference between the standard Squid\nsoftware and the Frontier Squid variant is that Frontier Squid\nchanges are in  /etc/squid/customize.sh  instead of /etc/squid/squid.conf .", 
            "title": "Configuring the Frontier Squid Service"
        }, 
        {
            "location": "/frontier-squid/squid/#configuring-the-osg-ce", 
            "text": "To configure the OSG Compute Element (CE) to know about your Frontier\nSquid service:    On your CE host, edit  /etc/osg/config.d/01-squid.ini   Make sure that  enabled  is set to  True  Set  location  to the hostname and port of your Frontier Squid\n    service (e.g.,  my.squid.host.edu:3128 )  Leave the other settings at  DEFAULT  unless you have specific\n    reasons to change them     Run  osg-configure  to propagate the changes on your CE     Note  You may want to finish other CE configuration tasks before running osg-configure . Just be sure to run it once before starting CE services.", 
            "title": "Configuring the OSG CE"
        }, 
        {
            "location": "/frontier-squid/squid/#starting-and-stopping-the-frontier-squid-service", 
            "text": "Starting frontier-squid:  UCL_ROOT_PROMPT  service frontier-squid start   Stopping frontier-squid:  UCL_ROOT_PROMPT  service frontier-squid stop", 
            "title": "Starting and Stopping the Frontier Squid Service"
        }, 
        {
            "location": "/frontier-squid/squid/#testing-frontier-squid", 
            "text": "As any user on another computer, do the following (where yoursquid.your.domain  is\nthe fully qualified domain name of your squid server):  [user@client ~]$ export http_proxy=http://yoursquid.your.domain:3128\n[user@client ~]$ wget -qdO/dev/null http://frontier.cern.ch 2 1|grep X-Cache\nX-Cache: MISS from yoursquid.your.domain\n[user@client ~]$ wget -qdO/dev/null http://frontier.cern.ch 2 1|grep X-Cache\nX-Cache: HIT from yoursquid.your.domain  If the grep doesn\u2019t print anything, try removing it from the pipeline to\nsee if errors are obvious. If the second try says  MISS  again, something\nis probably wrong with the squid cache writes.  If your squid will be supporting the Frontier application, it is also\ngood to do the test in the  upstream documentation Testing the\ninstallation\nsection .", 
            "title": "Testing Frontier Squid"
        }, 
        {
            "location": "/frontier-squid/squid/#frontier-squid-log-files", 
            "text": "Log file contents are explained in the  upstream documentation Log file\ncontents section .", 
            "title": "Frontier Squid Log Files"
        }, 
        {
            "location": "/frontier-squid/squid/#getting-help", 
            "text": "To get assistance please use  Help Procedure .", 
            "title": "Getting Help"
        }, 
        {
            "location": "/storage/gridftp/", 
            "text": "Installing and Maintaining a GridFTP Server\n\n\nAbout This Guide\n\n\nThis page explains how to install the stand-alone Globus GridFTP server.\n\n\nThe GridFTP package contains components necessary to set up a stand-alone gsiftp server and tools used to monitor and report its performance. A stand-alone GridFTP server might be used under the following circumstances:\n\n\n\n\nYou are serving VOs that use storage heavily (CMS, ATLAS, CDF, and D0) and your site has more than 250 cores\n\n\nYour site will be managing more than 50 TB of disk space\n\n\nA simple front-end to a filesystem allowing access over WAN - for example NFS.\n\n\n\n\n\n\nNote\n\n\nThis document is for a standalone GridFTP server on top of POSIX storage.  \nSee this page\n for installation and configuration of a GridFTP server on top of the Hadoop Distributed File System.\n\n\n\n\nBefore Starting\n\n\nBefore starting the installation process you will need to fulfill these prerequisites.\n\n\n\n\nEnsure the host has \na supported operating system\n\n\nObtain root access to the host\n\n\nPrepare \nthe required Yum repositories\n\n\nInstall \nCA certificates\n\n\nService certificate: The GridFTP service uses a host certificate at \n/etc/grid-security/hostcert.pem\n and an accompanying key at \n/etc/grid-security/hostkey.pem\n\n\nNetwork ports: GridFTP listens on TCP port 2811 and the list of ports configured by the \nGLOBUS_TCP_SOURCE_RANGE\n environment variable.\n\n\n\n\nInstalling GridFTP\n\n\nFirst, you will need to install the GridFTP meta-package:\n\n\n[root@client ~] #\n yum install osg-gridftp\n\n\n\n\n\nConfiguring GridFTP\n\n\nConfiguring authentication\n\n\nIn OSG 3.3, there are three methods to manage authentication for incoming jobs: the \nLCMAPS VOMS plugin\n, \nedg-mkgridmap\n and \nGUMS\n. Of these, GUMS has the most features and capabilities. The LCMAPS VOMS plugin is the new OSG-preferred authentication, offering the simplicity of edg-mkgridmap and many of GUMS' rich feature set. If you need to support \"\npool accounts\n\", GUMS is the only option with that capability.\n\n\nIn OSG 3.4, the LCMAPS VOMS plugin is the only available authentication solution.\n\n\nAuthentication with the LCMAPS VOMS plugin\n\n\n\n\n\n\nAdd the following line to \n/etc/sysconfig/globus-gridftp-server\n:\n\n\nexport\n \nLLGT_VOMS_ENABLE_CREDENTIAL_CHECK\n=\n1\n\n\n\n\n\n\nThis should \nonly\n be done for OSG 3.3; it is unnecessary for OSG 3.4.\n\n\n\n\n\n\nFollow the instructions in \nthe LCMAPS VOMS plugin installation and configuration document\n to prepare the LCMAPS VOMS plugin.\n\n\n\n\n\n\n\n\nNote\n\n\nThis is the suggested mechanism for all new installs.\n\n\n\n\nAuthentication with edg-mkgridmap\n\n\n\n\nWarning\n\n\nAs of the June 2017 release of OSG 3.4.0, this software is officially deprecated. Support is scheduled to end as of June 2018.\n\n\n\n\nBy default, GridFTP uses a gridmap file, found in \n/etc/grid-security/grid-mapfile\n. This is the file generated by \nedg-mkgridmap\n if you follow the default \ninstall instructions\n.  No further configuration is needed.\n\n\nAuthentication with GUMS\n\n\n\n\nWarning\n\n\nAs of the June 2017 release of OSG 3.4.0, this software is officially deprecated. Support is scheduled to end as of June 2018.\n\n\n\n\nIf you want to use GUMS security (recommended), you will need to enable it using the following steps:\n\n\n\n\n\n\nEdit \n/etc/grid-security/gsi-authz.conf\n and uncomment the globus callout.\n\n\nglobus_mapping liblcas_lcmaps_gt4_mapping.so lcmaps_callout\n\n\n\n\n\nNote that this used to be the full path to the library (\n/usr/lib64\n or \n/usr/lib\n), but now we rely on the linker for proper resolution in this file.\n\n\n\n\n\n\nEdit \n/etc/lcmaps.db\n to include your service endpoint:\n\n\n...\ngumsclient = \nlcmaps_gums_client.mod\n\n             \n-resourcetype ce\n\n             \n-actiontype execute-now\n\n             \n-capath /etc/grid-security/certificates\n\n             \n-cert   /etc/grid-security/hostcert.pem\n\n             \n-key    /etc/grid-security/hostkey.pem\n\n             \n--cert-owner root\n\n# Change this URL to your GUMS server\n             \n--endpoint https://\ngums.example.com:8443\n/gums/services/GUMSXACMLAuthorizationServicePort\n\n\n\n\n\n\n\n\n\n\nEnabling Gratia GridFTP transfer probe\n\n\nThe \nGratia GridFTP probe\n collects the information about the Gridftp transfers and forwards it to central Gratia collector. You need to enable the probe first. To do this, edit \n/etc/gratia/gridftp-transfer/ProbeConfig\n to set:\n\n\nEnableProbe=\n1\n\n\n\n\n\n\nAll other configuration settings should be suitable for most purposes. However, you can edit them if needed. The probe runs every 30 minutes as a cron job.\n\n\nOptional configuration\n\n\nModifying the environment\n\n\nEnvironment variables are stored in \n/etc/sysconfig/globus-gridftp-server\n which is sourced on service startup.  If you want to change LCMAPS log levels, or GridFTP port ranges, you can edit them there.\n\n\n#Uncomment and modify for firewalls\n\n\n#export GLOBUS_TCP_PORT_RANGE=min,max\n\n\n#export GLOBUS_TCP_SOURCE_RANGE=min,max\n\n\n\n\n\n\nNote that the variables \nGLOBUS_TCP_PORT_RANGE\n and \nGLOBUS_TCP_SOURCE_RANGE\n can be set here to allow GridFTP to navigate around firewall rules (these affect the inbound and outbound ports, respectively).\n\n\nTo troubleshoot LCMAPS authorization, you can add the following to \n/etc/sysconfig/globus-gridftp-server\n and choose a higher debug level:\n\n\n# level 0: no messages, 1: errors, 2: also warnings, 3: also notices,\n#  4: also info, 5: maximum debug\nLCMAPS_DEBUG_LEVEL=2\n\n\n\n\n\nOutput goes to \n/var/log/messages\n by default. Do not set logging to 5 on any production systems as that may cause systems to slow down significantly or become unresponsive.\n\n\nConfiguring a multi-homed server\n\n\nThe GridFTP uses control connections, data connections and IPC connections. By default it listens in all interfaces but this can be changed by editing the configuration file \n/etc/gridftp.conf\n.\n\n\nTo use a single interface you can set \nhostname\n to the Hostname or IP address to use:\n\n\nhostname IP-TO-USE\n\n\n\n\n\nYou can also set separately the \ncontrol_interface\n, \ndata_interface\n and \nipc_interface\n.  On systems that have multiple network interfaces, you may want to associate data transfers with the fastest possible NIC available. This can be done in the GridFTP server by setting \ndata_interface\n:\n\n\ncontrol_interface IP-TO-USE\ndata_interface IP-TO-USE\nipc_interface IP-TO-USE\n\n\n\n\n\nFor more options available for the GridFTP server, read the comments in the configuration file (\n/etc/gridftp.conf\n) or see the \nGlobus manual\n.\n\n\nManaging GridFTP\n\n\nIn addition to the GridFTP service itself, there are a number of supporting services in your installation. The specific services are:\n\n\n\n\n\n\n\n\nSoftware\n\n\nService name\n\n\nNotes\n\n\n\n\n\n\n\n\n\n\nFetch CRL\n\n\nfetch-crl-boot\n and \nfetch-crl-cron\n\n\nSee \nCA documentation\n for more info\n\n\n\n\n\n\nGratia\n\n\ngratia-probes-cron\n\n\nAccounting software\n\n\n\n\n\n\nGridFTP\n\n\nglobus-gridftp-server\n\n\n\n\n\n\n\n\n\n\nValidating GridFTP\n\n\nThe GridFTP service can be validated by using globus-url-copy. You will need to run \ngrid-proxy-init\n or \nvoms-proxy-init\n in order to get a valid user proxy in order to communicate with the GridFTP server.\n\n\n[root@client ~] #\n globus-url-copy file:///tmp/zero.source gsiftp://yourhost.yourdomain/tmp/zero\n\n[root@client ~] #\n \necho\n \n$?\n\n\n0\n\n\n\n\n\n\nRun the validation as an unprivileged user; when invoked as root, \nglobus-url-copy\n will attempt to use the host certificate instead of your user certificate, with confusing results.\n\n\nGetting Help\n\n\nFor assistance, please use \nthis page\n.\n\n\nReference\n\n\n\n\nGlobus GridFTP administration manual\n\n\nGlobus GridFTP tutorial\n\n\n\n\nConfiguration and Log Files\n\n\n\n\n\n\n\n\nService/Process\n\n\nConfiguration File\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nGridFTP\n\n\n/etc/sysconfig/globus-gridftp-server\n\n\nEnvironment variables for GridFTP and LCMAPS\n\n\n\n\n\n\n\n\n/usr/share/osg/sysconfig/globus-gridftp-server-plugin\n\n\nWhere environment variables for GridFTP plugin are included\n\n\n\n\n\n\nGratia Probe\n\n\n/etc/gratia/gridftp-transfer/ProbeConfig\n\n\nGridFTP Gratia Probe configuration\n\n\n\n\n\n\nGratia Probe\n\n\n/etc/cron.d/gratia-probe-gridftp-transfer.cron\n\n\nCron tab file\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nService/Process\n\n\nLog File\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nGridFTP\n\n\n/var/log/gridftp.log\n\n\nGridFTP transfer log\n\n\n\n\n\n\n\n\n/var/log/gridftp-auth.log\n\n\nGridFTP authorization log\n\n\n\n\n\n\nGratia probe\n\n\n/var/logs/gratia\n\n\n\n\n\n\n\n\n\n\nCertificates\n\n\n\n\n\n\n\n\nCertificate\n\n\nUser that owns certificate\n\n\nPath to certificate\n\n\n\n\n\n\n\n\n\n\nHost certificate\n\n\nroot\n\n\n/etc/grid-security/hostcert.pem\n and \n/etc/grid-security/hostkey.pem\n\n\n\n\n\n\n\n\nInstructions\n to request a service certificate.\n\n\nYou will also need a copy of CA certificates.\n\n\nUsers\n\n\nFor this package to function correctly, you will have to create the users needed for grid operation. Any Unix username that can be mapped by LCMAPS VOMS, \nedg-mkgridmap\n, or GUMS should be created on the GridFTP host.\n\n\nFor example, VOs newly-added to the LCMAPS VOMS configuration will not be able to transfer files until the corresponding Unix user account is created.\n\n\nNetworking\n\n\nFor more details on overall firewall configuration, please see our \nfirewall documentation\n.\n\n\n\n\n\n\n\n\nService Name\n\n\nProtocol\n\n\nPort Number\n\n\nInbound\n\n\nOutbound\n\n\nComment\n\n\n\n\n\n\n\n\n\n\nGridFTP data channels\n\n\ntcp\n\n\nGLOBUS_TCP_PORT_RANGE\n\n\nX\n\n\n\n\ncontiguous range of ports is necessary.\n\n\n\n\n\n\nGridFTP data channels\n\n\ntcp\n\n\nGLOBUS_TCP_SOURCE_RANGE\n\n\n\n\nX\n\n\ncontiguous range of ports is necessary.\n\n\n\n\n\n\nGridFTP control channel\n\n\ntcp\n\n\n2811\n\n\nX", 
            "title": "GridFTP Server"
        }, 
        {
            "location": "/storage/gridftp/#installing-and-maintaining-a-gridftp-server", 
            "text": "", 
            "title": "Installing and Maintaining a GridFTP Server"
        }, 
        {
            "location": "/storage/gridftp/#about-this-guide", 
            "text": "This page explains how to install the stand-alone Globus GridFTP server.  The GridFTP package contains components necessary to set up a stand-alone gsiftp server and tools used to monitor and report its performance. A stand-alone GridFTP server might be used under the following circumstances:   You are serving VOs that use storage heavily (CMS, ATLAS, CDF, and D0) and your site has more than 250 cores  Your site will be managing more than 50 TB of disk space  A simple front-end to a filesystem allowing access over WAN - for example NFS.    Note  This document is for a standalone GridFTP server on top of POSIX storage.   See this page  for installation and configuration of a GridFTP server on top of the Hadoop Distributed File System.", 
            "title": "About This Guide"
        }, 
        {
            "location": "/storage/gridftp/#before-starting", 
            "text": "Before starting the installation process you will need to fulfill these prerequisites.   Ensure the host has  a supported operating system  Obtain root access to the host  Prepare  the required Yum repositories  Install  CA certificates  Service certificate: The GridFTP service uses a host certificate at  /etc/grid-security/hostcert.pem  and an accompanying key at  /etc/grid-security/hostkey.pem  Network ports: GridFTP listens on TCP port 2811 and the list of ports configured by the  GLOBUS_TCP_SOURCE_RANGE  environment variable.", 
            "title": "Before Starting"
        }, 
        {
            "location": "/storage/gridftp/#installing-gridftp", 
            "text": "First, you will need to install the GridFTP meta-package:  [root@client ~] #  yum install osg-gridftp", 
            "title": "Installing GridFTP"
        }, 
        {
            "location": "/storage/gridftp/#configuring-gridftp", 
            "text": "", 
            "title": "Configuring GridFTP"
        }, 
        {
            "location": "/storage/gridftp/#configuring-authentication", 
            "text": "In OSG 3.3, there are three methods to manage authentication for incoming jobs: the  LCMAPS VOMS plugin ,  edg-mkgridmap  and  GUMS . Of these, GUMS has the most features and capabilities. The LCMAPS VOMS plugin is the new OSG-preferred authentication, offering the simplicity of edg-mkgridmap and many of GUMS' rich feature set. If you need to support \" pool accounts \", GUMS is the only option with that capability.  In OSG 3.4, the LCMAPS VOMS plugin is the only available authentication solution.", 
            "title": "Configuring authentication"
        }, 
        {
            "location": "/storage/gridftp/#authentication-with-the-lcmaps-voms-plugin", 
            "text": "Add the following line to  /etc/sysconfig/globus-gridftp-server :  export   LLGT_VOMS_ENABLE_CREDENTIAL_CHECK = 1   This should  only  be done for OSG 3.3; it is unnecessary for OSG 3.4.    Follow the instructions in  the LCMAPS VOMS plugin installation and configuration document  to prepare the LCMAPS VOMS plugin.     Note  This is the suggested mechanism for all new installs.", 
            "title": "Authentication with the LCMAPS VOMS plugin"
        }, 
        {
            "location": "/storage/gridftp/#authentication-with-edg-mkgridmap", 
            "text": "Warning  As of the June 2017 release of OSG 3.4.0, this software is officially deprecated. Support is scheduled to end as of June 2018.   By default, GridFTP uses a gridmap file, found in  /etc/grid-security/grid-mapfile . This is the file generated by  edg-mkgridmap  if you follow the default  install instructions .  No further configuration is needed.", 
            "title": "Authentication with edg-mkgridmap"
        }, 
        {
            "location": "/storage/gridftp/#authentication-with-gums", 
            "text": "Warning  As of the June 2017 release of OSG 3.4.0, this software is officially deprecated. Support is scheduled to end as of June 2018.   If you want to use GUMS security (recommended), you will need to enable it using the following steps:    Edit  /etc/grid-security/gsi-authz.conf  and uncomment the globus callout.  globus_mapping liblcas_lcmaps_gt4_mapping.so lcmaps_callout  Note that this used to be the full path to the library ( /usr/lib64  or  /usr/lib ), but now we rely on the linker for proper resolution in this file.    Edit  /etc/lcmaps.db  to include your service endpoint:  ...\ngumsclient =  lcmaps_gums_client.mod \n              -resourcetype ce \n              -actiontype execute-now \n              -capath /etc/grid-security/certificates \n              -cert   /etc/grid-security/hostcert.pem \n              -key    /etc/grid-security/hostkey.pem \n              --cert-owner root \n# Change this URL to your GUMS server\n              --endpoint https:// gums.example.com:8443 /gums/services/GUMSXACMLAuthorizationServicePort", 
            "title": "Authentication with GUMS"
        }, 
        {
            "location": "/storage/gridftp/#enabling-gratia-gridftp-transfer-probe", 
            "text": "The  Gratia GridFTP probe  collects the information about the Gridftp transfers and forwards it to central Gratia collector. You need to enable the probe first. To do this, edit  /etc/gratia/gridftp-transfer/ProbeConfig  to set:  EnableProbe= 1   All other configuration settings should be suitable for most purposes. However, you can edit them if needed. The probe runs every 30 minutes as a cron job.", 
            "title": "Enabling Gratia GridFTP transfer probe"
        }, 
        {
            "location": "/storage/gridftp/#optional-configuration", 
            "text": "", 
            "title": "Optional configuration"
        }, 
        {
            "location": "/storage/gridftp/#modifying-the-environment", 
            "text": "Environment variables are stored in  /etc/sysconfig/globus-gridftp-server  which is sourced on service startup.  If you want to change LCMAPS log levels, or GridFTP port ranges, you can edit them there.  #Uncomment and modify for firewalls  #export GLOBUS_TCP_PORT_RANGE=min,max  #export GLOBUS_TCP_SOURCE_RANGE=min,max   Note that the variables  GLOBUS_TCP_PORT_RANGE  and  GLOBUS_TCP_SOURCE_RANGE  can be set here to allow GridFTP to navigate around firewall rules (these affect the inbound and outbound ports, respectively).  To troubleshoot LCMAPS authorization, you can add the following to  /etc/sysconfig/globus-gridftp-server  and choose a higher debug level:  # level 0: no messages, 1: errors, 2: also warnings, 3: also notices,\n#  4: also info, 5: maximum debug\nLCMAPS_DEBUG_LEVEL=2  Output goes to  /var/log/messages  by default. Do not set logging to 5 on any production systems as that may cause systems to slow down significantly or become unresponsive.", 
            "title": "Modifying the environment"
        }, 
        {
            "location": "/storage/gridftp/#configuring-a-multi-homed-server", 
            "text": "The GridFTP uses control connections, data connections and IPC connections. By default it listens in all interfaces but this can be changed by editing the configuration file  /etc/gridftp.conf .  To use a single interface you can set  hostname  to the Hostname or IP address to use:  hostname IP-TO-USE  You can also set separately the  control_interface ,  data_interface  and  ipc_interface .  On systems that have multiple network interfaces, you may want to associate data transfers with the fastest possible NIC available. This can be done in the GridFTP server by setting  data_interface :  control_interface IP-TO-USE\ndata_interface IP-TO-USE\nipc_interface IP-TO-USE  For more options available for the GridFTP server, read the comments in the configuration file ( /etc/gridftp.conf ) or see the  Globus manual .", 
            "title": "Configuring a multi-homed server"
        }, 
        {
            "location": "/storage/gridftp/#managing-gridftp", 
            "text": "In addition to the GridFTP service itself, there are a number of supporting services in your installation. The specific services are:     Software  Service name  Notes      Fetch CRL  fetch-crl-boot  and  fetch-crl-cron  See  CA documentation  for more info    Gratia  gratia-probes-cron  Accounting software    GridFTP  globus-gridftp-server", 
            "title": "Managing GridFTP"
        }, 
        {
            "location": "/storage/gridftp/#validating-gridftp", 
            "text": "The GridFTP service can be validated by using globus-url-copy. You will need to run  grid-proxy-init  or  voms-proxy-init  in order to get a valid user proxy in order to communicate with the GridFTP server.  [root@client ~] #  globus-url-copy file:///tmp/zero.source gsiftp://yourhost.yourdomain/tmp/zero [root@client ~] #   echo   $?  0   Run the validation as an unprivileged user; when invoked as root,  globus-url-copy  will attempt to use the host certificate instead of your user certificate, with confusing results.", 
            "title": "Validating GridFTP"
        }, 
        {
            "location": "/storage/gridftp/#getting-help", 
            "text": "For assistance, please use  this page .", 
            "title": "Getting Help"
        }, 
        {
            "location": "/storage/gridftp/#reference", 
            "text": "Globus GridFTP administration manual  Globus GridFTP tutorial", 
            "title": "Reference"
        }, 
        {
            "location": "/storage/gridftp/#configuration-and-log-files", 
            "text": "Service/Process  Configuration File  Description      GridFTP  /etc/sysconfig/globus-gridftp-server  Environment variables for GridFTP and LCMAPS     /usr/share/osg/sysconfig/globus-gridftp-server-plugin  Where environment variables for GridFTP plugin are included    Gratia Probe  /etc/gratia/gridftp-transfer/ProbeConfig  GridFTP Gratia Probe configuration    Gratia Probe  /etc/cron.d/gratia-probe-gridftp-transfer.cron  Cron tab file        Service/Process  Log File  Description      GridFTP  /var/log/gridftp.log  GridFTP transfer log     /var/log/gridftp-auth.log  GridFTP authorization log    Gratia probe  /var/logs/gratia", 
            "title": "Configuration and Log Files"
        }, 
        {
            "location": "/storage/gridftp/#certificates", 
            "text": "Certificate  User that owns certificate  Path to certificate      Host certificate  root  /etc/grid-security/hostcert.pem  and  /etc/grid-security/hostkey.pem     Instructions  to request a service certificate.  You will also need a copy of CA certificates.", 
            "title": "Certificates"
        }, 
        {
            "location": "/storage/gridftp/#users", 
            "text": "For this package to function correctly, you will have to create the users needed for grid operation. Any Unix username that can be mapped by LCMAPS VOMS,  edg-mkgridmap , or GUMS should be created on the GridFTP host.  For example, VOs newly-added to the LCMAPS VOMS configuration will not be able to transfer files until the corresponding Unix user account is created.", 
            "title": "Users"
        }, 
        {
            "location": "/storage/gridftp/#networking", 
            "text": "For more details on overall firewall configuration, please see our  firewall documentation .     Service Name  Protocol  Port Number  Inbound  Outbound  Comment      GridFTP data channels  tcp  GLOBUS_TCP_PORT_RANGE  X   contiguous range of ports is necessary.    GridFTP data channels  tcp  GLOBUS_TCP_SOURCE_RANGE   X  contiguous range of ports is necessary.    GridFTP control channel  tcp  2811  X", 
            "title": "Networking"
        }, 
        {
            "location": "/release/release_series/", 
            "text": "OSG Release Series\n\n\nAn OSG release series is a sequence of OSG software releases that are intended to provide a painless upgrade path. For example, the 3.2 release series contains OSG software 3.2.0, 3.2.1, 3.2.2, and so forth. A release series corresponds to a set of Yum software repositories, including ones for development, testing, and production use. The Yum repositories for one release series are completely distinct from the repositories for a different release series, even though they share many common packages.  A particular release within a series is a snapshot of packages and their exact versions at one point in time. When you install software from a release series, say 3.2, you get the most current versions of software packages within that series, regardless of the current release version.\n\n\nWhen a new series is released, it is an opportunity for the OSG Technology area to add major new software packages, make substantial updates to existing packages, and remove obsolete packages. When a new series is initially released, most packages are identical to the previous release, but two adjacent series will diverge over time.\n\n\nOur goal is, within a series, that one may upgrade their OSG services via \nyum update\n cleanly and without any necessary config file changes or excessive downtime.\n\n\nOSG Release Series\n\n\nSince the start of the RPM-based OSG software stack, we have offered the following release series:\n\n\n\n\n\n\nOSG 3.1\n started in April 2012, and was end-of-lifed in April 2015. While the files have not been removed, it is strongly recommended that it not be installed anymore. Historically, there were 3.0.x releases as well, but there was no separate release series for 3.0 and 3.1; we simply went from 3.0.10 to 3.1.0 in the same repositories.\n\n\n\n\n\n\nOSG 3.2\n started in November 2013, and was end-of-lifed in August 2016. While the files have not been removed, it is strongly recommended that it not be installed anymore. The main differences between it and 3.1 were the introduction of glideinWMS 3.2, HTCondor 8.0, and Hadoop/HDFS 2.0; also the gLite CE Monitor system was dropped in favor of osg-info-services.\n\n\n\n\n\n\nOSG 3.3\n started in August 2015 and is still supported today.  End-of-support is scheduled for June 2018; sites are encouraged to investigate the upgrade to OSG 3.4. The main differences between 3.3 and 3.2 are the dropping of EL5 support, the addition of EL7 support, and the dropping of Globus GRAM support.\n\n\n\n\n\n\nOSG 3.4\n stared June 2017. The main differences between it and 3.3 are the removal of edg-mkgridmap, GUMS, BeStMan, and VOMS Admin Server packages.\n\n\n\n\n\n\nOSG Upcoming\n\n\nThere is one more OSG Series called \"upcoming\" which contains major updates planned for a future release series. The yum repositories for upcoming (\nosg-upcoming\n and \nosg-upcoming-testing\n) are available from all OSG 3.x series, and individual packages can be installed from Upcoming without needing to update entirely to a new series. Note, however, that packages in the \"upcoming\" repositories are tested against the most recent OSG series.  As of the time of writing, \nosg-upcoming\n is meant to work with OSG 3.4.\n\n\nInstalling an OSG Release Series\n\n\nSee the \nyum repositories document\n for instructions on installing the OSG repositories.\n\n\nUpdating from OSG 3.1, 3.2, 3.3 to 3.3 or 3.4\n\n\n\n\n\n\nIf you have an existing installation based on OSG 3.1, 3.2, or 3.3 (which will be referred to as the \nold series\n), and want to upgrade to 3.3 or 3.4 (the \nnew series\n), we recommend the following procedure:\n\n\nFirst, remove the old series yum repositories:\n\n\n[root@client ~] #\n rpm -e osg-release\n\n\n\n\n\nThis step ensures that any local modifications to \n*.repo\n files will not prevent installing the new series repos. Any modified \n*.repo\n files should appear under \n/etc/yum.repos.d/\n with the \n*.rpmsave\n extension. After installing the new OSG repositories (the next step) you may want to apply any changes made in the \n*.rpmsave\n files to the new \n*.repo\n files.\n\n\n\n\n\n\nInstall the OSG repositories:\n\n\n[root@client ~] #\n rpm -Uvh \nURL\n\n\n\n\n\n\nwhere \nURL\n is one of the following:\n\n\n\n\n\n\n\n\nSeries\n\n\nEL5 URL (for RHEL5, CentOS5, or SL5)\n\n\nEL6 URL (for RHEL6, CentOS6, or SL6)\n\n\nEL7 URL (for RHEL7, CentOS7, or SL7)\n\n\n\n\n\n\n\n\n\n\nOSG 3.1\n (unsupported)\n\n\nhttp://repo.grid.iu.edu/osg/3.1/osg-3.1-el5-release-latest.rpm\n\n\nhttp://repo.grid.iu.edu/osg/3.1/osg-3.1-el6-release-latest.rpm\n\n\nN/A\n\n\n\n\n\n\nOSG 3.2\n (unsupported)\n\n\nhttp://repo.grid.iu.edu/osg/3.2/osg-3.2-el5-release-latest.rpm\n\n\nhttp://repo.grid.iu.edu/osg/3.2/osg-3.2-el6-release-latest.rpm\n\n\nN/A\n\n\n\n\n\n\nOSG 3.3\n\n\nN/A\n\n\nhttp://repo.grid.iu.edu/osg/3.3/osg-3.3-el6-release-latest.rpm\n\n\nhttp://repo.grid.iu.edu/osg/3.3/osg-3.3-el7-release-latest.rpm\n\n\n\n\n\n\nOSG 3.4\n\n\nN/A\n\n\nhttp://repo.grid.iu.edu/osg/3.4/osg-3.4-el6-release-latest.rpm\n\n\nhttp://repo.grid.iu.edu/osg/3.4/osg-3.4-el7-release-latest.rpm\n\n\n\n\n\n\n\n\n\n\n\n\nClean yum cache:\n\n\n[root@client ~] #\n yum clean all --enablerepo\n=\n*\n\n\n\n\n\n\n\n\n\nUpdate software:\n\n\n[root@client ~] #\n yum update\n\n\n\n\n\n\n\n\n\nThis command will update \nall\n packages on your system.\n\n\nTroubleshooting\n If you are not having the expected result or having problems with Yum please see the \nYum troubleshooting guide\n\n\nMigrating from edg-mkgridmap to LCMAPS VOMS Plugin\n\n\nAfter following the update instructions above, perform the migration process documented \nhere\n.\n\n\nUpdating from Frontier Squid 2.7 to Frontier Squid 3.5 (upgrading from OSG 3.3)\n\n\nThe program \nfrontier-squid\n received a major version upgrade (versions 2.7 to 3.5) between OSG 3.3 and OSG 3.4. Follow the \nupstream upgrade documentation\n when transitioning your squid server to OSG 3.4.\n\n\nUninstalling BeStMan2 from the Storage Element (upgrading to OSG 3.4)\n\n\nThe program BeStMan2 is no longer available in OSG 3.4 and its functionality has been replaced by \nload-balanced GridFTP\n. To update your storage element to OSG 3.4, you must perform the following procedure:\n\n\n\n\n\n\nEnsure that OSG BeStMan packages are installed:\n\n\n[root@client ~] #\n rpm -q osg-se-bestman\n\n\n\n\n\n\n\n\n\nStop the \nbestman2\n service:\n\n\n[root@client ~] #\n service bestman2 stop\n\n\n\n\n\n\n\n\n\nUninstall the software:\n\n\n[root@client ~] #\n yum erase bestman2-tester-libs bestman2-common-libs \n\\\n\n                            bestman2-server-libs bestman2-server-dep-libs \n\\\n\n                            bestman2-client-libs bestman2-tester bestman2-client \n\\\n\n                            bestman2-server osg-se-bestman\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nIn the output from this command, yum should \nnot\n list other packages than those nine. If it lists other packages, cancel the erase operation, make sure the other packages are updated to their latest OSG 3.3 versions, and try again.\n\n\n\n\nAfter successfully removing BeStMan2, continue updating your host to OSG 3.4 by following the instructions above.\n\n\nUninstalling OSG Info Services from the Compute Element (upgrading from OSG 3.3 or 3.2)\n\n\nThe program OSG Info Services is no longer required on OSG 3.3, and is no longer available starting in OSG 3.4. This is because the service that OSG Info Services reported to, named BDII, has been retired and is no longer functional.\n\n\nTo cleanly uninstall OSG Info Services from your CE, perform the following procedure (after following the main update instructions above):\n\n\n\n\n\n\nEnsure that you are using a sufficiently new version of the \nosg-ce\n metapackages:\n\n\n[root@client ~] #\n rpm -q osg-ce\n\n\n\n\n\nshould be at least 3.3-12 (OSG 3.3) or 3.4-1 (OSG 3.4).  If not, update them:\n\n\n[root@client ~] #\n yum update osg-ce\n\n\n\n\n\n\n\n\n\nStop the \nosg-info-services\n service:\n\n\n[root@client ~] #\n service osg-info-services stop\n\n\n\n\n\n\n\n\n\nUninstall the software:\n\n\n[root@client ~] #\n yum erase gip osg-info-services\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nIn the output from this command, yum should \nnot\n list other packages than those two. If it lists other packages, cancel the erase operation, make sure the other packages are updated to their latest OSG 3.3 (or 3.4) versions, and try again.\n\n\n\n\nUninstalling CEMon from the Compute Element (upgrading from OSG 3.1)\n\n\nThe program CEMon (found in the package \nglite-ce-monitor\n) is no longer available starting in OSG 3.2. Its functionality is no longer required because the service that CEMon reported to has been retired and is no longer functional.\n\n\nTo cleanly uninstall CEMon from your CE, perform the following procedure (after following the main update instructions above):\n\n\n\n\n\n\nEnsure that you are using a sufficiently new version of the \nosg-ce\n metapackages:\n\n\n[root@client ~] #\n rpm -q osg-ce\n\n\n\n\n\nshould be at least 3.3-12 (OSG 3.3) or 3.4-1 (OSG 3.4). If not, update them:\n\n\n[root@client ~] #\n yum update osg-ce\n\n\n\n\n\n\n\n\n\nIf there is a CEMon configuration file at \n/etc/osg/config.d/30-cemon.ini\n, remove it.\n\n\n\n\nRemove CEMon and related packages:\n[root@client ~] #\n yum erase glite-ce-monitor glite-ce-osg-ce-plugin osg-configure-cemon\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nIn the output from this command, yum should \nnot\n list other packages than those three. If it lists other packages, cancel the erase operation, make sure the other packages are updated to their OSG 3.3 (or 3.4) versions (they should have \n.osg33\n or \n.osg34\n in their versions), and try again.\n\n\n\n\nReferences\n\n\n\n\nYUM Repositories\n\n\nBasic use of Yum\n\n\nBest practices in using Yum", 
            "title": "OSG Release Series"
        }, 
        {
            "location": "/release/release_series/#osg-release-series", 
            "text": "An OSG release series is a sequence of OSG software releases that are intended to provide a painless upgrade path. For example, the 3.2 release series contains OSG software 3.2.0, 3.2.1, 3.2.2, and so forth. A release series corresponds to a set of Yum software repositories, including ones for development, testing, and production use. The Yum repositories for one release series are completely distinct from the repositories for a different release series, even though they share many common packages.  A particular release within a series is a snapshot of packages and their exact versions at one point in time. When you install software from a release series, say 3.2, you get the most current versions of software packages within that series, regardless of the current release version.  When a new series is released, it is an opportunity for the OSG Technology area to add major new software packages, make substantial updates to existing packages, and remove obsolete packages. When a new series is initially released, most packages are identical to the previous release, but two adjacent series will diverge over time.  Our goal is, within a series, that one may upgrade their OSG services via  yum update  cleanly and without any necessary config file changes or excessive downtime.", 
            "title": "OSG Release Series"
        }, 
        {
            "location": "/release/release_series/#osg-release-series_1", 
            "text": "Since the start of the RPM-based OSG software stack, we have offered the following release series:    OSG 3.1  started in April 2012, and was end-of-lifed in April 2015. While the files have not been removed, it is strongly recommended that it not be installed anymore. Historically, there were 3.0.x releases as well, but there was no separate release series for 3.0 and 3.1; we simply went from 3.0.10 to 3.1.0 in the same repositories.    OSG 3.2  started in November 2013, and was end-of-lifed in August 2016. While the files have not been removed, it is strongly recommended that it not be installed anymore. The main differences between it and 3.1 were the introduction of glideinWMS 3.2, HTCondor 8.0, and Hadoop/HDFS 2.0; also the gLite CE Monitor system was dropped in favor of osg-info-services.    OSG 3.3  started in August 2015 and is still supported today.  End-of-support is scheduled for June 2018; sites are encouraged to investigate the upgrade to OSG 3.4. The main differences between 3.3 and 3.2 are the dropping of EL5 support, the addition of EL7 support, and the dropping of Globus GRAM support.    OSG 3.4  stared June 2017. The main differences between it and 3.3 are the removal of edg-mkgridmap, GUMS, BeStMan, and VOMS Admin Server packages.", 
            "title": "OSG Release Series"
        }, 
        {
            "location": "/release/release_series/#osg-upcoming", 
            "text": "There is one more OSG Series called \"upcoming\" which contains major updates planned for a future release series. The yum repositories for upcoming ( osg-upcoming  and  osg-upcoming-testing ) are available from all OSG 3.x series, and individual packages can be installed from Upcoming without needing to update entirely to a new series. Note, however, that packages in the \"upcoming\" repositories are tested against the most recent OSG series.  As of the time of writing,  osg-upcoming  is meant to work with OSG 3.4.", 
            "title": "OSG Upcoming"
        }, 
        {
            "location": "/release/release_series/#installing-an-osg-release-series", 
            "text": "See the  yum repositories document  for instructions on installing the OSG repositories.", 
            "title": "Installing an OSG Release Series"
        }, 
        {
            "location": "/release/release_series/#updating-from-osg-31-32-33-to-33-or-34", 
            "text": "If you have an existing installation based on OSG 3.1, 3.2, or 3.3 (which will be referred to as the  old series ), and want to upgrade to 3.3 or 3.4 (the  new series ), we recommend the following procedure:  First, remove the old series yum repositories:  [root@client ~] #  rpm -e osg-release  This step ensures that any local modifications to  *.repo  files will not prevent installing the new series repos. Any modified  *.repo  files should appear under  /etc/yum.repos.d/  with the  *.rpmsave  extension. After installing the new OSG repositories (the next step) you may want to apply any changes made in the  *.rpmsave  files to the new  *.repo  files.    Install the OSG repositories:  [root@client ~] #  rpm -Uvh  URL   where  URL  is one of the following:     Series  EL5 URL (for RHEL5, CentOS5, or SL5)  EL6 URL (for RHEL6, CentOS6, or SL6)  EL7 URL (for RHEL7, CentOS7, or SL7)      OSG 3.1  (unsupported)  http://repo.grid.iu.edu/osg/3.1/osg-3.1-el5-release-latest.rpm  http://repo.grid.iu.edu/osg/3.1/osg-3.1-el6-release-latest.rpm  N/A    OSG 3.2  (unsupported)  http://repo.grid.iu.edu/osg/3.2/osg-3.2-el5-release-latest.rpm  http://repo.grid.iu.edu/osg/3.2/osg-3.2-el6-release-latest.rpm  N/A    OSG 3.3  N/A  http://repo.grid.iu.edu/osg/3.3/osg-3.3-el6-release-latest.rpm  http://repo.grid.iu.edu/osg/3.3/osg-3.3-el7-release-latest.rpm    OSG 3.4  N/A  http://repo.grid.iu.edu/osg/3.4/osg-3.4-el6-release-latest.rpm  http://repo.grid.iu.edu/osg/3.4/osg-3.4-el7-release-latest.rpm       Clean yum cache:  [root@client ~] #  yum clean all --enablerepo = *    Update software:  [root@client ~] #  yum update    This command will update  all  packages on your system.  Troubleshooting  If you are not having the expected result or having problems with Yum please see the  Yum troubleshooting guide", 
            "title": "Updating from OSG 3.1, 3.2, 3.3 to 3.3 or 3.4"
        }, 
        {
            "location": "/release/release_series/#migrating-from-edg-mkgridmap-to-lcmaps-voms-plugin", 
            "text": "After following the update instructions above, perform the migration process documented  here .", 
            "title": "Migrating from edg-mkgridmap to LCMAPS VOMS Plugin"
        }, 
        {
            "location": "/release/release_series/#updating-from-frontier-squid-27-to-frontier-squid-35-upgrading-from-osg-33", 
            "text": "The program  frontier-squid  received a major version upgrade (versions 2.7 to 3.5) between OSG 3.3 and OSG 3.4. Follow the  upstream upgrade documentation  when transitioning your squid server to OSG 3.4.", 
            "title": "Updating from Frontier Squid 2.7 to Frontier Squid 3.5 (upgrading from OSG 3.3)"
        }, 
        {
            "location": "/release/release_series/#uninstalling-bestman2-from-the-storage-element-upgrading-to-osg-34", 
            "text": "The program BeStMan2 is no longer available in OSG 3.4 and its functionality has been replaced by  load-balanced GridFTP . To update your storage element to OSG 3.4, you must perform the following procedure:    Ensure that OSG BeStMan packages are installed:  [root@client ~] #  rpm -q osg-se-bestman    Stop the  bestman2  service:  [root@client ~] #  service bestman2 stop    Uninstall the software:  [root@client ~] #  yum erase bestman2-tester-libs bestman2-common-libs  \\ \n                            bestman2-server-libs bestman2-server-dep-libs  \\ \n                            bestman2-client-libs bestman2-tester bestman2-client  \\ \n                            bestman2-server osg-se-bestman     Note  In the output from this command, yum should  not  list other packages than those nine. If it lists other packages, cancel the erase operation, make sure the other packages are updated to their latest OSG 3.3 versions, and try again.   After successfully removing BeStMan2, continue updating your host to OSG 3.4 by following the instructions above.", 
            "title": "Uninstalling BeStMan2 from the Storage Element (upgrading to OSG 3.4)"
        }, 
        {
            "location": "/release/release_series/#uninstalling-osg-info-services-from-the-compute-element-upgrading-from-osg-33-or-32", 
            "text": "The program OSG Info Services is no longer required on OSG 3.3, and is no longer available starting in OSG 3.4. This is because the service that OSG Info Services reported to, named BDII, has been retired and is no longer functional.  To cleanly uninstall OSG Info Services from your CE, perform the following procedure (after following the main update instructions above):    Ensure that you are using a sufficiently new version of the  osg-ce  metapackages:  [root@client ~] #  rpm -q osg-ce  should be at least 3.3-12 (OSG 3.3) or 3.4-1 (OSG 3.4).  If not, update them:  [root@client ~] #  yum update osg-ce    Stop the  osg-info-services  service:  [root@client ~] #  service osg-info-services stop    Uninstall the software:  [root@client ~] #  yum erase gip osg-info-services     Note  In the output from this command, yum should  not  list other packages than those two. If it lists other packages, cancel the erase operation, make sure the other packages are updated to their latest OSG 3.3 (or 3.4) versions, and try again.", 
            "title": "Uninstalling OSG Info Services from the Compute Element (upgrading from OSG 3.3 or 3.2)"
        }, 
        {
            "location": "/release/release_series/#uninstalling-cemon-from-the-compute-element-upgrading-from-osg-31", 
            "text": "The program CEMon (found in the package  glite-ce-monitor ) is no longer available starting in OSG 3.2. Its functionality is no longer required because the service that CEMon reported to has been retired and is no longer functional.  To cleanly uninstall CEMon from your CE, perform the following procedure (after following the main update instructions above):    Ensure that you are using a sufficiently new version of the  osg-ce  metapackages:  [root@client ~] #  rpm -q osg-ce  should be at least 3.3-12 (OSG 3.3) or 3.4-1 (OSG 3.4). If not, update them:  [root@client ~] #  yum update osg-ce    If there is a CEMon configuration file at  /etc/osg/config.d/30-cemon.ini , remove it.   Remove CEMon and related packages: [root@client ~] #  yum erase glite-ce-monitor glite-ce-osg-ce-plugin osg-configure-cemon     Note  In the output from this command, yum should  not  list other packages than those three. If it lists other packages, cancel the erase operation, make sure the other packages are updated to their OSG 3.3 (or 3.4) versions (they should have  .osg33  or  .osg34  in their versions), and try again.", 
            "title": "Uninstalling CEMon from the Compute Element (upgrading from OSG 3.1)"
        }, 
        {
            "location": "/release/release_series/#references", 
            "text": "YUM Repositories  Basic use of Yum  Best practices in using Yum", 
            "title": "References"
        }, 
        {
            "location": "/release/yum-basics/", 
            "text": "Basics of using yum and RPM\n\n\nAbout This Document\n\n\nThis document introduces package management tools that help you install, update, and remove packages. OSG uses RPMs (the Red Hat Packaging Manager) to package its software. While RPM is the packaging format, \nyum\n is the command you will use to do the installation. For example, \nyum\n will resolve and download the dependencies for the package you want to install; \nrpm\n will simply complain if you want to install a package that does not have all its dependencies installed.\n\n\nInstallation\n\n\nInstallation is done with the \nyum install\n command. Each of the individual installation guide shows you the correct command to use to do an installation. Here is an example installation with all of the output from yum.\n\n\n[root@client ~] #\n sudo yum install osg-ca-certs\n\nLoaded plugins: kernel-module, priorities\n\n\nepel                                                                                         | 3.7 kB     00:00     \n\n\nepel/primary_db                                                                              | 3.8 MB     00:00     \n\n\nfermi-base                                                                                   | 2.1 kB     00:00     \n\n\nfermi-base/primary_db                                                                        |  48 kB     00:00     \n\n\nfermi-security                                                                               | 1.9 kB     00:00     \n\n\nfermi-security/primary_db                                                                    | 1.7 MB     00:00     \n\n\nosg                                                                                          | 1.9 kB     00:00     \n\n\nosg/primary_db                                                                               |  65 kB     00:00     \n\n\nsl-base                                                                                      | 2.1 kB     00:00     \n\n\nsl-base/primary_db                                                                           | 2.0 MB     00:00     \n\n\n957 packages excluded due to repository priority protections\n\n\nSetting up Install Process\n\n\nResolving Dependencies\n\n\n--\n Running transaction check\n\n\n---\n Package osg-ca-certs.noarch 0:1.23-1 set to be updated\n\n\n--\n Finished Dependency Resolution\n\n\nBeginning Kernel Module Plugin\n\n\nFinished Kernel Module Plugin\n\n\n\nDependencies Resolved\n\n\n\n====================================================================================================================\n\n\n Package                         Arch                      Version                     Repository              Size\n\n\n====================================================================================================================\n\n\nInstalling:\n\n\n osg-ca-certs                    noarch                    1.23-1                      osg                    450 k\n\n\n\nTransaction Summary\n\n\n====================================================================================================================\n\n\nInstall       1 Package(s)\n\n\nUpgrade       0 Package(s)\n\n\n\nTotal download size: 450 k\n\n\nIs this ok [y/N]: y\n\n\nDownloading Packages:\n\n\nosg-ca-certs-1.23-1.noarch.rpm                                                               | 450 kB     00:00     \n\n\nwarning: rpmts_HdrFromFdno: Header V3 DSA signature: NOKEY, key ID 824b8603\n\n\nosg/gpgkey                                                                                   | 1.7 kB     00:00     \n\n\nImporting GPG key 0x824B8603 \nOSG Software Team (RPM Signing Key for Koji Packages) \nvdt-support@opensciencegrid.org\n from /etc/pki/rpm-gpg/RPM-GPG-KEY-OSG\n\n\nIs this ok [y/N]: y\n\n\nRunning rpm_check_debug\n\n\nRunning Transaction Test\n\n\nFinished Transaction Test\n\n\nTransaction Test Succeeded\n\n\nRunning Transaction\n\n\n  Installing     : osg-ca-certs                                                                                 1/1 \n\n\n\nInstalled:\n\n\n  osg-ca-certs.noarch 0:1.23-1                                                                                      \n\n\n\nComplete!\n\n\n\n\n\n\nPlease Note\n: When you first install a package from the OSG repository, you will be prompted to import the GPG key. We use this key to sign our RPMs as a security measure. You should double-check the key id (above it is 824B8603) with the \ninformation on our signed RPMs\n. If it doesn't match, there is a problem somewhere and you should report it to the OSG via goc@opensciencegrid.org.\n\n\nVerifying Packages and Installations\n\n\nYou can check if an RPM has been modified. For instance, to check to see if any files have been modified in the \nosg-ca-certs\n RPM you just installed:\n\n\n[user@client ~] $\n rpm --verify osg-ca-certs\n\n\n\n\n\nThe lack of any output means there were no problems. If you would like to see all the files for which there are no problems, you can do:\n\n\n[user@client ~] $\n rpm --verify -v osg-ca-certs\n\n........    /etc/grid-security/certificates\n\n\n........    /etc/grid-security/certificates/0119347c.0\n\n\n........    /etc/grid-security/certificates/0119347c.namespaces\n\n\n........    /etc/grid-security/certificates/0119347c.signing_policy\n\n\n... etc ...\n\n\n\n\n\n\nEach dot indicates a specific check that was made and passed. If someone had modified a file, you might see this:\n\n\n[user@client ~] $\n rpm --verify osg-ca-certs\n\n..5....T    /etc/grid-security/certificates/ffc3d59b.0\n\n\n\n\n\n\nThis means the files MD5 checksum has changed (so the contents have changed) and the timestamp is different. The complete set of changes you might see (copied from the \nrpm\n man page) are:\n\n\n\n\n\n\n\n\nLetter\n\n\nMeaning\n\n\n\n\n\n\n\n\n\n\nS\n\n\nfile Size differs\n\n\n\n\n\n\nM\n\n\nMode differs (includes permissions and file type)\n\n\n\n\n\n\n5\n\n\nMD5 sum differs\n\n\n\n\n\n\nD\n\n\nDevice major/minor number mismatch\n\n\n\n\n\n\nL\n\n\nreadLink(2) path mismatch\n\n\n\n\n\n\nU\n\n\nUser ownership differs\n\n\n\n\n\n\nG\n\n\nGroup ownership differs\n\n\n\n\n\n\nT\n\n\nmTime differs\n\n\n\n\n\n\n\n\nIf you don't care about some of those changes, you can tell rpm to ignore them. For instance, to ignore changes in the modification time:\n\n\n[user@client ~] $\n rpm --verify --nomtime osg-ca-certs\n\n..5.....    /etc/grid-security/certificates/ffc3d59b.0\n\n\n\n\n\n\nUnderstanding a package\n\n\nIf you want to know what package a file belongs to, you can ask rpm. For instance, if you're curious what package contains the \nsrm-ls\n command, you can do:\n\n\n#\n \n1\n. Find the exact path\n\n[user@client ~] $\n which srm-ls\n\n/usr/bin/srm-ls\n\n\n\n#\n \n2\n. Ask rpm what package it is part of:\n\n[user@client ~] $\n rpm -q --file /usr/bin/srm-ls\n\nbestman2-client-2.2.0-14.osg.el5.noarch\n\n\n\n\n\n\nIf you want to know what other things are in a package--perhaps the other available tools or configuration files--you can do that as well:\n\n\n[user@client ~] $\n rpm -ql bestman2-client\n\n/etc/bestman2/conf/bestman2.rc\n\n\n/etc/bestman2/conf/bestman2.rc.samples\n\n\n/etc/bestman2/conf/srmclient.conf\n\n\n/etc/sysconfig/bestman2\n\n\n/usr/bin/srm-copy\n\n\n/usr/bin/srm-copy-status\n\n\n/usr/bin/srm-extendfilelifetime\n\n\n/usr/bin/srm-ls\n\n\n/usr/bin/srm-ls-status\n\n\n... output trimmed ...\n\n\n\n\n\n\nWhat else does a package install?\n\n\nSometimes you need to understand what other software is installed by a package. This can be particularly useful for understanding \nmeta-packages\n, which are packages such as the \nosg-wn-client\n (worker node client) that contain nothing by themselves but only depend on other RPMs. To do this, use the \n--requires\n option to rpm. For example, you can see that the worker node client (as of OSG 3.1.8 in early September, 2012) will install \ncurl\n, \nuberftp\n, \nlcg-utils\n, and a dozen or so other packages.\n\n\n[user@client ~] $\n rpm -q --requires osg-wn-client\n\n/usr/bin/curl  \n\n\n/usr/bin/dccp  \n\n\n/usr/bin/ldapsearch  \n\n\n/usr/bin/uberftp  \n\n\n/usr/bin/wget  \n\n\nbestman2-client  \n\n\nconfig(osg-wn-client) = 3.0.0-16.osg.el5\n\n\ndcache-srmclient  \n\n\ndcap-tunnel-gsi  \n\n\nedg-gridftp-client  \n\n\nfetch-crl  \n\n\nglite-fts-client  \n\n\nglobus-gass-copy-progs  \n\n\ngrid-certificates  \n\n\njava-1.6.0-sun-compat  \n\n\nlcg-utils  \n\n\nlfc-client  \n\n\nlfc-python  \n\n\nmyproxy  \n\n\nosg-system-profiler  \n\n\nosg-version  \n\n\nrpmlib(CompressedFileNames) \n= 3.0.4-1\n\n\nrpmlib(PayloadFilesHavePrefix) \n= 4.0-1\n\n\nvo-client\n\n\n\n\n\n\nFinding RPM Packages\n\n\nIt is normally best to read the OSG documentation to decide which packages to install because it may not be obvious what the correct packages to install are. That said, you can use yum to find out all sort of things. For instance, you can list packages that begin with \"voms\":\n\n\n[user@client ~] $\n yum list \nvoms*\n\n\nLoaded plugins: kernel-module, priorities\n\n\n957 packages excluded due to repository priority protections\n\n\nAvailable Packages\n\n\nvoms.i386                                                    2.0.6-3.osg                                        osg \n\n\nvoms.x86_64                                                  2.0.6-3.osg                                        osg \n\n\nvoms-admin-client.x86_64                                     2.0.16-1                                           osg \n\n\nvoms-admin-server.noarch                                     2.6.1-9                                            osg \n\n\nvoms-clients.x86_64                                          2.0.6-3.osg                                        osg \n\n\nvoms-compat.i386                                             1.9.19.2-6.osg                                     osg \n\n\nvoms-compat.x86_64                                           1.9.19.2-6.osg                                     osg \n\n\nvoms-devel.i386                                              2.0.6-3.osg                                        osg \n\n\nvoms-devel.x86_64                                            2.0.6-3.osg                                        osg \n\n\nvoms-doc.x86_64                                              2.0.6-3.osg                                        osg \n\n\nvoms-mysql-plugin.x86_64                                     3.1.5.1-1.el5                                      epel\n\n\nvoms-server.x86_64                                           2.0.6-3.osg                                        osg \n\n\nvomsjapi.x86_64                                              2.0.6-3.osg                                        osg \n\n\nvomsjapi-javadoc.x86_64                                      2.0.6-3.osg                                        osg\n\n\n\n\n\n\nIf you want to search for packages that contain VOMS anywhere in the name or description, you can use \nyum search\n:\n\n\n[user@client ~] $\n yum search voms\n\nLoaded plugins: kernel-module, priorities\n\n\n957 packages excluded due to repository priority protections\n\n\n================================================== Matched: voms ===================================================\n\n\nosg-voms.noarch : OSG VOMS\n\n\nperl-VOMS-Lite.noarch : Perl extension for VOMS Attribute certificate creation\n\n\nperl-voms-server.noarch : Perl extension for VOMS Attribute certificate creation\n\n\nphp-voms-admin.noarch : Web based interface to control VOMS parameters written in PHP\n\n\nvoms.i386 : Virtual Organization Membership Service\n\n\nvoms.x86_64 : Virtual Organization Membership Service\n\n\n... etc ...\n\n\n\n\n\n\nOne last example, if you want to know what RPM would give you the \nvoms-proxy-init\n command, you can ask \nyum\n. The \n*\n indicates that you don't know the full pathname of \nvoms-proxy-init\n.\n\n\n[user@client ~] $\n yum whatprovides \n*voms-proxy-init\n\n\nLoaded plugins: kernel-module, priorities\n\n\n957 packages excluded due to repository priority protections\n\n\nvoms-clients-2.0.6-3.osg.x86_64 : Virtual Organization Membership Service Clients\n\n\nRepo        : osg\n\n\nMatched from:\n\n\nFilename    : /usr/bin/voms-proxy-init\n\n\n\n\n\n\nRemoving Packages\n\n\nTo remove a single RPM, you can use \nyum remove\n. Not only will it uninstall the RPM you requested, but it will uninstall anything that depends on it. For example, if I previously installed the \nvoms-clients\n package, I also installed another package it depends on called \nvoms\n. If I remove \nvoms\n, yum will also remove \nvoms-clients\n:\n\n\n[user@client ~] $\n sudo yum remove voms\n\nLoaded plugins: kernel-module, priorities\n\n\nSetting up Remove Process\n\n\nResolving Dependencies\n\n\n--\n Running transaction check\n\n\n---\n Package voms.x86_64 0:2.0.6-3.osg set to be erased\n\n\n--\n Processing Dependency: libvomsapi.so.1()(64bit) for package: voms-clients\n\n\n--\n Processing Dependency: voms = 2.0.6-3.osg for package: voms-clients\n\n\n--\n Running transaction check\n\n\n---\n Package voms-clients.x86_64 0:2.0.6-3.osg set to be erased\n\n\n--\n Finished Dependency Resolution\n\n\nBeginning Kernel Module Plugin\n\n\nFinished Kernel Module Plugin\n\n\n\nDependencies Resolved\n\n\n\n====================================================================================================================\n\n\n Package                      Arch                   Version                        Repository                 Size\n\n\n====================================================================================================================\n\n\nRemoving:\n\n\n voms                         x86_64                 2.0.6-3.osg                    installed                 407 k\n\n\nRemoving for dependencies:\n\n\n voms-clients                 x86_64                 2.0.6-3.osg                    installed                 373 k\n\n\n\nTransaction Summary\n\n\n====================================================================================================================\n\n\nRemove        2 Package(s)\n\n\nReinstall     0 Package(s)\n\n\nDowngrade     0 Package(s)\n\n\n\nIs this ok [y/N]: y\n\n\nDownloading Packages:\n\n\nRunning rpm_check_debug\n\n\nRunning Transaction Test\n\n\nFinished Transaction Test\n\n\nTransaction Test Succeeded\n\n\nRunning Transaction\n\n\n  Erasing        : voms                                                                                         1/2 \n\n\n  Erasing        : voms-clients                                                                                 2/2 \n\n\n\nRemoved:\n\n\n  voms.x86_64 0:2.0.6-3.osg                                                                                         \n\n\n\nDependency Removed:\n\n\n  voms-clients.x86_64 0:2.0.6-3.osg                                                                                 \n\n\n\nComplete!\n\n\n\n\n\n\nUpgrading Packages\n\n\nYou can check for updates with \nyum check-update\n. For example:\n\n\n[root@client ~] #\n yum check-update\n\nLoaded plugins: kernel-module, priorities\n\n\n957 packages excluded due to repository priority protections\n\n\n\nkernel.x86_64                                            2.6.18-274.3.1.el5                           fermi-security\n\n\nObsoleting Packages\n\n\nocsinventory-agent.noarch                                1.1.2.1-1.el5                                epel          \n\n\n    ocsinventory-client.noarch                           0.9.9-10                                     installed     \n\n\n\n\n\n\nYou can do the update with \nyum update\n. Note that in this case we got more than was listed due to dependencies that needed to be resolved:\n\n\n[root@client ~] #\n yum update\n\n957 packages excluded due to repository priority protections\n\n\nSetting up Update Process\n\n\nResolving Dependencies\n\n\n--\n Running transaction check\n\n\n---\n Package kernel.x86_64 0:2.6.18-274.3.1.el5 set to be installed\n\n\n---\n Package ocsinventory-agent.noarch 0:1.1.2.1-1.el5 set to be updated\n\n\n--\n Processing Dependency: perl(Crypt::SSLeay) for package: ocsinventory-agent\n\n\n--\n Processing Dependency: perl(Proc::Daemon) for package: ocsinventory-agent\n\n\n--\n Processing Dependency: monitor-edid for package: ocsinventory-agent\n\n\n--\n Processing Dependency: perl(Net::IP) for package: ocsinventory-agent\n\n\n--\n Processing Dependency: nmap for package: ocsinventory-agent\n\n\n--\n Processing Dependency: perl(Net::SSLeay) for package: ocsinventory-agent\n\n\n--\n Running transaction check\n\n\n---\n Package monitor-edid.x86_64 0:2.5-1.el5.1 set to be updated\n\n\n---\n Package nmap.x86_64 2:4.11-1.1 set to be updated\n\n\n---\n Package perl-Crypt-SSLeay.x86_64 0:0.51-11.el5 set to be updated\n\n\n---\n Package perl-Net-IP.noarch 0:1.25-2.fc6 set to be updated\n\n\n---\n Package perl-Net-SSLeay.x86_64 0:1.30-4.fc6 set to be updated\n\n\n---\n Package perl-Proc-Daemon.noarch 0:0.03-1.el5 set to be updated\n\n\n--\n Finished Dependency Resolution\n\n\nBeginning Kernel Module Plugin\n\n\nFinished Kernel Module Plugin\n\n\n--\n Running transaction check\n\n\n---\n Package kernel.x86_64 0:2.6.18-238.1.1.el5 set to be erased\n\n\n--\n Finished Dependency Resolution\n\n\n\nDependencies Resolved\n\n\n\n====================================================================================================================\n\n\n Package                        Arch               Version                         Repository                  Size\n\n\n====================================================================================================================\n\n\nInstalling:\n\n\n kernel                         x86_64             2.6.18-274.3.1.el5              fermi-security              21 M\n\n\n ocsinventory-agent             noarch             1.1.2.1-1.el5                   epel                       156 k\n\n\n     replacing  ocsinventory-client.noarch 0.9.9-10\n\n\n\nRemoving:\n\n\n kernel                         x86_64             2.6.18-238.1.1.el5              installed                   93 M\n\n\nInstalling for dependencies:\n\n\n monitor-edid                   x86_64             2.5-1.el5.1                     epel                        82 k\n\n\n nmap                           x86_64             2:4.11-1.1                      sl-base                    680 k\n\n\n perl-Crypt-SSLeay              x86_64             0.51-11.el5                     sl-base                     45 k\n\n\n perl-Net-IP                    noarch             1.25-2.fc6                      sl-base                     31 k\n\n\n perl-Net-SSLeay                x86_64             1.30-4.fc6                      sl-base                    192 k\n\n\n perl-Proc-Daemon               noarch             0.03-1.el5                      epel                       9.4 k\n\n\n\nTransaction Summary\n\n\n====================================================================================================================\n\n\nInstall       8 Package(s)\n\n\nUpgrade       0 Package(s)\n\n\nRemove        1 Package(s)\n\n\nReinstall     0 Package(s)\n\n\nDowngrade     0 Package(s)\n\n\n\nTotal download size: 22 M\n\n\nIs this ok [y/N]: y\n\n\nDownloading Packages:\n\n\n(1/8): perl-Proc-Daemon-0.03-1.el5.noarch.rpm                                                | 9.4 kB     00:00     \n\n\n(2/8): perl-Net-IP-1.25-2.fc6.noarch.rpm                                                     |  31 kB     00:00     \n\n\n(3/8): perl-Crypt-SSLeay-0.51-11.el5.x86_64.rpm                                              |  45 kB     00:00     \n\n\n(4/8): monitor-edid-2.5-1.el5.1.x86_64.rpm                                                   |  82 kB     00:00     \n\n\n(5/8): ocsinventory-agent-1.1.2.1-1.el5.noarch.rpm                                           | 156 kB     00:00     \n\n\n(6/8): perl-Net-SSLeay-1.30-4.fc6.x86_64.rpm                                                 | 192 kB     00:00     \n\n\n(7/8): nmap-4.11-1.1.x86_64.rpm                                                              | 680 kB     00:00     \n\n\n(8/8): kernel-2.6.18-274.3.1.el5.x86_64.rpm                                                  |  21 MB     00:00     \n\n\n--------------------------------------------------------------------------------------------------------------------\n\n\nTotal                                                                               3.5 MB/s |  22 MB     00:06     \n\n\nwarning: rpmts_HdrFromFdno: Header V3 DSA signature: NOKEY, key ID 217521f6\n\n\nepel/gpgkey                                                                                  | 1.7 kB     00:00     \n\n\nImporting GPG key 0x217521F6 \nFedora EPEL \nepel@fedoraproject.org\n from /etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL\n\n\nIs this ok [y/N]: y\n\n\nRunning rpm_check_debug\n\n\nRunning Transaction Test\n\n\nFinished Transaction Test\n\n\nTransaction Test Succeeded\n\n\nRunning Transaction\n\n\n  Installing     : perl-Net-SSLeay                                                                             1/10 \n\n\n  Installing     : nmap                                                                                        2/10 \n\n\n  Installing     : monitor-edid                                                                                3/10 \n\n\n  Installing     : perl-Crypt-SSLeay                                                                           4/10 \n\n\n  Installing     : perl-Net-IP                                                                                 5/10 \n\n\n  Installing     : perl-Proc-Daemon                                                                            6/10 \n\n\n  Installing     : kernel                                                                                      7/10 \n\n\n  Installing     : ocsinventory-agent                                                                          8/10 \n\n\nule, priorities\n\n\n957 packages excluded due to repository priority protections\n\n\n\nkernel.x86_64                                            2.6.18-274.3.1.el5                           fermi-security\n\n\nObsoleting Packages\n\n\nocsinventory-agent.noarch                                1.1.2.1-1.el5                                epel          \n\n\n    ocsinventory-client.noarch                           0.9.9-10                                     installed     \n\n\n  Erasing        : ocsinventory-client                                                                         9/10 \n\n\nwarning: /etc/ocsinventory-client/ocsinv.conf saved as /etc/ocsinventory-client/ocsinv.conf.rpmsave\n\n\n  Cleanup        : kernel                                                                                     10/10 \n\n\n\nRemoved:\n\n\n  kernel.x86_64 0:2.6.18-238.1.1.el5                                                                                \n\n\n\nInstalled:\n\n\n  kernel.x86_64 0:2.6.18-274.3.1.el5                    ocsinventory-agent.noarch 0:1.1.2.1-1.el5                   \n\n\n\nDependency Installed:\n\n\n  monitor-edid.x86_64 0:2.5-1.el5.1   nmap.x86_64 2:4.11-1.1                perl-Crypt-SSLeay.x86_64 0:0.51-11.el5  \n\n\n  perl-Net-IP.noarch 0:1.25-2.fc6     perl-Net-SSLeay.x86_64 0:1.30-4.fc6   perl-Proc-Daemon.noarch 0:0.03-1.el5    \n\n\n\nReplaced:\n\n\n  ocsinventory-client.noarch 0:0.9.9-10                                                                             \n\n\n\nComplete!\n\n\n\n\n\n\nAdvanced topic: Only geting OSG updates\n\n\nIf you only want to get updates from the OSG repository and \nno other\n repositories, you can tell yum to do that with the following command:\n\n\n[root@client ~] #\n yum --disablerepo\n=\n* --enablerepo\n=\nosg update\n\n\n\n\n\nAdvanced topic: Getting debugging information for installed software\n\n\nIf you run into a problem with our software and have a hankering to debug it directly (or perhaps we need to ask you for some help), you can install so-called \"debuginfo\" packages. These packages will provide debugging symbols and source code so that you can do things like run \ngdb\n or \npstack\n to get information about a program.\n\n\nInstalling the debuginfo package requires three steps.\n\n\n\n\n\n\nEnable the installation of debuginfo packages. This only needs to be done once. Edit the yum repo file, usually \n/etc/yum.repos.d/osg.repo\n to enable the separate debuginfo repository. Near the bottom of the file, you'll see the \nosg-debug\n repo: \n\n\n[osg-debug]\n\n\n\nname\n=\nOSG Software for Enterprise Linux 5 - $basearch - Debug\n\n\nbaseurl\n=\nhttp://repo.grid.iu.edu/osg-release/$basearch/debu\n\n\nfailovermethod\n=\npriority \n\n\npriority\n=\n98 \n\n\nenabled\n=\n1\n\n\ngpgcheck\n=\n1 \n\n\ngpgkey\n=\nfile:///etc/pki/rpm-gpg/RPM-GPG-KEY-OSG\n\n\n\n\n\n\nMake sure that \"enabled\" is set to 1.\n\n\n\n\n\n\nFigure out which package installed the program you want to debug. One way to figure it out is to ask RPM. For example, if you want to debug grid-proxy-init:\n\n\n[user@client ~] $\n rpm -qf \n`\nwhich grid-proxy-init\n`\n\n\nglobus-proxy-utils-5.0-5.osg.x86_64\n\n\n\n\n\n\n\n\n\n\nInstall the debugging information for that package. Continuing this example: \n\n\n[root@client ~] #\n debuginfo-install globus-proxy-utils\n\n...\n\n\n=================================================================================================================================\n\n\n Package                                      Arch                   Version                     Repository                 Size\n\n\n=================================================================================================================================\n\n\nInstalling:\n\n\n globus-proxy-utils-debuginfo                 x86_64                 5.0-5.osg                   osg-debug                  61 k\n\n\n\nTransaction Summary\n\n\n=================================================================================================================================\n\n\nInstall       1 Package(s)\n\n\nUpgrade       0 Package(s)\n\n\n\nTotal download size: 61 k\n\n\nIs this ok [y/N]: y\n\n\n...\n\n\nInstalled:\n\n\n  globus-proxy-utils-debuginfo.x86_64 0:5.0-5.osg\n\n\n\n\n\n\nThis last step will select the right package name, then use \nyum\n to install it.\n\n\n\n\n\n\nTroubleshooting\n\n\nYum not finding packages\n\n\nIf you is not finding some packages, e.g.:\n\n\nError Downloading Packages:\n  packageXYZ: failure: packageXYZ.rpm from osg: [Errno 256] No more mirrors to try.\n\n\n\n\n\nthen you can try cleaning up Yum's cache: \n\n\n[root@client ~] #\n yum clean all --enablerpeo\n=\n*\n\n\n\n\n\nto make an even more thorough job you can follow also add:\n\n\n[root@client ~] #\n yum clean expire-cache --enablerepo\n=\n*\n\n\n\n\n\n\n\nNote\n\n\nyum clean\n cleans only enabled repositories. If you want to also clean any (temporarily) disabled repositories you need to use \n--enablerepo=\u2019*\u2019\n option.\n\n\n\n\nYum complaining about missing keys\n\n\nIf yum is complaining you can re-import the keys in your distribution: \n\n\n[root@client ~] #\n rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY*\n\n\n\n\n\nReferences\n\n\n\n\nThe main yum web site\n\n\nA good description of the commands for RPM and yum can be found at \nLearn Linux 101: RPM and YUM Package Management\n.", 
            "title": "Yum Basics"
        }, 
        {
            "location": "/release/yum-basics/#basics-of-using-yum-and-rpm", 
            "text": "", 
            "title": "Basics of using yum and RPM"
        }, 
        {
            "location": "/release/yum-basics/#about-this-document", 
            "text": "This document introduces package management tools that help you install, update, and remove packages. OSG uses RPMs (the Red Hat Packaging Manager) to package its software. While RPM is the packaging format,  yum  is the command you will use to do the installation. For example,  yum  will resolve and download the dependencies for the package you want to install;  rpm  will simply complain if you want to install a package that does not have all its dependencies installed.", 
            "title": "About This Document"
        }, 
        {
            "location": "/release/yum-basics/#installation", 
            "text": "Installation is done with the  yum install  command. Each of the individual installation guide shows you the correct command to use to do an installation. Here is an example installation with all of the output from yum.  [root@client ~] #  sudo yum install osg-ca-certs Loaded plugins: kernel-module, priorities  epel                                                                                         | 3.7 kB     00:00       epel/primary_db                                                                              | 3.8 MB     00:00       fermi-base                                                                                   | 2.1 kB     00:00       fermi-base/primary_db                                                                        |  48 kB     00:00       fermi-security                                                                               | 1.9 kB     00:00       fermi-security/primary_db                                                                    | 1.7 MB     00:00       osg                                                                                          | 1.9 kB     00:00       osg/primary_db                                                                               |  65 kB     00:00       sl-base                                                                                      | 2.1 kB     00:00       sl-base/primary_db                                                                           | 2.0 MB     00:00       957 packages excluded due to repository priority protections  Setting up Install Process  Resolving Dependencies  --  Running transaction check  ---  Package osg-ca-certs.noarch 0:1.23-1 set to be updated  --  Finished Dependency Resolution  Beginning Kernel Module Plugin  Finished Kernel Module Plugin  Dependencies Resolved  ====================================================================================================================   Package                         Arch                      Version                     Repository              Size  ====================================================================================================================  Installing:   osg-ca-certs                    noarch                    1.23-1                      osg                    450 k  Transaction Summary  ====================================================================================================================  Install       1 Package(s)  Upgrade       0 Package(s)  Total download size: 450 k  Is this ok [y/N]: y  Downloading Packages:  osg-ca-certs-1.23-1.noarch.rpm                                                               | 450 kB     00:00       warning: rpmts_HdrFromFdno: Header V3 DSA signature: NOKEY, key ID 824b8603  osg/gpgkey                                                                                   | 1.7 kB     00:00       Importing GPG key 0x824B8603  OSG Software Team (RPM Signing Key for Koji Packages)  vdt-support@opensciencegrid.org  from /etc/pki/rpm-gpg/RPM-GPG-KEY-OSG  Is this ok [y/N]: y  Running rpm_check_debug  Running Transaction Test  Finished Transaction Test  Transaction Test Succeeded  Running Transaction    Installing     : osg-ca-certs                                                                                 1/1   Installed:    osg-ca-certs.noarch 0:1.23-1                                                                                        Complete!   Please Note : When you first install a package from the OSG repository, you will be prompted to import the GPG key. We use this key to sign our RPMs as a security measure. You should double-check the key id (above it is 824B8603) with the  information on our signed RPMs . If it doesn't match, there is a problem somewhere and you should report it to the OSG via goc@opensciencegrid.org.", 
            "title": "Installation"
        }, 
        {
            "location": "/release/yum-basics/#verifying-packages-and-installations", 
            "text": "You can check if an RPM has been modified. For instance, to check to see if any files have been modified in the  osg-ca-certs  RPM you just installed:  [user@client ~] $  rpm --verify osg-ca-certs  The lack of any output means there were no problems. If you would like to see all the files for which there are no problems, you can do:  [user@client ~] $  rpm --verify -v osg-ca-certs ........    /etc/grid-security/certificates  ........    /etc/grid-security/certificates/0119347c.0  ........    /etc/grid-security/certificates/0119347c.namespaces  ........    /etc/grid-security/certificates/0119347c.signing_policy  ... etc ...   Each dot indicates a specific check that was made and passed. If someone had modified a file, you might see this:  [user@client ~] $  rpm --verify osg-ca-certs ..5....T    /etc/grid-security/certificates/ffc3d59b.0   This means the files MD5 checksum has changed (so the contents have changed) and the timestamp is different. The complete set of changes you might see (copied from the  rpm  man page) are:     Letter  Meaning      S  file Size differs    M  Mode differs (includes permissions and file type)    5  MD5 sum differs    D  Device major/minor number mismatch    L  readLink(2) path mismatch    U  User ownership differs    G  Group ownership differs    T  mTime differs     If you don't care about some of those changes, you can tell rpm to ignore them. For instance, to ignore changes in the modification time:  [user@client ~] $  rpm --verify --nomtime osg-ca-certs ..5.....    /etc/grid-security/certificates/ffc3d59b.0", 
            "title": "Verifying Packages and Installations"
        }, 
        {
            "location": "/release/yum-basics/#understanding-a-package", 
            "text": "If you want to know what package a file belongs to, you can ask rpm. For instance, if you're curious what package contains the  srm-ls  command, you can do:  #   1 . Find the exact path [user@client ~] $  which srm-ls /usr/bin/srm-ls  #   2 . Ask rpm what package it is part of: [user@client ~] $  rpm -q --file /usr/bin/srm-ls bestman2-client-2.2.0-14.osg.el5.noarch   If you want to know what other things are in a package--perhaps the other available tools or configuration files--you can do that as well:  [user@client ~] $  rpm -ql bestman2-client /etc/bestman2/conf/bestman2.rc  /etc/bestman2/conf/bestman2.rc.samples  /etc/bestman2/conf/srmclient.conf  /etc/sysconfig/bestman2  /usr/bin/srm-copy  /usr/bin/srm-copy-status  /usr/bin/srm-extendfilelifetime  /usr/bin/srm-ls  /usr/bin/srm-ls-status  ... output trimmed ...", 
            "title": "Understanding a package"
        }, 
        {
            "location": "/release/yum-basics/#what-else-does-a-package-install", 
            "text": "Sometimes you need to understand what other software is installed by a package. This can be particularly useful for understanding  meta-packages , which are packages such as the  osg-wn-client  (worker node client) that contain nothing by themselves but only depend on other RPMs. To do this, use the  --requires  option to rpm. For example, you can see that the worker node client (as of OSG 3.1.8 in early September, 2012) will install  curl ,  uberftp ,  lcg-utils , and a dozen or so other packages.  [user@client ~] $  rpm -q --requires osg-wn-client /usr/bin/curl    /usr/bin/dccp    /usr/bin/ldapsearch    /usr/bin/uberftp    /usr/bin/wget    bestman2-client    config(osg-wn-client) = 3.0.0-16.osg.el5  dcache-srmclient    dcap-tunnel-gsi    edg-gridftp-client    fetch-crl    glite-fts-client    globus-gass-copy-progs    grid-certificates    java-1.6.0-sun-compat    lcg-utils    lfc-client    lfc-python    myproxy    osg-system-profiler    osg-version    rpmlib(CompressedFileNames)  = 3.0.4-1  rpmlib(PayloadFilesHavePrefix)  = 4.0-1  vo-client", 
            "title": "What else does a package install?"
        }, 
        {
            "location": "/release/yum-basics/#finding-rpm-packages", 
            "text": "It is normally best to read the OSG documentation to decide which packages to install because it may not be obvious what the correct packages to install are. That said, you can use yum to find out all sort of things. For instance, you can list packages that begin with \"voms\":  [user@client ~] $  yum list  voms*  Loaded plugins: kernel-module, priorities  957 packages excluded due to repository priority protections  Available Packages  voms.i386                                                    2.0.6-3.osg                                        osg   voms.x86_64                                                  2.0.6-3.osg                                        osg   voms-admin-client.x86_64                                     2.0.16-1                                           osg   voms-admin-server.noarch                                     2.6.1-9                                            osg   voms-clients.x86_64                                          2.0.6-3.osg                                        osg   voms-compat.i386                                             1.9.19.2-6.osg                                     osg   voms-compat.x86_64                                           1.9.19.2-6.osg                                     osg   voms-devel.i386                                              2.0.6-3.osg                                        osg   voms-devel.x86_64                                            2.0.6-3.osg                                        osg   voms-doc.x86_64                                              2.0.6-3.osg                                        osg   voms-mysql-plugin.x86_64                                     3.1.5.1-1.el5                                      epel  voms-server.x86_64                                           2.0.6-3.osg                                        osg   vomsjapi.x86_64                                              2.0.6-3.osg                                        osg   vomsjapi-javadoc.x86_64                                      2.0.6-3.osg                                        osg   If you want to search for packages that contain VOMS anywhere in the name or description, you can use  yum search :  [user@client ~] $  yum search voms Loaded plugins: kernel-module, priorities  957 packages excluded due to repository priority protections  ================================================== Matched: voms ===================================================  osg-voms.noarch : OSG VOMS  perl-VOMS-Lite.noarch : Perl extension for VOMS Attribute certificate creation  perl-voms-server.noarch : Perl extension for VOMS Attribute certificate creation  php-voms-admin.noarch : Web based interface to control VOMS parameters written in PHP  voms.i386 : Virtual Organization Membership Service  voms.x86_64 : Virtual Organization Membership Service  ... etc ...   One last example, if you want to know what RPM would give you the  voms-proxy-init  command, you can ask  yum . The  *  indicates that you don't know the full pathname of  voms-proxy-init .  [user@client ~] $  yum whatprovides  *voms-proxy-init  Loaded plugins: kernel-module, priorities  957 packages excluded due to repository priority protections  voms-clients-2.0.6-3.osg.x86_64 : Virtual Organization Membership Service Clients  Repo        : osg  Matched from:  Filename    : /usr/bin/voms-proxy-init", 
            "title": "Finding RPM Packages"
        }, 
        {
            "location": "/release/yum-basics/#removing-packages", 
            "text": "To remove a single RPM, you can use  yum remove . Not only will it uninstall the RPM you requested, but it will uninstall anything that depends on it. For example, if I previously installed the  voms-clients  package, I also installed another package it depends on called  voms . If I remove  voms , yum will also remove  voms-clients :  [user@client ~] $  sudo yum remove voms Loaded plugins: kernel-module, priorities  Setting up Remove Process  Resolving Dependencies  --  Running transaction check  ---  Package voms.x86_64 0:2.0.6-3.osg set to be erased  --  Processing Dependency: libvomsapi.so.1()(64bit) for package: voms-clients  --  Processing Dependency: voms = 2.0.6-3.osg for package: voms-clients  --  Running transaction check  ---  Package voms-clients.x86_64 0:2.0.6-3.osg set to be erased  --  Finished Dependency Resolution  Beginning Kernel Module Plugin  Finished Kernel Module Plugin  Dependencies Resolved  ====================================================================================================================   Package                      Arch                   Version                        Repository                 Size  ====================================================================================================================  Removing:   voms                         x86_64                 2.0.6-3.osg                    installed                 407 k  Removing for dependencies:   voms-clients                 x86_64                 2.0.6-3.osg                    installed                 373 k  Transaction Summary  ====================================================================================================================  Remove        2 Package(s)  Reinstall     0 Package(s)  Downgrade     0 Package(s)  Is this ok [y/N]: y  Downloading Packages:  Running rpm_check_debug  Running Transaction Test  Finished Transaction Test  Transaction Test Succeeded  Running Transaction    Erasing        : voms                                                                                         1/2     Erasing        : voms-clients                                                                                 2/2   Removed:    voms.x86_64 0:2.0.6-3.osg                                                                                           Dependency Removed:    voms-clients.x86_64 0:2.0.6-3.osg                                                                                   Complete!", 
            "title": "Removing Packages"
        }, 
        {
            "location": "/release/yum-basics/#upgrading-packages", 
            "text": "You can check for updates with  yum check-update . For example:  [root@client ~] #  yum check-update Loaded plugins: kernel-module, priorities  957 packages excluded due to repository priority protections  kernel.x86_64                                            2.6.18-274.3.1.el5                           fermi-security  Obsoleting Packages  ocsinventory-agent.noarch                                1.1.2.1-1.el5                                epel                ocsinventory-client.noarch                           0.9.9-10                                     installed        You can do the update with  yum update . Note that in this case we got more than was listed due to dependencies that needed to be resolved:  [root@client ~] #  yum update 957 packages excluded due to repository priority protections  Setting up Update Process  Resolving Dependencies  --  Running transaction check  ---  Package kernel.x86_64 0:2.6.18-274.3.1.el5 set to be installed  ---  Package ocsinventory-agent.noarch 0:1.1.2.1-1.el5 set to be updated  --  Processing Dependency: perl(Crypt::SSLeay) for package: ocsinventory-agent  --  Processing Dependency: perl(Proc::Daemon) for package: ocsinventory-agent  --  Processing Dependency: monitor-edid for package: ocsinventory-agent  --  Processing Dependency: perl(Net::IP) for package: ocsinventory-agent  --  Processing Dependency: nmap for package: ocsinventory-agent  --  Processing Dependency: perl(Net::SSLeay) for package: ocsinventory-agent  --  Running transaction check  ---  Package monitor-edid.x86_64 0:2.5-1.el5.1 set to be updated  ---  Package nmap.x86_64 2:4.11-1.1 set to be updated  ---  Package perl-Crypt-SSLeay.x86_64 0:0.51-11.el5 set to be updated  ---  Package perl-Net-IP.noarch 0:1.25-2.fc6 set to be updated  ---  Package perl-Net-SSLeay.x86_64 0:1.30-4.fc6 set to be updated  ---  Package perl-Proc-Daemon.noarch 0:0.03-1.el5 set to be updated  --  Finished Dependency Resolution  Beginning Kernel Module Plugin  Finished Kernel Module Plugin  --  Running transaction check  ---  Package kernel.x86_64 0:2.6.18-238.1.1.el5 set to be erased  --  Finished Dependency Resolution  Dependencies Resolved  ====================================================================================================================   Package                        Arch               Version                         Repository                  Size  ====================================================================================================================  Installing:   kernel                         x86_64             2.6.18-274.3.1.el5              fermi-security              21 M   ocsinventory-agent             noarch             1.1.2.1-1.el5                   epel                       156 k       replacing  ocsinventory-client.noarch 0.9.9-10  Removing:   kernel                         x86_64             2.6.18-238.1.1.el5              installed                   93 M  Installing for dependencies:   monitor-edid                   x86_64             2.5-1.el5.1                     epel                        82 k   nmap                           x86_64             2:4.11-1.1                      sl-base                    680 k   perl-Crypt-SSLeay              x86_64             0.51-11.el5                     sl-base                     45 k   perl-Net-IP                    noarch             1.25-2.fc6                      sl-base                     31 k   perl-Net-SSLeay                x86_64             1.30-4.fc6                      sl-base                    192 k   perl-Proc-Daemon               noarch             0.03-1.el5                      epel                       9.4 k  Transaction Summary  ====================================================================================================================  Install       8 Package(s)  Upgrade       0 Package(s)  Remove        1 Package(s)  Reinstall     0 Package(s)  Downgrade     0 Package(s)  Total download size: 22 M  Is this ok [y/N]: y  Downloading Packages:  (1/8): perl-Proc-Daemon-0.03-1.el5.noarch.rpm                                                | 9.4 kB     00:00       (2/8): perl-Net-IP-1.25-2.fc6.noarch.rpm                                                     |  31 kB     00:00       (3/8): perl-Crypt-SSLeay-0.51-11.el5.x86_64.rpm                                              |  45 kB     00:00       (4/8): monitor-edid-2.5-1.el5.1.x86_64.rpm                                                   |  82 kB     00:00       (5/8): ocsinventory-agent-1.1.2.1-1.el5.noarch.rpm                                           | 156 kB     00:00       (6/8): perl-Net-SSLeay-1.30-4.fc6.x86_64.rpm                                                 | 192 kB     00:00       (7/8): nmap-4.11-1.1.x86_64.rpm                                                              | 680 kB     00:00       (8/8): kernel-2.6.18-274.3.1.el5.x86_64.rpm                                                  |  21 MB     00:00       --------------------------------------------------------------------------------------------------------------------  Total                                                                               3.5 MB/s |  22 MB     00:06       warning: rpmts_HdrFromFdno: Header V3 DSA signature: NOKEY, key ID 217521f6  epel/gpgkey                                                                                  | 1.7 kB     00:00       Importing GPG key 0x217521F6  Fedora EPEL  epel@fedoraproject.org  from /etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL  Is this ok [y/N]: y  Running rpm_check_debug  Running Transaction Test  Finished Transaction Test  Transaction Test Succeeded  Running Transaction    Installing     : perl-Net-SSLeay                                                                             1/10     Installing     : nmap                                                                                        2/10     Installing     : monitor-edid                                                                                3/10     Installing     : perl-Crypt-SSLeay                                                                           4/10     Installing     : perl-Net-IP                                                                                 5/10     Installing     : perl-Proc-Daemon                                                                            6/10     Installing     : kernel                                                                                      7/10     Installing     : ocsinventory-agent                                                                          8/10   ule, priorities  957 packages excluded due to repository priority protections  kernel.x86_64                                            2.6.18-274.3.1.el5                           fermi-security  Obsoleting Packages  ocsinventory-agent.noarch                                1.1.2.1-1.el5                                epel                ocsinventory-client.noarch                           0.9.9-10                                     installed         Erasing        : ocsinventory-client                                                                         9/10   warning: /etc/ocsinventory-client/ocsinv.conf saved as /etc/ocsinventory-client/ocsinv.conf.rpmsave    Cleanup        : kernel                                                                                     10/10   Removed:    kernel.x86_64 0:2.6.18-238.1.1.el5                                                                                  Installed:    kernel.x86_64 0:2.6.18-274.3.1.el5                    ocsinventory-agent.noarch 0:1.1.2.1-1.el5                     Dependency Installed:    monitor-edid.x86_64 0:2.5-1.el5.1   nmap.x86_64 2:4.11-1.1                perl-Crypt-SSLeay.x86_64 0:0.51-11.el5      perl-Net-IP.noarch 0:1.25-2.fc6     perl-Net-SSLeay.x86_64 0:1.30-4.fc6   perl-Proc-Daemon.noarch 0:0.03-1.el5      Replaced:    ocsinventory-client.noarch 0:0.9.9-10                                                                               Complete!", 
            "title": "Upgrading Packages"
        }, 
        {
            "location": "/release/yum-basics/#advanced-topic-only-geting-osg-updates", 
            "text": "If you only want to get updates from the OSG repository and  no other  repositories, you can tell yum to do that with the following command:  [root@client ~] #  yum --disablerepo = * --enablerepo = osg update", 
            "title": "Advanced topic: Only geting OSG updates"
        }, 
        {
            "location": "/release/yum-basics/#advanced-topic-getting-debugging-information-for-installed-software", 
            "text": "If you run into a problem with our software and have a hankering to debug it directly (or perhaps we need to ask you for some help), you can install so-called \"debuginfo\" packages. These packages will provide debugging symbols and source code so that you can do things like run  gdb  or  pstack  to get information about a program.  Installing the debuginfo package requires three steps.    Enable the installation of debuginfo packages. This only needs to be done once. Edit the yum repo file, usually  /etc/yum.repos.d/osg.repo  to enable the separate debuginfo repository. Near the bottom of the file, you'll see the  osg-debug  repo:   [osg-debug]  name = OSG Software for Enterprise Linux 5 - $basearch - Debug  baseurl = http://repo.grid.iu.edu/osg-release/$basearch/debu  failovermethod = priority   priority = 98   enabled = 1  gpgcheck = 1   gpgkey = file:///etc/pki/rpm-gpg/RPM-GPG-KEY-OSG   Make sure that \"enabled\" is set to 1.    Figure out which package installed the program you want to debug. One way to figure it out is to ask RPM. For example, if you want to debug grid-proxy-init:  [user@client ~] $  rpm -qf  ` which grid-proxy-init `  globus-proxy-utils-5.0-5.osg.x86_64     Install the debugging information for that package. Continuing this example:   [root@client ~] #  debuginfo-install globus-proxy-utils ...  =================================================================================================================================   Package                                      Arch                   Version                     Repository                 Size  =================================================================================================================================  Installing:   globus-proxy-utils-debuginfo                 x86_64                 5.0-5.osg                   osg-debug                  61 k  Transaction Summary  =================================================================================================================================  Install       1 Package(s)  Upgrade       0 Package(s)  Total download size: 61 k  Is this ok [y/N]: y  ...  Installed:    globus-proxy-utils-debuginfo.x86_64 0:5.0-5.osg   This last step will select the right package name, then use  yum  to install it.", 
            "title": "Advanced topic: Getting debugging information for installed software"
        }, 
        {
            "location": "/release/yum-basics/#troubleshooting", 
            "text": "", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/release/yum-basics/#yum-not-finding-packages", 
            "text": "If you is not finding some packages, e.g.:  Error Downloading Packages:\n  packageXYZ: failure: packageXYZ.rpm from osg: [Errno 256] No more mirrors to try.  then you can try cleaning up Yum's cache:   [root@client ~] #  yum clean all --enablerpeo = *  to make an even more thorough job you can follow also add:  [root@client ~] #  yum clean expire-cache --enablerepo = *   Note  yum clean  cleans only enabled repositories. If you want to also clean any (temporarily) disabled repositories you need to use  --enablerepo=\u2019*\u2019  option.", 
            "title": "Yum not finding packages"
        }, 
        {
            "location": "/release/yum-basics/#yum-complaining-about-missing-keys", 
            "text": "If yum is complaining you can re-import the keys in your distribution:   [root@client ~] #  rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY*", 
            "title": "Yum complaining about missing keys"
        }, 
        {
            "location": "/release/yum-basics/#references", 
            "text": "The main yum web site  A good description of the commands for RPM and yum can be found at  Learn Linux 101: RPM and YUM Package Management .", 
            "title": "References"
        }, 
        {
            "location": "/release/signing/", 
            "text": "OSG Release Signing Information\n\n\nVerifying OSG's RPMs\n\n\nWe use a GPG key to sign our software packages. Normally \nyum\n and \nrpm\n transparently use the GPG signatures to verify the packages have not been corrupted and were created by us. You get our GPG public key when you install the \nosg-release\n RPM.\n\n\nIf you wish to verify one of our RPMs manually, you can run:\n\n\n$\n rpm --checksig -v \nNAME.RPM\n\n\n\n\n\n\nFor example:\n\n\n$\n rpm --checksig -v globus-core-8.0-2.osg.x86_64.rpm \n\nglobus-core-8.0-2.osg.x86_64.rpm:\n\n\n    Header V3 DSA signature: OK, key ID 824b8603\n\n\n    Header SHA1 digest: OK (2b5af4348c548c27f10e2e47e1ec80500c4f85d7)\n\n\n    MD5 digest: OK (d11503a229a1a0e02262034efe0f7e46)\n\n\n    V3 DSA signature: OK, key ID 824b8603\n\n\n\n\n\n\nThe OSG Packaging Signing Key\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLocation\n\n\n/etc/pki/rpm-gpg/RPM-GPG-KEY-OSG\n\n\n\n\n\n\nDownload\n\n\nGitHub\n\n\n\n\n\n\nDownload\n\n\nUW-Madison\n\n\n\n\n\n\nFingerprint\n\n\n6459 !D9D2 AAA9 AB67 A251  FB44 2110 !B1C8 824B 8603\n\n\n\n\n\n\nKey ID\n\n\n824b8603\n\n\n\n\n\n\n\n\nYou can see the fingerprint for yourself:\n\n\n$\n gpg --with-fingerprint /etc/pki/rpm-gpg/RPM-GPG-KEY-OSG\n\npub  1024D/824B8603 2011-09-15 OSG Software Team (RPM Signing Key for Koji Packages) \nvdt-support@opensciencegrid.org\n\n\n      Key fingerprint = 6459 D9D2 AAA9 AB67 A251  FB44 2110 B1C8 824B 8603\n\n\nsub  2048g/28E5857C 2011-09-15", 
            "title": "RPM Signing"
        }, 
        {
            "location": "/release/signing/#osg-release-signing-information", 
            "text": "", 
            "title": "OSG Release Signing Information"
        }, 
        {
            "location": "/release/signing/#verifying-osgs-rpms", 
            "text": "We use a GPG key to sign our software packages. Normally  yum  and  rpm  transparently use the GPG signatures to verify the packages have not been corrupted and were created by us. You get our GPG public key when you install the  osg-release  RPM.  If you wish to verify one of our RPMs manually, you can run:  $  rpm --checksig -v  NAME.RPM   For example:  $  rpm --checksig -v globus-core-8.0-2.osg.x86_64.rpm  globus-core-8.0-2.osg.x86_64.rpm:      Header V3 DSA signature: OK, key ID 824b8603      Header SHA1 digest: OK (2b5af4348c548c27f10e2e47e1ec80500c4f85d7)      MD5 digest: OK (d11503a229a1a0e02262034efe0f7e46)      V3 DSA signature: OK, key ID 824b8603", 
            "title": "Verifying OSG's RPMs"
        }, 
        {
            "location": "/release/signing/#the-osg-packaging-signing-key", 
            "text": "Location  /etc/pki/rpm-gpg/RPM-GPG-KEY-OSG    Download  GitHub    Download  UW-Madison    Fingerprint  6459 !D9D2 AAA9 AB67 A251  FB44 2110 !B1C8 824B 8603    Key ID  824b8603     You can see the fingerprint for yourself:  $  gpg --with-fingerprint /etc/pki/rpm-gpg/RPM-GPG-KEY-OSG pub  1024D/824B8603 2011-09-15 OSG Software Team (RPM Signing Key for Koji Packages)  vdt-support@opensciencegrid.org        Key fingerprint = 6459 D9D2 AAA9 AB67 A251  FB44 2110 B1C8 824B 8603  sub  2048g/28E5857C 2011-09-15", 
            "title": "The OSG Packaging Signing Key"
        }, 
        {
            "location": "/release/supported_platforms/", 
            "text": "OSG Software Supported Operating Systems\n\n\nThe OSG Software 3.3 and 3.4 release series are supported on Red Hat Enterprise 6 and 7 for 64-bit (RHEL 6 and RHEL 7) and 32-bit (RHEL 6 only) Intel architectures.\n\n\nOSG also supports select rebuilds of RHEL.  Specifically:\n\n\n\n\nCentOS 6\n\n\nCentOS 7\n\n\nRed Hat Enterprise Linux 6\n\n\nRed Hat Enterprise Linux 7\n\n\nScientific Linux 6\n\n\nScientific Linux 7\n\n\n\n\nThe OSG Software 3.1 and 3.2 release series also supported Red Hat Enterprise Linux 5, but neither 3.1 nor 3.2 are actively supported.", 
            "title": "Supported Platforms"
        }, 
        {
            "location": "/release/supported_platforms/#osg-software-supported-operating-systems", 
            "text": "The OSG Software 3.3 and 3.4 release series are supported on Red Hat Enterprise 6 and 7 for 64-bit (RHEL 6 and RHEL 7) and 32-bit (RHEL 6 only) Intel architectures.  OSG also supports select rebuilds of RHEL.  Specifically:   CentOS 6  CentOS 7  Red Hat Enterprise Linux 6  Red Hat Enterprise Linux 7  Scientific Linux 6  Scientific Linux 7   The OSG Software 3.1 and 3.2 release series also supported Red Hat Enterprise Linux 5, but neither 3.1 nor 3.2 are actively supported.", 
            "title": "OSG Software Supported Operating Systems"
        }, 
        {
            "location": "/common/pki-cli/", 
            "text": "OSG PKI Command Line Clients\n\n\nOverview\n\n\nThe OSG PKI Command Line Clients provide a command-line interface for requesting and issuing host certificates from the OSG PKI. They complement the \nOIM Web Interface\n.\n\n\nPrerequisites\n\n\nIf you have not already done so, you need to \nconfigure the OSG software repositories\n.\n\n\nInstallation\n\n\nThe command-line scripts have been packaged as an RPM and are available from the OSG repositories.\n\n\nTo install the RPM, run:\n\n\n[root@client ~] #\n yum install osg-pki-tools\n\n\n\n\n\nUsage\n\n\nConfiguration Files\n\n\nThis configuration file contains information divided into two sections for testing and production.  Configuration variables include:\n\n\n\n\nRequest URL\n\n\nApprove URL\n\n\nRetrieve URL\n\n\nHost URL\n\n\n\n\nThese parameters are used as input to the script depending upon the mode of execution of the script (test or OIM). The command-line utilities check for configuration files in the following order:\n\n\n\n\n$HOME/.osg-pki/OSG_PKI.ini\n\n\n./pki-clients.ini\n\n\n/etc/pki-clients.ini\n\n\n\n\nosg-cert-request\n\n\nSends a request for a host certificate.\n\n\nThis script generates a private key and submits a request for a certificate to the OSG PKI. The request will be approved by an appropriate Grid Admin. You will receive an email when this approval has been completed containing directions on how to run \nosg-cert-retreive\n to retrieve the certificate. It works in two modes:\n\n\n\n\nCSR is provided by the user: the CSR provided is sent to the OIM.\n\n\nCSR is not provided by the user: the script generates a private key for the user. Writes it to default key file name or the one specified by \n-o\n.\n\n\n\n\nThis script:\n\n\n\n\nGenerates a new host private key and CSR (the only important part of CSR is \nCN=\nHOSTNAME\n component).\n\n\nSaves the host private key to disk (as specified by the user).\n\n\nAuthenticates to OIM and posts the CSR as a request to OIM.\n\n\nReturns the request ID to the user.\n\n\n\n\nIf the user provides the CSR, then this script would just send the same CSR to OIM.\n\n\nInputs:\n\n\n\n\nfully-qualified hostname\n\n\nfilename to store private key (optional; default is \n./hostkey.pem\n).\n\n\npath to user's certificate (optional: default is path specified by \n$X509_USER_CERT\n environment variable, then \n~/.globus/usercert.pem\n).\n\n\npath to user's private key (optional: default is path specified by \n$X509_USER_KEY\n environment variable, then \n~/.globus/userkey.pem\n).\n\n\nPassphrase for user's private key (via non-echoing prompt).\n\n\nUser needs to provide VO name if the requested hostname has multiple VO's assigned.\n\n\n\n\nOutputs:\n\n\n\n\nPrivate key, to filename specified by \n-o\n or \n./hostkey.pem\n by default.\n\n\nRequest Id, to \nstdout\n.\n\n\n\n\n[root@client ~] #\n osg-cert-request --help\n\nUsage: osg-cert-request [options]\n\n\n\nOptions:\n\n\n  -h, --help            show this help message and exit\n\n\n  -c CSR, --csr=CSR     Specify CSR name (default = gennew.csr)\n\n\n  -o OUTPUT KEYFILE, --outkeyfile=OUTPUT KEYFILE\n\n\n                        Specify the output filename for the retrieved user certificate.\n\n\n                        Default is ./hostkey.pem\n\n\n  -v VO name, --vo=VO name\n\n\n                        Specify the VO for the host request\n\n\n  -y CC LIST, --cc=CC LIST\n\n\n                        Specify the CC list(the email id\ns to be CCed).\n\n\n                        Separate values by \n,\n\n\n  -m COMMENT, --comment=COMMENT\n\n\n                        The comment to be added to the request\n\n\n  -H CN, --hostname=CN  Specify a hostname for CSR (FQDN)\n\n\n  -a HOSTNAME, --altname=HOSTNAME\n\n\n                        Specify an alternative hostname for the CSR (FQDN). May be used more than once\n\n\n  -e EMAIL, --email=EMAIL\n\n\n                        Email address to receive certificate\n\n\n  -n NAME, --name=NAME  Name of user receiving certificate\n\n\n  -p PHONE, --phone=PHONE\n\n\n                        Phone number of user receiving certificate\n\n\n  -t TIMEOUT, --timeout=TIMEOUT\n\n\n                        Specify the timeout in minutes\n\n\n  -T, --test            Run in test mode\n\n\n  -q, --quiet           don\nt print status messages to stdout\n\n\n  -d WRITE_DIRECTORY, --directory=WRITE_DIRECTORY\n\n\n                        Write the output files to this directory\n\n\n  -V, --version         Print version information and exit\n\n\n\n\n\n\nExamples.\n\n\nOSG generates the key pair for the request.\n\n\n[root@client ~] #\n osg-cert-request -t hostname.domain.com -e emailaddress@domain.com -n \nYour Name\n -p \n9999999999\n -y \nxyz@domain.com,abc@domain.com\n -m \nThis is my comment\n\n\n\n\n\n\nIf you want to request a service certificate, you need to escape backslash for service name inside CN like following.\n\n\n[root@client ~] #\n osg-cert-request -t hostname.domain.com -e emailaddress@domain.com -n \nYour Name\n -p \n9999999999\n -y \nrsv\\/xyz@domain.com\n -m \nThis is my comment\n\n\n\n\n\n\nYou can create your CSR on your target hosts using tools such as \nopenssl\n.\n\n\n[root@client ~] #\n \numask\n \n077\n;\n openssl req -new -newkey rsa:2048 -nodes -keyout hostkey.pem -subj \n/CN=osg-ce.example.edu\n -out csr.pem\n\n\n\n\n\nNote that the DN will be overriden by the OSG PKI except for the CN component.\n\n\nSubmitting the request:\n\n\n[root@client ~] #\n osg-cert-request -t hostname.domain.com -e emailaddress@domain.com -n \nYour Name\n -p \n9999999999\n -y \nxyz@domain.com,abc@domain.com\n -m \nThis is my comment\n --csr csr.pem\n\n\n\n\n\nosg-cert-retrieve\n\n\nRetrieve a certificate (host or user) from OIM given a request Id. Typically you will run this script after submitting a request with \nosg-cert-request\n and receiving an email telling you your certificate has been approved.\n\n\nYou can also use this script to retrieve other certificates that have been previously issued (assuming you know their request ID number).\n\n\nSince certificates are public, no authentication of the user is required.\n\n\nThis script:\n\n\n\n\nAccepts a request Id from the user\n\n\nConnects to OIM and requests the certificate identified by the request ID\n\n\nWrites the certificate to disk (as specified by the user)\n\n\n\n\nInputs:\n\n\n\n\nRequest ID\n\n\nFilename to store certificate (optional: default is \n./hostcert.pem\n).\n\n\n\n\nOutputs:\n\n\n\n\nHost certificate as PEM, to filename specified or \n./hostcert.pem\n.\n\n\n\n\n[root@client ~] #\n osg-cert-retrieve --help\n\nUsage: osg-cert-retrieve [options] \nRequest ID\n\n\nUsage: osg-cert-retrieve -h/--help [for detailed explanations of options]\n\n\n\nOptions:\n\n\n  -h, --help            show this help message and exit\n\n\n  -o ID, --certfile=ID  Specify the output filename for the retrieved user\n\n\n                        certificate . Default is ./hostcert.pem\n\n\n  -T, --test            Run in test mode\n\n\n  -t TIMEOUT, --timeout=TIMEOUT\n\n\n                        Specify the timeout in minutes\n\n\n  -q, --quiet           don\nt print status messages to stdout\n\n\n  -d WRITE_DIRECTORY, --directory=WRITE_DIRECTORY\n\n\n                        Write the output files to this directory\n\n\n  -V, --version         Print version information and exit\n\n\n  -i, --id              Specify ID# of certificate to be retrieved\n\n\n                        [deprecated]\n\n\n\n\n\n\nExample:\n\n\n[root@client ~] #\n osg-cert-retrieve -i \n555\n\n\n\n\n\n\nosg-gridadmin-cert-request\n\n\nRequest and retrieve multliple host certificates from OIM. Authenticates to OIM and is only for use by Grid Admins for certificates they are authorized to approve. This script is only supported with all hosts being in the same domain (so we ensure they go to the same Grid Admin). The certificates are stored with the format of \nhostname-requestid.pem\n (i.e. the id generated from the request for the certificate). The key is stored as \nhostname-serial-key.pem\n.\n\n\nThis script does the following in the process of acquiring certificates for the hostnames specified:\n\n\n\n\nReads a list of fully-qualified hostnames from a file specified by the user.\n\n\nFor each hostname:\n\n\nGenerates a new private key and CSR.\n\n\nOnly important part of CSR is \nCN=\nHOSTNAME\n component.\n\n\nWrites the private key to a file with filename: \nPREFIX\n/\nHOSTNAME\n-key.pem\n.\n\n\nPrompts the user for their private key pass phrase (the pass phrase is cached so user is not re-prompted).\n\n\nAuthenticates to OIM and posts the CSRs as a single request to OIM.\n\n\nRequest ID is returned and subsequently used.\n\n\nAuthenticates to OIM and approves the request.\n\n\nWaits one minute for request to be processed by OIM.\n\n\nConnects to OIM and attempts to retrieve certificates.\n\n\nWrites out any certificates it retrieves with filename of \nPREFIX\n/\nHOSTNAME\n-\nID\n.pem\n.\n\n\nIf all certificates have been retrieved, exits loop.\n\n\nWait 5 seconds and proceeds with the next repeat.\n\n\n\n\n\n\n\n\nInputs:\n\n\n\n\nfilename of list of hostnames.\n\n\nprefix path in which to write private keys and certificates (default: \n.\n.)\n\n\npath to user's certificate (optional: default is path specified by \n$X509_USER_CERT\n environment variable, then \n~/.globus/usercert.pem\n).\n\n\npath to user's private key (optional, default is path specified by \n$X509_USER_KEY\n environment variable, then \n~/.globus/userkey.pem\n).\n\n\nPassphrase for user's private key via non-echoing prompt.\n\n\n\n\nOutputs:\n\n\n\n\nN\n host certificates in PEM format.\n\n\nN\n private keys in PEM format.\n\n\n\n\n[root@client ~] #\n osg-gridadmin-cert-request --help\n\nUsage: osg-gridadmin-cert-request [options] arg\n\n\nUsage: osg-gridadmin-cert-request -h/--help [for detailed explanations of options]\n\n\n\nOptions:\n\n\n  -h, --help            show this help message and exit\n\n\n  -k PKEY, --pkey=PKEY  Specify Requestor\ns private key (PEM Format). If not\n\n\n                        specifiedwill take the value of X509_USER_KEY or\n\n\n                        $\nHOME/.globus/userkey.pem\n\n  -c CERT, --cert=CERT  Specify Requestor\ns certificate (PEM Format). If not\n\n\n                        specified, will take the value of X509_USER_CERT or\n\n\n                        $\nHOME/.globus/usercert.pem\n\n  -a HOSTNAME, --altname=HOSTNAME\n\n\n                        Specify an alternative hostname for CSR (FQDN). May be\n\n\n                        used more than once and if specified, -f/--hostfile\n\n\n                        will be ignored\n\n\n  -v VO name, --vo=VO name\n\n\n                        Specify the VO for the host request\n\n\n  -y CC List, --cc=CC List\n\n\n                        Specify the CC list(the email id\ns to be\n\n\n                        CCed).Separate values by \n,\n\n\n  -T, --test            Run in test mode\n\n\n  -t TIMEOUT, --timeout=TIMEOUT\n\n\n                        Specify the timeout in minutes\n\n\n  -q, --quiet           don\nt print status messages to stdout\n\n\n  -d WRITE_DIRECTORY, --directory=WRITE_DIRECTORY\n\n\n                        Write the output files to this directory\n\n\n  -V, --version         Print version information and exit\n\n\n\n  Hostname Options:\n\n\n    Use either of these options. Specify hostname as a single hostname\n\n\n    using -H/--hostname or specify from a file using -f/--hostfile.\n\n\n\n    -H HOSTNAME, --hostname=HOSTNAME\n\n\n                        Specify the hostname or service/hostname for which you\n\n\n                        want to request the certificate for. If specified,\n\n\n                        -f/--hostfile will be ignored\n\n\n    -f HOSTFILE, --hostfile=HOSTFILE\n\n\n                        Filename with one host (hostname or service/hostname\n\n\n                        and its optional,alternative hostnames, separated by\n\n\n                        spaces) per line\n\n\n\n\n\n\nExamples:\n\n\n[root@client ~] #\n osg-gridadmin-cert-request -f filename -k privatekeyfile -c certificatefile\n\n\n\n\n\n[root@client ~] #\n osg-gridadmin-cert-request -H hostname.domain.com -k privatekeyfile -c certificatefile\n\n\n\n\n\nosg-user-cert-renew\n\n\nSends a request for renewing a user certificate and if the certificate can be renewed, fetches and writes the renewed certificate.\n\n\nThe script generates request for renewing user certificate to the OIM, and if the certificate is renewed, it fetches the renewed user certificate. The user is authenticated before making such a request. If the user certificate is renewed, the user gets email notification regarding the same and the renewed certificate is saved by the name of the existing certificate suffixed by \n-renewed.pem\n (e.g. when we renew \nmy-cert.pem\n, the renewed certificate is named \nmy-cert-renewed.pem\n).\n\n\nInputs:\n\n\n\n\npath to user's certificate (optional: default is path specified by \n$X509_USER_CERT\n environment variable, then \n~/.globus/usercert.pem\n).\n\n\npath to user's private key (optional: default is path specified by \n$X509_USER_KEY\n environment variable, then \n~/.globus/userkey.pem\n).\n\n\nPassphrase for user's private key via non-echoing prompt.\n\n\nUser needs to provide VO name if the requested hostname has multiple VO's assigned\n\n\n\n\nOutputs:\n\n\n\n\nOn Renewal, the renewed certificate is stored with the filename of the older user certificate suffixed with \n-renewed.pem\n.  The certificate name for renewed certificate is sent to \nstdout\n.\n\n\n\n\n\n\nNote\n\n\nIf the retrieval of user certificate fails for some reason, the user can download the renewed certificate from OIM web interface using the following URL (where \nREQID\n is the request ID number for the user certificate on OIM):\n\n\nhttps://oim.opensciencegrid.org/oim/certificateuser?id=\nREQID\n\n\n\n\n\n\n\n\n[root@client ~] #\n osg-user-cert-renew --help\n\nUsage: osg-user-cert-renew [options]\n\n\n\nOptions:\n\n\n  -h, --help            show this help message and exit\n\n\n  -k PKEY, --pkey=PKEY  Specify Requestor\ns private key (PEM Format). If not\n\n\n                        specified  will take the value of X509_USER_KEY or\n\n\n                        $\nHOME/.globus/userkey.pem\n\n  -c CERT, --cert=CERT  Specify Requestor\ns certificate (PEM Format).  If not\n\n\n                        specified will take the value of X509_USER_CERT or\n\n\n                        $\nHOME/.globus/usercert.pem\n\n  -T, --test            Run in test mode\n\n\n  -t TIMEOUT, --timeout=TIMEOUT\n\n\n                        Specify the timeout in minutes\n\n\n  -d WRITE_DIRECTORY, --directory=WRITE_DIRECTORY\n\n\n                        Write the output files to this directory\n\n\n  -q, --quiet           don\nt print status messages to stdout\n\n\n  -V, --version         Print version information and exit\n\n\n\n\n\n\nExample\n\n\n[root@client ~] #\n osg-user-cert-renew -k userkey.pem -c usercert.pem\n\n\n\n\n\nosg-user-cert-revoke\n\n\nRevoke a user certificate from OIM given a request ID or certificate ID. Usually the script is run when a user wants to revoke user certificate.\n\n\nFor revoking user certificate, user authentication is done and if the user is authorized to revoke the user certificate, the certificate is immediately revoked and an email notification is sent informing the user that the user certificate is revoked.\n\n\nThe script:\n\n\n\n\nAccepts a Request ID or Certificate ID from the user.\n\n\nAuthenticates user and connects to OIM to revoke the user certificate identified by the request ID or the certificate ID.\n\n\n\n\nInputs:\n\n\n\n\nPrivate key for the user requesting host certificate revocation.\n\n\nUser certificate for the user requesting host certificate revocation.\n\n\nMessage for requesting the user certificate revocation.\n\n\nRequest ID OR the certificate ID for the user certificate to be revoked.\n\n\n\n\nOutputs:\n\n\n\n\nMessage if the revocation was successful along with the host cert request ID/certificate ID on \nstdout\n.\n\n\nError message if the revocation was unsuccessful on \nstdout\n.\n\n\n\n\nIf the user's private key and certificate are not provided, the script takes the private key and user certificate from the \n~/.globus\n folder using the default names (\nuserkey.pem\n and \nusercert.pem\n, respectively)\n\n\n[root@client ~] #\n osg-user-cert-revoke --help\n\nUsage: osg-user-cert-revoke [options] \nRequest ID\n \nmessage\n\n\nUsage: osg-user-cert-revoke -h/--help [for detailed explanations of options]\n\n\n\nOptions:\n\n\n  -h, --help            show this help message and exit\n\n\n  -n, --certid          Treat the ID argument as the serial ID# for the\n\n\n                        certificate to be revoked\n\n\n  -u, --user            Certificate to be revoked is a user certificate.\n\n\n                        Redundant when using `osg-user-cert-revoke`.\n\n\n  -k PKEY, --pkey=PKEY  Specify Requestor\ns private key (PEM Format). If not\n\n\n                        specified, this takes the value of X509_USER_KEY or\n\n\n                        $\nHOME/.globus/userkey.pem\n\n  -c CERT, --cert=CERT  Specify Requestor\ns certificate (PEM Format). If not\n\n\n                        specified, this takes the value of X509_USER_CERT or\n\n\n                        $\nHOME/.globus/usercert.pem\n\n  -T, --test            Run in test mode\n\n\n  -t TIMEOUT, --timeout=TIMEOUT\n\n\n                        Specify the timeout in minutes\n\n\n  -q, --quiet           don\nt print status messages to stdout\n\n\n  -V, --version         Print version information and exit\n\n\n  -m REASON, --message=REASON\n\n\n                        Specify the reason for certificate revocation\n\n\n                        [deprecated]\n\n\n  -i, --id              Specify ID# of certificate to be retrieved\n\n\n                        [deprecated]\n\n\n\n\n\n\nExample:\n\n\n[root@client ~] #\n osg-user-cert-revoke -i \n999\n -m \nTesting user cert revocation\n -k privatekeyfile -c usercertfile\n\n\n\n\n\nosg-cert-revoke\n\n\nRevoke a host certificate from OIM given a request ID. Usually the script is run when a user wants to revoke host/service certificate.\n\n\nFor revoking host certificate, user authentication is done and if the user is authorized to revoke the host certificate, the certificate is immediately revoked and an email notification is sent informing the user that the host certificate is revoked.\n\n\nThe script:\n\n\n\n\nAccepts a request ID from the user.\n\n\nAuthenticates user and connects to OIM to revoke the host certificate identified by the request ID.\n\n\n\n\nInputs:\n\n\n\n\nPrivate key for the user requesting host certificate revocation.\n\n\ncertificate for the user requesting host certificate revocation.\n\n\nMessage for requesting the host certificate revocation.\n\n\nRequest ID for the host certificate to be revoked.\n\n\n\n\nOutputs:\n\n\n\n\nMessage if the revocation was successful along with the host cert request ID on \nstdout\n.\n\n\nError message if the revocation was unsuccessful on \nstdout\n.\n\n\n\n\nIf the user's private key and certificate are not provided, the script takes the private key and user certificate from the \n~/.globus\n folder using the default names (\nuserkey.pem\n and \nusercert.pem\n, respectively).\n\n\n[root@client ~] #\n osg-user-cert-revoke --help\n\nUsage: osg-cert-revoke [options] \nRequest ID\n \nmessage\n\n\nUsage: osg-cert-revoke -h/--help [for detailed explanations of options]\n\n\n\nOptions:\n\n\n  -h, --help            show this help message and exit\n\n\n  -n, --certid          Treat the ID argument as the serial ID# for the\n\n\n                        certificate to be revoked\n\n\n  -u, --user            Certificate to be revoked is a user certificate.\n\n\n                        Redundant when using `osg-user-cert-revoke`.\n\n\n  -k PKEY, --pkey=PKEY  Specify Requestor\ns private key (PEM Format). If not\n\n\n                        specified, this takes the value of X509_USER_KEY or\n\n\n                        $\nHOME/.globus/userkey.pem\n\n  -c CERT, --cert=CERT  Specify Requestor\ns certificate (PEM Format). If not\n\n\n                        specified, this takes the value of X509_USER_CERT or\n\n\n                        $\nHOME/.globus/usercert.pem\n\n  -T, --test            Run in test mode\n\n\n  -t TIMEOUT, --timeout=TIMEOUT\n\n\n                        Specify the timeout in minutes\n\n\n  -q, --quiet           don\nt print status messages to stdout\n\n\n  -V, --version         Print version information and exit\n\n\n  -m REASON, --message=REASON\n\n\n                        Specify the reason for certificate revocation\n\n\n                        [deprecated]\n\n\n  -i, --id              Specify ID# of certificate to be retrieved\n\n\n                        [deprecated]\n\n\n\n\n\n\nExample:\n\n\n[root@client ~] #\n osg-cert-revoke -i \n999\n -m \nTesting host cert revocation\n -k privatekeyfile -c usercertfile\n\n\n\n\n\nTest Mode\n\n\nThe scripts have two modes of execution.\n\n\nIn the normal mode of execution, the script connects to the production server and generated certificates are from default OSG CA.\n\n\nIf the user provides a \n-T\n parameter on the command-line, the scripts connect to the OIM-ITB server and any generated certificates are issued by the OSG test CAs. This mode is intended for testing and training. The resulting certificates are not usable in a production environment.\n\n\nCurrent Limitations and Bugs\n\n\n\n\nNote that Common Names (CNs) are limited to 64 characters. This is a limitation of OpenSSL and the PKI standard. For details see \nOSGPKI-252\n.", 
            "title": "Certificate Tools"
        }, 
        {
            "location": "/common/pki-cli/#osg-pki-command-line-clients", 
            "text": "", 
            "title": "OSG PKI Command Line Clients"
        }, 
        {
            "location": "/common/pki-cli/#overview", 
            "text": "The OSG PKI Command Line Clients provide a command-line interface for requesting and issuing host certificates from the OSG PKI. They complement the  OIM Web Interface .", 
            "title": "Overview"
        }, 
        {
            "location": "/common/pki-cli/#prerequisites", 
            "text": "If you have not already done so, you need to  configure the OSG software repositories .", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/common/pki-cli/#installation", 
            "text": "The command-line scripts have been packaged as an RPM and are available from the OSG repositories.  To install the RPM, run:  [root@client ~] #  yum install osg-pki-tools", 
            "title": "Installation"
        }, 
        {
            "location": "/common/pki-cli/#usage", 
            "text": "", 
            "title": "Usage"
        }, 
        {
            "location": "/common/pki-cli/#configuration-files", 
            "text": "This configuration file contains information divided into two sections for testing and production.  Configuration variables include:   Request URL  Approve URL  Retrieve URL  Host URL   These parameters are used as input to the script depending upon the mode of execution of the script (test or OIM). The command-line utilities check for configuration files in the following order:   $HOME/.osg-pki/OSG_PKI.ini  ./pki-clients.ini  /etc/pki-clients.ini", 
            "title": "Configuration Files"
        }, 
        {
            "location": "/common/pki-cli/#osg-cert-request", 
            "text": "Sends a request for a host certificate.  This script generates a private key and submits a request for a certificate to the OSG PKI. The request will be approved by an appropriate Grid Admin. You will receive an email when this approval has been completed containing directions on how to run  osg-cert-retreive  to retrieve the certificate. It works in two modes:   CSR is provided by the user: the CSR provided is sent to the OIM.  CSR is not provided by the user: the script generates a private key for the user. Writes it to default key file name or the one specified by  -o .   This script:   Generates a new host private key and CSR (the only important part of CSR is  CN= HOSTNAME  component).  Saves the host private key to disk (as specified by the user).  Authenticates to OIM and posts the CSR as a request to OIM.  Returns the request ID to the user.   If the user provides the CSR, then this script would just send the same CSR to OIM.  Inputs:   fully-qualified hostname  filename to store private key (optional; default is  ./hostkey.pem ).  path to user's certificate (optional: default is path specified by  $X509_USER_CERT  environment variable, then  ~/.globus/usercert.pem ).  path to user's private key (optional: default is path specified by  $X509_USER_KEY  environment variable, then  ~/.globus/userkey.pem ).  Passphrase for user's private key (via non-echoing prompt).  User needs to provide VO name if the requested hostname has multiple VO's assigned.   Outputs:   Private key, to filename specified by  -o  or  ./hostkey.pem  by default.  Request Id, to  stdout .   [root@client ~] #  osg-cert-request --help Usage: osg-cert-request [options]  Options:    -h, --help            show this help message and exit    -c CSR, --csr=CSR     Specify CSR name (default = gennew.csr)    -o OUTPUT KEYFILE, --outkeyfile=OUTPUT KEYFILE                          Specify the output filename for the retrieved user certificate.                          Default is ./hostkey.pem    -v VO name, --vo=VO name                          Specify the VO for the host request    -y CC LIST, --cc=CC LIST                          Specify the CC list(the email id s to be CCed).                          Separate values by  ,    -m COMMENT, --comment=COMMENT                          The comment to be added to the request    -H CN, --hostname=CN  Specify a hostname for CSR (FQDN)    -a HOSTNAME, --altname=HOSTNAME                          Specify an alternative hostname for the CSR (FQDN). May be used more than once    -e EMAIL, --email=EMAIL                          Email address to receive certificate    -n NAME, --name=NAME  Name of user receiving certificate    -p PHONE, --phone=PHONE                          Phone number of user receiving certificate    -t TIMEOUT, --timeout=TIMEOUT                          Specify the timeout in minutes    -T, --test            Run in test mode    -q, --quiet           don t print status messages to stdout    -d WRITE_DIRECTORY, --directory=WRITE_DIRECTORY                          Write the output files to this directory    -V, --version         Print version information and exit", 
            "title": "osg-cert-request"
        }, 
        {
            "location": "/common/pki-cli/#examples", 
            "text": "OSG generates the key pair for the request.  [root@client ~] #  osg-cert-request -t hostname.domain.com -e emailaddress@domain.com -n  Your Name  -p  9999999999  -y  xyz@domain.com,abc@domain.com  -m  This is my comment   If you want to request a service certificate, you need to escape backslash for service name inside CN like following.  [root@client ~] #  osg-cert-request -t hostname.domain.com -e emailaddress@domain.com -n  Your Name  -p  9999999999  -y  rsv\\/xyz@domain.com  -m  This is my comment   You can create your CSR on your target hosts using tools such as  openssl .  [root@client ~] #   umask   077 ;  openssl req -new -newkey rsa:2048 -nodes -keyout hostkey.pem -subj  /CN=osg-ce.example.edu  -out csr.pem  Note that the DN will be overriden by the OSG PKI except for the CN component.  Submitting the request:  [root@client ~] #  osg-cert-request -t hostname.domain.com -e emailaddress@domain.com -n  Your Name  -p  9999999999  -y  xyz@domain.com,abc@domain.com  -m  This is my comment  --csr csr.pem", 
            "title": "Examples."
        }, 
        {
            "location": "/common/pki-cli/#osg-cert-retrieve", 
            "text": "Retrieve a certificate (host or user) from OIM given a request Id. Typically you will run this script after submitting a request with  osg-cert-request  and receiving an email telling you your certificate has been approved.  You can also use this script to retrieve other certificates that have been previously issued (assuming you know their request ID number).  Since certificates are public, no authentication of the user is required.  This script:   Accepts a request Id from the user  Connects to OIM and requests the certificate identified by the request ID  Writes the certificate to disk (as specified by the user)   Inputs:   Request ID  Filename to store certificate (optional: default is  ./hostcert.pem ).   Outputs:   Host certificate as PEM, to filename specified or  ./hostcert.pem .   [root@client ~] #  osg-cert-retrieve --help Usage: osg-cert-retrieve [options]  Request ID  Usage: osg-cert-retrieve -h/--help [for detailed explanations of options]  Options:    -h, --help            show this help message and exit    -o ID, --certfile=ID  Specify the output filename for the retrieved user                          certificate . Default is ./hostcert.pem    -T, --test            Run in test mode    -t TIMEOUT, --timeout=TIMEOUT                          Specify the timeout in minutes    -q, --quiet           don t print status messages to stdout    -d WRITE_DIRECTORY, --directory=WRITE_DIRECTORY                          Write the output files to this directory    -V, --version         Print version information and exit    -i, --id              Specify ID# of certificate to be retrieved                          [deprecated]   Example:  [root@client ~] #  osg-cert-retrieve -i  555", 
            "title": "osg-cert-retrieve"
        }, 
        {
            "location": "/common/pki-cli/#osg-gridadmin-cert-request", 
            "text": "Request and retrieve multliple host certificates from OIM. Authenticates to OIM and is only for use by Grid Admins for certificates they are authorized to approve. This script is only supported with all hosts being in the same domain (so we ensure they go to the same Grid Admin). The certificates are stored with the format of  hostname-requestid.pem  (i.e. the id generated from the request for the certificate). The key is stored as  hostname-serial-key.pem .  This script does the following in the process of acquiring certificates for the hostnames specified:   Reads a list of fully-qualified hostnames from a file specified by the user.  For each hostname:  Generates a new private key and CSR.  Only important part of CSR is  CN= HOSTNAME  component.  Writes the private key to a file with filename:  PREFIX / HOSTNAME -key.pem .  Prompts the user for their private key pass phrase (the pass phrase is cached so user is not re-prompted).  Authenticates to OIM and posts the CSRs as a single request to OIM.  Request ID is returned and subsequently used.  Authenticates to OIM and approves the request.  Waits one minute for request to be processed by OIM.  Connects to OIM and attempts to retrieve certificates.  Writes out any certificates it retrieves with filename of  PREFIX / HOSTNAME - ID .pem .  If all certificates have been retrieved, exits loop.  Wait 5 seconds and proceeds with the next repeat.     Inputs:   filename of list of hostnames.  prefix path in which to write private keys and certificates (default:  . .)  path to user's certificate (optional: default is path specified by  $X509_USER_CERT  environment variable, then  ~/.globus/usercert.pem ).  path to user's private key (optional, default is path specified by  $X509_USER_KEY  environment variable, then  ~/.globus/userkey.pem ).  Passphrase for user's private key via non-echoing prompt.   Outputs:   N  host certificates in PEM format.  N  private keys in PEM format.   [root@client ~] #  osg-gridadmin-cert-request --help Usage: osg-gridadmin-cert-request [options] arg  Usage: osg-gridadmin-cert-request -h/--help [for detailed explanations of options]  Options:    -h, --help            show this help message and exit    -k PKEY, --pkey=PKEY  Specify Requestor s private key (PEM Format). If not                          specifiedwill take the value of X509_USER_KEY or                          $ HOME/.globus/userkey.pem   -c CERT, --cert=CERT  Specify Requestor s certificate (PEM Format). If not                          specified, will take the value of X509_USER_CERT or                          $ HOME/.globus/usercert.pem   -a HOSTNAME, --altname=HOSTNAME                          Specify an alternative hostname for CSR (FQDN). May be                          used more than once and if specified, -f/--hostfile                          will be ignored    -v VO name, --vo=VO name                          Specify the VO for the host request    -y CC List, --cc=CC List                          Specify the CC list(the email id s to be                          CCed).Separate values by  ,    -T, --test            Run in test mode    -t TIMEOUT, --timeout=TIMEOUT                          Specify the timeout in minutes    -q, --quiet           don t print status messages to stdout    -d WRITE_DIRECTORY, --directory=WRITE_DIRECTORY                          Write the output files to this directory    -V, --version         Print version information and exit    Hostname Options:      Use either of these options. Specify hostname as a single hostname      using -H/--hostname or specify from a file using -f/--hostfile.      -H HOSTNAME, --hostname=HOSTNAME                          Specify the hostname or service/hostname for which you                          want to request the certificate for. If specified,                          -f/--hostfile will be ignored      -f HOSTFILE, --hostfile=HOSTFILE                          Filename with one host (hostname or service/hostname                          and its optional,alternative hostnames, separated by                          spaces) per line   Examples:  [root@client ~] #  osg-gridadmin-cert-request -f filename -k privatekeyfile -c certificatefile  [root@client ~] #  osg-gridadmin-cert-request -H hostname.domain.com -k privatekeyfile -c certificatefile", 
            "title": "osg-gridadmin-cert-request"
        }, 
        {
            "location": "/common/pki-cli/#osg-user-cert-renew", 
            "text": "Sends a request for renewing a user certificate and if the certificate can be renewed, fetches and writes the renewed certificate.  The script generates request for renewing user certificate to the OIM, and if the certificate is renewed, it fetches the renewed user certificate. The user is authenticated before making such a request. If the user certificate is renewed, the user gets email notification regarding the same and the renewed certificate is saved by the name of the existing certificate suffixed by  -renewed.pem  (e.g. when we renew  my-cert.pem , the renewed certificate is named  my-cert-renewed.pem ).  Inputs:   path to user's certificate (optional: default is path specified by  $X509_USER_CERT  environment variable, then  ~/.globus/usercert.pem ).  path to user's private key (optional: default is path specified by  $X509_USER_KEY  environment variable, then  ~/.globus/userkey.pem ).  Passphrase for user's private key via non-echoing prompt.  User needs to provide VO name if the requested hostname has multiple VO's assigned   Outputs:   On Renewal, the renewed certificate is stored with the filename of the older user certificate suffixed with  -renewed.pem .  The certificate name for renewed certificate is sent to  stdout .    Note  If the retrieval of user certificate fails for some reason, the user can download the renewed certificate from OIM web interface using the following URL (where  REQID  is the request ID number for the user certificate on OIM):  https://oim.opensciencegrid.org/oim/certificateuser?id= REQID    [root@client ~] #  osg-user-cert-renew --help Usage: osg-user-cert-renew [options]  Options:    -h, --help            show this help message and exit    -k PKEY, --pkey=PKEY  Specify Requestor s private key (PEM Format). If not                          specified  will take the value of X509_USER_KEY or                          $ HOME/.globus/userkey.pem   -c CERT, --cert=CERT  Specify Requestor s certificate (PEM Format).  If not                          specified will take the value of X509_USER_CERT or                          $ HOME/.globus/usercert.pem   -T, --test            Run in test mode    -t TIMEOUT, --timeout=TIMEOUT                          Specify the timeout in minutes    -d WRITE_DIRECTORY, --directory=WRITE_DIRECTORY                          Write the output files to this directory    -q, --quiet           don t print status messages to stdout    -V, --version         Print version information and exit   Example  [root@client ~] #  osg-user-cert-renew -k userkey.pem -c usercert.pem", 
            "title": "osg-user-cert-renew"
        }, 
        {
            "location": "/common/pki-cli/#osg-user-cert-revoke", 
            "text": "Revoke a user certificate from OIM given a request ID or certificate ID. Usually the script is run when a user wants to revoke user certificate.  For revoking user certificate, user authentication is done and if the user is authorized to revoke the user certificate, the certificate is immediately revoked and an email notification is sent informing the user that the user certificate is revoked.  The script:   Accepts a Request ID or Certificate ID from the user.  Authenticates user and connects to OIM to revoke the user certificate identified by the request ID or the certificate ID.   Inputs:   Private key for the user requesting host certificate revocation.  User certificate for the user requesting host certificate revocation.  Message for requesting the user certificate revocation.  Request ID OR the certificate ID for the user certificate to be revoked.   Outputs:   Message if the revocation was successful along with the host cert request ID/certificate ID on  stdout .  Error message if the revocation was unsuccessful on  stdout .   If the user's private key and certificate are not provided, the script takes the private key and user certificate from the  ~/.globus  folder using the default names ( userkey.pem  and  usercert.pem , respectively)  [root@client ~] #  osg-user-cert-revoke --help Usage: osg-user-cert-revoke [options]  Request ID   message  Usage: osg-user-cert-revoke -h/--help [for detailed explanations of options]  Options:    -h, --help            show this help message and exit    -n, --certid          Treat the ID argument as the serial ID# for the                          certificate to be revoked    -u, --user            Certificate to be revoked is a user certificate.                          Redundant when using `osg-user-cert-revoke`.    -k PKEY, --pkey=PKEY  Specify Requestor s private key (PEM Format). If not                          specified, this takes the value of X509_USER_KEY or                          $ HOME/.globus/userkey.pem   -c CERT, --cert=CERT  Specify Requestor s certificate (PEM Format). If not                          specified, this takes the value of X509_USER_CERT or                          $ HOME/.globus/usercert.pem   -T, --test            Run in test mode    -t TIMEOUT, --timeout=TIMEOUT                          Specify the timeout in minutes    -q, --quiet           don t print status messages to stdout    -V, --version         Print version information and exit    -m REASON, --message=REASON                          Specify the reason for certificate revocation                          [deprecated]    -i, --id              Specify ID# of certificate to be retrieved                          [deprecated]   Example:  [root@client ~] #  osg-user-cert-revoke -i  999  -m  Testing user cert revocation  -k privatekeyfile -c usercertfile", 
            "title": "osg-user-cert-revoke"
        }, 
        {
            "location": "/common/pki-cli/#osg-cert-revoke", 
            "text": "Revoke a host certificate from OIM given a request ID. Usually the script is run when a user wants to revoke host/service certificate.  For revoking host certificate, user authentication is done and if the user is authorized to revoke the host certificate, the certificate is immediately revoked and an email notification is sent informing the user that the host certificate is revoked.  The script:   Accepts a request ID from the user.  Authenticates user and connects to OIM to revoke the host certificate identified by the request ID.   Inputs:   Private key for the user requesting host certificate revocation.  certificate for the user requesting host certificate revocation.  Message for requesting the host certificate revocation.  Request ID for the host certificate to be revoked.   Outputs:   Message if the revocation was successful along with the host cert request ID on  stdout .  Error message if the revocation was unsuccessful on  stdout .   If the user's private key and certificate are not provided, the script takes the private key and user certificate from the  ~/.globus  folder using the default names ( userkey.pem  and  usercert.pem , respectively).  [root@client ~] #  osg-user-cert-revoke --help Usage: osg-cert-revoke [options]  Request ID   message  Usage: osg-cert-revoke -h/--help [for detailed explanations of options]  Options:    -h, --help            show this help message and exit    -n, --certid          Treat the ID argument as the serial ID# for the                          certificate to be revoked    -u, --user            Certificate to be revoked is a user certificate.                          Redundant when using `osg-user-cert-revoke`.    -k PKEY, --pkey=PKEY  Specify Requestor s private key (PEM Format). If not                          specified, this takes the value of X509_USER_KEY or                          $ HOME/.globus/userkey.pem   -c CERT, --cert=CERT  Specify Requestor s certificate (PEM Format). If not                          specified, this takes the value of X509_USER_CERT or                          $ HOME/.globus/usercert.pem   -T, --test            Run in test mode    -t TIMEOUT, --timeout=TIMEOUT                          Specify the timeout in minutes    -q, --quiet           don t print status messages to stdout    -V, --version         Print version information and exit    -m REASON, --message=REASON                          Specify the reason for certificate revocation                          [deprecated]    -i, --id              Specify ID# of certificate to be retrieved                          [deprecated]   Example:  [root@client ~] #  osg-cert-revoke -i  999  -m  Testing host cert revocation  -k privatekeyfile -c usercertfile", 
            "title": "osg-cert-revoke"
        }, 
        {
            "location": "/common/pki-cli/#test-mode", 
            "text": "The scripts have two modes of execution.  In the normal mode of execution, the script connects to the production server and generated certificates are from default OSG CA.  If the user provides a  -T  parameter on the command-line, the scripts connect to the OIM-ITB server and any generated certificates are issued by the OSG test CAs. This mode is intended for testing and training. The resulting certificates are not usable in a production environment.", 
            "title": "Test Mode"
        }, 
        {
            "location": "/common/pki-cli/#current-limitations-and-bugs", 
            "text": "Note that Common Names (CNs) are limited to 64 characters. This is a limitation of OpenSSL and the PKI standard. For details see  OSGPKI-252 .", 
            "title": "Current Limitations and Bugs"
        }, 
        {
            "location": "/client/using-wn/", 
            "text": "Introduction\n\n\nThe Worker Node Client is a collection of useful software components that is expected to be on every OSG worker node. In addition, a job running on a worker node can access a handful of environment variables that can be used to locate resources..\n\n\nThis page describes how to initialize the environment of your job to correctly access the execution and data areas from the worker node.\n\n\nThe OSG provides no scientific software dependencies or software build tools on the worker node; you are expected to bring along all application-level dependencies yourself (preferred; most portable) or utilize CVMFS. Sites are not required to provide any specific tools (\ngcc\n, \nlapack\n, \nblas\n, etc.) beyond the ones in the OSG worker node client.\n\n\nCommon software available on worker nodes.\n\n\nThe OSG worker node client (called the \nosg-wn-client\n package) contains the following software:\n\n\n\n\nThe supported set of CA certificates (located in $X509_CERT_DIR after the environment is set up)\n\n\nProxy management tools:\n\n\nCreate proxies: \nvoms-proxy-init\n and \ngrid-proxy-init\n\n\nShow proxy info: \nvoms-proxy-info\n and \ngrid-proxy-info\n\n\nDestroy the current proxy: \nvoms-proxy-destroy\n and \ngrid-proxy-destroy\n\n\n\n\n\n\nData transfer tools:\n\n\nHTTP/plain FTP protocol tools (via system dependencies):\n\n\nwget\n and \ncurl\n: standard tools for downloading files with HTTP and FTP\n\n\n\n\n\n\nTransfer clients\n\n\nGFAL\n-based client (\ngfal-copy\n and others).  GFAL supports SRM, GridFTP, and HTTP protocols.\n\n\nGlobus GridFTP client (\nglobus-url-copy\n)\n\n\n\n\n\n\n\n\n\n\nMyProxy client tools\n\n\n\n\nThe Worker Node Environment\n\n\nThe following table outlines the various important directories and information in the worker node environment. A job running on an OSG worker node can refer to each directory using the corresponding environment variable.\n\n\n\n\n\n\n\n\nEnvironment Variable\n\n\nPurpose\n\n\nNotes\n\n\n\n\n\n\n\n\n\n\n$X509_CERT_DIR\n\n\nLocation of the CA certificates\n\n\n\n\n\n\n\n\n$OSG_WN_TMP\n\n\nTemporary storage area in which your job(s) run\n\n\nLocal to each batch slot. Create a directory under this as your work area.\n\n\n\n\n\n\n$_CONDOR_SCRATCH_DIR\n\n\nSuggested temporary storage are for glideinWMS-based VOs.\n\n\nUsers should prefer this environment variable if running inside glideinWMS.\n\n\n\n\n\n\n$OSG_SQUID_LOCATION\n, \nhttp_proxy\n\n\nLocation of a HTTP caching proxy server\n\n\nUtilize this service for downloading files via HTTP for cache-friendly workflows.\n\n\n\n\n\n\n$OSG_GRID\n\n\nLocation of additional environment variables.\n\n\nPilots should source \n$OSG_GRID/setup.sh\n in order to guarantee the environment contains the worker node binaries in \n$PATH\n.\n\n\n\n\n\n\n$OSG_SITE_NAME\n\n\nName of the site where the worker node is located.\n\n\n\n\n\n\n\n\n\n\nBe careful with using \n$OSG_WN_TMP\n; at some sites, this directory might be shared with other VOs. We recommend creating a new sub-directory as a precautio:\n\n\nmkdir -p \n$OSG_WN_TMP\n/MYVO\n\nexport\n \nmydir\n=\n`\nmktemp -d -t MYVO\n`\n\n\ncd\n \n$mydir\n\n\n# Run the rest of your application\n\nrm -rf \n$mydir\n\n\n\n\n\n\nA significant number of sites use the batch system to make an independent directory for each user job, and change \n$OSG_WN_TMP\n on the fly to point to this directory.\n\n\nThere is no way to know in advance how much scratch disk space any given worker node has available; recall, what disk space is available may be shared among a number of job slots.", 
            "title": "Worker Node Environment"
        }, 
        {
            "location": "/client/using-wn/#introduction", 
            "text": "The Worker Node Client is a collection of useful software components that is expected to be on every OSG worker node. In addition, a job running on a worker node can access a handful of environment variables that can be used to locate resources..  This page describes how to initialize the environment of your job to correctly access the execution and data areas from the worker node.  The OSG provides no scientific software dependencies or software build tools on the worker node; you are expected to bring along all application-level dependencies yourself (preferred; most portable) or utilize CVMFS. Sites are not required to provide any specific tools ( gcc ,  lapack ,  blas , etc.) beyond the ones in the OSG worker node client.", 
            "title": "Introduction"
        }, 
        {
            "location": "/client/using-wn/#common-software-available-on-worker-nodes", 
            "text": "The OSG worker node client (called the  osg-wn-client  package) contains the following software:   The supported set of CA certificates (located in $X509_CERT_DIR after the environment is set up)  Proxy management tools:  Create proxies:  voms-proxy-init  and  grid-proxy-init  Show proxy info:  voms-proxy-info  and  grid-proxy-info  Destroy the current proxy:  voms-proxy-destroy  and  grid-proxy-destroy    Data transfer tools:  HTTP/plain FTP protocol tools (via system dependencies):  wget  and  curl : standard tools for downloading files with HTTP and FTP    Transfer clients  GFAL -based client ( gfal-copy  and others).  GFAL supports SRM, GridFTP, and HTTP protocols.  Globus GridFTP client ( globus-url-copy )      MyProxy client tools", 
            "title": "Common software available on worker nodes."
        }, 
        {
            "location": "/client/using-wn/#the-worker-node-environment", 
            "text": "The following table outlines the various important directories and information in the worker node environment. A job running on an OSG worker node can refer to each directory using the corresponding environment variable.     Environment Variable  Purpose  Notes      $X509_CERT_DIR  Location of the CA certificates     $OSG_WN_TMP  Temporary storage area in which your job(s) run  Local to each batch slot. Create a directory under this as your work area.    $_CONDOR_SCRATCH_DIR  Suggested temporary storage are for glideinWMS-based VOs.  Users should prefer this environment variable if running inside glideinWMS.    $OSG_SQUID_LOCATION ,  http_proxy  Location of a HTTP caching proxy server  Utilize this service for downloading files via HTTP for cache-friendly workflows.    $OSG_GRID  Location of additional environment variables.  Pilots should source  $OSG_GRID/setup.sh  in order to guarantee the environment contains the worker node binaries in  $PATH .    $OSG_SITE_NAME  Name of the site where the worker node is located.      Be careful with using  $OSG_WN_TMP ; at some sites, this directory might be shared with other VOs. We recommend creating a new sub-directory as a precautio:  mkdir -p  $OSG_WN_TMP /MYVO export   mydir = ` mktemp -d -t MYVO `  cd   $mydir  # Run the rest of your application \nrm -rf  $mydir   A significant number of sites use the batch system to make an independent directory for each user job, and change  $OSG_WN_TMP  on the fly to point to this directory.  There is no way to know in advance how much scratch disk space any given worker node has available; recall, what disk space is available may be shared among a number of job slots.", 
            "title": "The Worker Node Environment"
        }, 
        {
            "location": "/common/ca_updater/", 
            "text": "OSG CA Certificates Updater\n\n\nThis document explains the installation and use of \nosg-ca-certs-updater\n, a package in the OSG Software 3.x distribution that provides automatic updates of CA certificates.\n\n\nRequirements\n\n\n\n\nOS must be Red Hat Enterprise Linux 5 or 6 or variants.\n\n\nThe OSG repositories must be installed and enabled. See the \nYum Repositories\n page for instructions.\n\n\nOne grid-certificates package from the OSG repositories must be installed as described \nhere\n. Currently, these are: \nigtf-ca-certs\n, \nosg-ca-certs\n.\n\n\n\n\nInstall instructions\n\n\nRun the following command to install the latest version of the updater.\n\n\n[root@client ~]$ yum install osg-ca-certs-updater\n\n\n\n\n\n\nServices\n\n\nStarting and Enabling Services\n\n\nRun the following to enable the updater. This will persist until the machine is rebooted.\n\n\n[root@client ~]$ service osg-ca-certs-updater-cron start\n\n\n\n\n\n\nRun the following to enable the updater when the machine is rebooted.\n\n\n[root@client ~]$ chkconfig osg-ca-certs-updater-cron on\n\n\n\n\n\n\nRun both commands if you wish for the service to activate immediately and remain active throughout reboots.\n\n\nStopping and Disabling Services\n\n\nEnter the following to disable the updater. This will persist until the machine is rebooted.\n\n\n[root@client ~]$ service osg-ca-certs-updater-cron stop\n\n\n\n\n\n\nEnter the following to disable the updater when the machine is rebooted.\n\n\n[root@client ~]$ chkconfig osg-ca-certs-updater-cron off\n\n\n\n\n\n\nRun both commands if you wish for the service to deactivate immediately and not get reactivated during reboots.\n\n\nConfiguration\n\n\nWhile there is no configuration file, the behavior of the updater can be adjusted by command-line arguments that are specified in the \ncron\n entry of the service. This entry is located in the file \n/etc/cron.d/osg-ca-certs-updater\n. Please see the Unix manual page for \ncrontab\n in section 5 for an explanation of the format. The manual page can be accessed by the command \nman 5 crontab\n. The valid command-line arguments can be listed by running \nosg-ca-certs-updater --help\n. Reasonable defaults have been provided, namely:\n\n\n\n\nAttempt an update no more often than every 23 hours. Due to the random wait (see below), having a 24-hour minimum time between updates would cause the update time to slowly slide back every day.\n\n\nRun the script every 6 hours. We run the script more often than we update so that downtime at the wrong moment does not cause the update to be delayed for a full day.\n\n\nDelay for a random amount of time up to 30 minutes before updating, to reduce load spikes on OSG repositories.\n\n\nDo not warn the administrator about update failures that have happened less than 72 hours since the last successful update.\n\n\nLog errors only.\n\n\n\n\nTroubleshooting\n\n\nUseful configuration and log files\n\n\nConfiguration file\n\n\n\n\n\n\n\n\nPackage\n\n\nFile Description\n\n\nLocation\n\n\nComment\n\n\n\n\n\n\n\n\n\n\nosg-ca-certs-updater\n\n\nCron entry for periodically launching the updater\n\n\n/etc/cron.d/osg-ca-certs-updater\n\n\nCommand-line arguments to the updater can be specified here\n\n\n\n\n\n\nosg-release\n\n\nRepo definition files for production OSG repositories\n\n\n/etc/yum.repos.d/osg.repo\n or \n/etc/yum.repos.d/osg-el6.repo\n\n\nMake sure these repositories are enabled and reachable from the host you are trying to update\n\n\n\n\n\n\n\n\nLog files\n\n\nLogging is performed to the console by default. Please see the manual for your \ncron\n daemon to find out how it handles console output.\n\n\nA logfile can be specified via the \n-l\n / \n--logfile\n command-line option.\n\n\nIf logging to syslog via the \n-s\n / \n--log-to-syslog\n option, the updater will write to the \nuser\n section of the syslog. The file \n/etc/syslog.conf\n determines where syslog messages are saved.\n\n\nHow to get Help?\n\n\nTo get assistance please use \nHelp Procedure\n.\n\n\nReferences\n\n\nSome guides on X.509 certificates:\n\n\n\n\nUseful commands: \nhttp://security.ncsa.illinois.edu/research/grid-howtos/usefulopenssl.html\n\n\nInstall GSI authentication on a server: \nhttp://security.ncsa.illinois.edu/research/wssec/gsihttps/\n\n\nCertificates how-to: \nhttp://www.nordugrid.org/documents/certificate_howto.html\n\n\n\n\nSome examples about verifying the certificates:\n\n\n\n\nhttp://gagravarr.org/writing/openssl-certs/others.shtml\n\n\nhttp://www.cyberciti.biz/faq/test-ssl-certificates-diagnosis-ssl-certificate/\n\n\nhttp://www.cyberciti.biz/tips/debugging-ssl-communications-from-unix-shell-prompt.html\n\n\n\n\nRelated software:\n\n\n\n\nOSG CA certificates\n\n\nDescription, manual and examples of OsgCaManage\n\n\nOsgCaCertsUpdater", 
            "title": "CA Updater"
        }, 
        {
            "location": "/common/ca_updater/#osg-ca-certificates-updater", 
            "text": "This document explains the installation and use of  osg-ca-certs-updater , a package in the OSG Software 3.x distribution that provides automatic updates of CA certificates.", 
            "title": "OSG CA Certificates Updater"
        }, 
        {
            "location": "/common/ca_updater/#requirements", 
            "text": "OS must be Red Hat Enterprise Linux 5 or 6 or variants.  The OSG repositories must be installed and enabled. See the  Yum Repositories  page for instructions.  One grid-certificates package from the OSG repositories must be installed as described  here . Currently, these are:  igtf-ca-certs ,  osg-ca-certs .", 
            "title": "Requirements"
        }, 
        {
            "location": "/common/ca_updater/#install-instructions", 
            "text": "Run the following command to install the latest version of the updater.  [root@client ~]$ yum install osg-ca-certs-updater", 
            "title": "Install instructions"
        }, 
        {
            "location": "/common/ca_updater/#services", 
            "text": "", 
            "title": "Services"
        }, 
        {
            "location": "/common/ca_updater/#starting-and-enabling-services", 
            "text": "Run the following to enable the updater. This will persist until the machine is rebooted.  [root@client ~]$ service osg-ca-certs-updater-cron start   Run the following to enable the updater when the machine is rebooted.  [root@client ~]$ chkconfig osg-ca-certs-updater-cron on   Run both commands if you wish for the service to activate immediately and remain active throughout reboots.", 
            "title": "Starting and Enabling Services"
        }, 
        {
            "location": "/common/ca_updater/#stopping-and-disabling-services", 
            "text": "Enter the following to disable the updater. This will persist until the machine is rebooted.  [root@client ~]$ service osg-ca-certs-updater-cron stop   Enter the following to disable the updater when the machine is rebooted.  [root@client ~]$ chkconfig osg-ca-certs-updater-cron off   Run both commands if you wish for the service to deactivate immediately and not get reactivated during reboots.", 
            "title": "Stopping and Disabling Services"
        }, 
        {
            "location": "/common/ca_updater/#configuration", 
            "text": "While there is no configuration file, the behavior of the updater can be adjusted by command-line arguments that are specified in the  cron  entry of the service. This entry is located in the file  /etc/cron.d/osg-ca-certs-updater . Please see the Unix manual page for  crontab  in section 5 for an explanation of the format. The manual page can be accessed by the command  man 5 crontab . The valid command-line arguments can be listed by running  osg-ca-certs-updater --help . Reasonable defaults have been provided, namely:   Attempt an update no more often than every 23 hours. Due to the random wait (see below), having a 24-hour minimum time between updates would cause the update time to slowly slide back every day.  Run the script every 6 hours. We run the script more often than we update so that downtime at the wrong moment does not cause the update to be delayed for a full day.  Delay for a random amount of time up to 30 minutes before updating, to reduce load spikes on OSG repositories.  Do not warn the administrator about update failures that have happened less than 72 hours since the last successful update.  Log errors only.", 
            "title": "Configuration"
        }, 
        {
            "location": "/common/ca_updater/#troubleshooting", 
            "text": "", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/common/ca_updater/#useful-configuration-and-log-files", 
            "text": "", 
            "title": "Useful configuration and log files"
        }, 
        {
            "location": "/common/ca_updater/#configuration-file", 
            "text": "Package  File Description  Location  Comment      osg-ca-certs-updater  Cron entry for periodically launching the updater  /etc/cron.d/osg-ca-certs-updater  Command-line arguments to the updater can be specified here    osg-release  Repo definition files for production OSG repositories  /etc/yum.repos.d/osg.repo  or  /etc/yum.repos.d/osg-el6.repo  Make sure these repositories are enabled and reachable from the host you are trying to update", 
            "title": "Configuration file"
        }, 
        {
            "location": "/common/ca_updater/#log-files", 
            "text": "Logging is performed to the console by default. Please see the manual for your  cron  daemon to find out how it handles console output.  A logfile can be specified via the  -l  /  --logfile  command-line option.  If logging to syslog via the  -s  /  --log-to-syslog  option, the updater will write to the  user  section of the syslog. The file  /etc/syslog.conf  determines where syslog messages are saved.", 
            "title": "Log files"
        }, 
        {
            "location": "/common/ca_updater/#how-to-get-help", 
            "text": "To get assistance please use  Help Procedure .", 
            "title": "How to get Help?"
        }, 
        {
            "location": "/common/ca_updater/#references", 
            "text": "Some guides on X.509 certificates:   Useful commands:  http://security.ncsa.illinois.edu/research/grid-howtos/usefulopenssl.html  Install GSI authentication on a server:  http://security.ncsa.illinois.edu/research/wssec/gsihttps/  Certificates how-to:  http://www.nordugrid.org/documents/certificate_howto.html   Some examples about verifying the certificates:   http://gagravarr.org/writing/openssl-certs/others.shtml  http://www.cyberciti.biz/faq/test-ssl-certificates-diagnosis-ssl-certificate/  http://www.cyberciti.biz/tips/debugging-ssl-communications-from-unix-shell-prompt.html   Related software:   OSG CA certificates  Description, manual and examples of OsgCaManage  OsgCaCertsUpdater", 
            "title": "References"
        }, 
        {
            "location": "/common/cert_scripts/", 
            "text": "Certificate Scripts package\n\n\n \n\n\nAbout This Document\n\n\nThis the home page for documenting the cert-scripts package that provides a command-line interface to the DOEGrids CA website and some additional utilities for dealing with X509 certificates. This package was developed originally by the PPDG project and is now maintained by the OSG RA.\n\n\nAs an alternative to the web browser interface, these scripts are contributed to the DOEGrids PKI to allow a command-line interface to the certificate authority for submitting certificate requests, retrieving signed certificates, renewing certificates, directory lookup of existing certificates, and checking the remaining lifetime of certificates and certificate revocation lists. They work directly with the PEM format files used by Globus. These are perl scripts and bash shell scripts (some awk), depend upon openssl, ldapsearch and the perl LWP:: module with \nSSL support\n. Click on the File link below for the usage description of the script, or to download the tar file package containing the scripts.\n\n\nHow to get Help?\n\n\nTo get assistance please use \nHelp Procedure\n.\n\n\nRequirements\n\n\n\n\nA host to install the Cert Scripts package. It is normally included in the CE.\n\n\nOS is \n. Currently most of our testing has been done on Scientific Linux 5.\n\n\nRoot access\n\n\nAllow outbound network connection to the CA\n\n\n\n\nInstallation Procedure \nOSGAllInstallCertScripts\n\n\nYumRepositories\n\n\nInstallCertAuth\n\n\nOSGBriefInstallCertScripts\n\n\nInstall the certificate scripts package The Cert Scripts package can be installed with the following command:\n\n\n[root@client ~]$ yum install osg-cert-scripts\n\n\n\n\n\n\nOSGBriefInstallCertScripts\n \nOSGAllInstallCertScripts\n\n\nUsage of certificate scripts package This package is mainly used to request certificates via the command line: either host and service certificates or user certificates.\n\n\nGet host and service certificates using command line\n\n\nExample usage of check-cert-time The cert-check-time script is helpful in setting up and monitoring the CA certificates and CRL\u2019s that get installed in your trusted certificates directory. This section describes using these scripts to check the CA and CRL status. \u2014+++! Checking CA certificates\n\n\nThere are numerous CA certificates installed with VDT and you may not want to allow all of them on your site. The \ncert-check-time\n is a helpful command for reviewing them. This must be run in a directory where you have write access even though it does not create any permanent files. You may want to redirect stdout to a file you can then review.\n\n\nUCL_PROMPT\n \nb\ncert-check-time -cR -s /usr/share/osg-cert-scripts/\n/b\n\n\n\n\n\n\nFor each CA, the output shows:\n\n\n\n\nremaining lifetime of the CA certificate (in days),\n\n\nthe human readable name of the CA,\n\n\nand the location of the actual certificate file.\n\n\n\n\nTWISTY_OPTS_OUTPUT\n\n\n         days  name       CA certificate file\n       6712.9 subject= /DC=HK/DC=HKU/DC=GRID/CN=HKU Grid CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/4798da47.0\n       6674.9 subject= /DC=cz/DC=cesnet-ca/O=CESNET CA/CN=CESNET CA Root  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/edca0fc0.0\n       6640.8 subject= /C=FR/O=CNRS/CN=CNRS2  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/163af95c.0\n       6639.8 subject= /C=FR/O=CNRS/CN=CNRS2-Projets  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/09ff08b7.0\n       6638.8 subject= /C=FR/O=CNRS/CN=GRID2-FR  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/d11f973e.0\n       6620.4 subject= /C=US/ST=UT/L=Salt Lake City/O=The USERTRUST Network/OU=http://www.usertrust.com/CN=UTN-USERFirst-Client Authentication and Email  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/9ec3a561.0\n       6620.4 subject= /C=NL/O=TERENA/CN=TERENA eScience Personal CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/169d7f9c.0\n       6620.4 subject= /C=GB/ST=Greater Manchester/L=Salford/O=Comodo CA Limited/CN=AAA Certificate Services  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/75680d2e.0\n       6542.2 subject= /DC=by/DC=grid/O=uiip.bas-net.by/CN=Belarusian Grid Certification Authority  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/709bed08.0\n       6274.0 subject= /C=MK/O=MARGI/CN=MARGI-CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/7d0d064a.0\n       6191.7 subject= /C=UK/O=eScienceRoot/OU=Authority/CN=UK e-Science Root  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/98ef0ee5.0\n       6165.7 subject= /C=TW/O=AS/CN=Academia Sinica Grid Computing Certification Authority Mercury  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/9cd75e87.0\n       5929.1 subject= /C=CH/O=Switch - Teleinformatikdienste fuer Lehre und Forschung/CN=SWITCHgrid Root CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/d0b701c0.0\n       5799.7 subject= /DC=ch/DC=cern/CN=CERN Root CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/d254cc30.0\n       5719.6 subject= /C=GR/O=HellasGrid/OU=Certification Authorities/CN=HellasGrid Root CA 2006  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/28a58577.0\n       5690.1 subject= /C=HR/O=edu/OU=srce/CN=SRCE CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/ff94d436.0\n       5581.6 subject= /DC=CN/DC=Grid/CN=Root Certificate Authority at CNIC  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/b2771d44.0\n       5536.3 subject= /C=CA/O=Grid/CN=Grid Canada Certificate Authority  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/bffbd7d0.0\n       5437.9 subject= /C=TR/O=TRGrid/CN=TR-Grid CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/1691b9ba.0\n       5327.0 subject= /DC=cz/DC=cesnet-ca/CN=CESNET CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/9b59ecad.0\n       5084.8 subject= /C=JP/O=AIST/OU=GRID/CN=Certificate Authority  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/a317c467.0\n       4947.1 subject= /C=PT/O=LIPCA/CN=LIP Certification Authority  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/11b4a5a2.0\n       4361.6 subject= /DC=net/DC=ES/O=ESnet/OU=Certificate Authorities/CN=ESnet Root CA 1  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/d1b603c3.0\n       3774.1 subject= /C=BM/O=QuoVadis Limited/OU=Root Certification Authority/CN=QuoVadis Root Certification Authority  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/5cf9d536.0\n       3737.4 subject= /C=NL/O=NIKHEF/CN=NIKHEF medium-security certification auth  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/16da7552.0\n       3572.8 subject= /C=PL/O=GRID/CN=Polish Grid CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/8a661490.0\n       3482.8 subject= /C=US/ST=UT/L=Salt Lake City/O=The USERTRUST Network/OU=http://www.usertrust.com/CN=UTN-USERFirst-Hardware  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/ff783690.0\n       3482.8 subject= /C=SE/O=AddTrust AB/OU=AddTrust External TTP Network/CN=AddTrust External CA Root  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/3c58f906.0\n       3482.8 subject= /C=NL/O=TERENA/CN=TERENA eScience SSL CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/20ce830e.0\n       3319.1 subject= /DC=cz/DC=cesnet-ca/O=CESNET CA/CN=CESNET CA 3  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/712ae4cc.0\n       3089.1 subject= /DC=gov/DC=fnal/O=Fermilab/OU=Certificate Authorities/CN=Kerberized CA HSM  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/99f9f5a3.0\n       3087.2 subject= /C=BM/O=QuoVadis Limited/OU=Issuing Certification Authority/CN=QuoVadis Grid ICA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/e72045ce.0\n       3039.3 subject= /DC=MD/DC=MD-Grid/O=RENAM/OU=Certification Authority/CN=MD-Grid CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/9ff26ea4.0\n       2939.0 subject= /C=BE/OU=BEGRID/O=BELNET/CN=BEgrid CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/e8d818e6.0\n       2906.9 subject= /C=DE/O=DFN-Verein/OU=DFN-PKI/CN=DFN SLCS-CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/a02131f7.0\n       2904.9 subject= /C=VE/O=Grid/O=Universidad de Los Andes/OU=CeCalCULA/CN=ULAGrid Certification Authority  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/3f0f4285.0\n       2879.6 subject= /DC=IN/DC=GARUDAINDIA/CN=Indian Grid Certification Authority  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/da75f6a8.0\n       2874.5 subject= /DC=EDU/DC=UTEXAS/DC=TACC/O=UT-AUSTIN/CN=TACC Root CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/684261aa.0\n       2850.4 subject= /DC=TW/DC=ORG/DC=NCHC/CN=NCHC CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/71a89a47.0\n       2769.2 subject= /DC=NET/DC=PRAGMA-GRID/CN=PRAGMA-UCSD CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/7721d4d3.0\n       2763.2 subject= /DC=LV/DC=latgrid/CN=Certification Authority for Latvian Grid  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/742edd45.0\n       2756.7 subject= /DC=me/DC=ac/DC=MREN/CN=MREN-CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/3232b9bc.0\n       2581.9 subject= /C=PK/O=NCP/CN=PK-GRID-CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/f5ead794.0\n       2560.4 subject= /C=MX/O=UNAMgrid/OU=UNAM/CN=CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/24c3ccde.0\n       2549.2 subject= /C=MA/O=MaGrid/CN=MaGrid CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/7b54708e.0\n       2510.1 subject= /DC=RO/DC=RomanianGRID/O=ROSA/OU=Certification Authority/CN=RomanianGRID CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/1f3834d0.0\n       2485.1 subject= /C=AR/O=e-Ciencia/OU=UNLP/L=CeSPI/CN=PKIGrid  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/b7bcb7b2.0\n       2449.6 subject= /C=KR/O=KISTI/O=GRID/CN=KISTI Grid Certificate Authority  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/722e5071.0\n       2446.1 subject= /DC=BR/DC=UFF/DC=IC/O=UFF LACGrid CA/CN=UFF Latin American and Caribbean Catch-all Grid CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/a9082267.0\n       2367.8 subject= /C=CL/O=REUNACA/CN=REUNA Certification Authority  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/295adc19.0\n       2343.9 subject= /C=RS/O=AEGIS/CN=AEGIS-CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/393f7863.0\n       2279.2 subject= /DC=bg/DC=acad/CN=BG.ACAD CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/2418a3f3.0\n       2238.5 subject= /C=TH/O=NECTEC/OU=GOC/CN=NECTEC GOC CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/8a047de1.0\n       2147.9 subject= /C=IT/O=INFN/CN=INFN CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/2f3fadf6.0\n       2147.8 subject= /DC=ch/DC=cern/CN=CERN Trusted Certification Authority  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/1d879c6c.0\n       2068.6 subject= /C=JP/O=National Research Grid Initiative/OU=CGRD/CN=NAREGI CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/a87d9192.0\n       2067.7 subject= /C=GR/O=HellasGrid/OU=Certification Authorities/CN=HellasGrid CA 2006  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/82b36fca.0\n       2064.1 subject= /C=BR/O=ICPEDU/O=UFF BrGrid CA/CN=UFF Brazilian Grid Certification Authority  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/0a2bac92.0\n       1928.6 subject= /DC=CN/DC=Grid/DC=SDG/CN=Scientific Data Grid CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/c48c63f3.0\n       1877.5 subject= /C=AU/O=APACGrid/OU=CA/CN=APACGrid/emailAddress=camanager@vpac.org  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/1e12d831.0\n       1769.8 subject= /DC=org/DC=balticgrid/CN=Baltic Grid Certification Authority  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/2a237f16.0\n       1725.0 subject= /C=RU/O=RDIG/CN=Russian Data-Intensive Grid CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/55994d72.0\n       1682.6 subject= /DC=es/DC=irisgrid/CN=IRISGridCA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/9dd23746.0\n       1649.8 subject= /C=CN/O=HEP/CN=gridca-cn/emailAddress=gridca@ihep.ac.cn  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/ba2f39ca.0\n       1575.2 subject= /C=AT/O=AustrianGrid/OU=Certification Authority/CN=Certificate Issuer  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/6e3b436b.0\n       1571.4 subject= /C=HU/O=NIIF/OU=Certificate Authorities/CN=NIIF Root CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/cc800af0.0\n       1389.9 subject= /CN=Purdue TeraGrid RA/OU=Purdue TeraGrid/O=Purdue University/ST=Indiana/C=US  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/67e8acfa.0\n       1378.2 subject= /CN=PurdueCA/O=Purdue University/ST=Indiana/C=US  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/95009ddc.0\n       1374.7 subject= /DC=ORG/DC=SEE-GRID/CN=SEE-GRID CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/468d15b3.0\n       1301.9 subject= /C=DE/O=GermanGrid/CN=GridKa-CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/dd4b34ea.0\n       1211.2 subject= /C=US/O=National Center for Supercomputing Applications/OU=Certificate Authorities/CN=GridShib CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/e8ac4b61.0\n       1141.9 subject= /C=IL/O=IUCC/CN=IUCC/emailAddress=ca@mail.iucc.ac.il  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/6fee79b0.0\n       1111.4 subject= /C=AM/O=ArmeSFo/CN=ArmeSFo CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/d0c2a341.0\n       1049.5 subject= /DC=EDU/DC=UTEXAS/DC=TACC/O=UT-AUSTIN/CN=TACC MICS CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/2ac09305.0\n       1049.5 subject= /DC=EDU/DC=UTEXAS/DC=TACC/O=UT-AUSTIN/CN=TACC Classic CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/e5cc84c2.0\n       1025.9 subject= /C=DE/O=DFN-Verein/OU=DFN-PKI/CN=DFN-Verein PCA Grid - G01  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/1149214e.0\n        943.2 subject= /DC=net/DC=ES/OU=Certificate Authorities/CN=NERSC Online CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/b93d6240.0\n        910.1 subject= /C=IR/O=IPM/O=IRAN-GRID/CN=IRAN-GRID CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/ce33db76.0\n        815.9 subject= /C=CY/O=CyGrid/O=HPCL/CN=CyGridCA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/afe55e66.0\n        800.7 subject= /DC=org/DC=DOEGrids/OU=Certificate Authorities/CN=DOEGrids CA 1  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/1c3f2ca8.0\n        795.3 subject= /DC=org/DC=ugrid/CN=UGRID CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/0a12b607.0\n        761.9 subject= /C=SK/O=SlovakGrid/CN=SlovakGrid CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/e13e0fcf.0\n        713.7 subject= /C=UK/O=eScienceCA/OU=Authority/CN=UK e-Science CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/367b75c3.0\n        619.1 subject= /C=IE/O=Grid-Ireland/CN=Grid-Ireland Certification Authority  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/1e43b9cc.0\n        523.2 subject= /C=US/O=National Center for Supercomputing Applications/OU=Certificate Authorities/CN=MyProxy  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/f2e89fe3.0\n        523.2 subject= /C=US/O=National Center for Supercomputing Applications/OU=Certificate Authorities/CN=CACL  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/9b95bbf2.0\n        450.1 subject= /C=CH/O=Switch - Teleinformatikdienste fuer Lehre und Forschung/CN=SWITCHslcs CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/304cf809.0\n        279.7 subject= /C=SI/O=SiGNET/CN=SiGNET CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/3d5be7bc.0\n        179.9 subject= /O=Grid/O=NorduGrid/CN=NorduGrid Certification Authority  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/1f0e8352.0\n        135.0 subject= /C=JP/O=KEK/OU=CRC/CN=KEK GRID Certificate Authority  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/617ff41b.0\nnearest CA certificate expiration 134.984 days\n\n\n\n\n\n\n\nIn addition, at the bottom of the listing it points out which CA\u2019s do not have a CRL. This is useful AFTER the edg-crl-upgraded daemon has run at least once because then it shows those CA\u2019s which have not published a certificate revocation list. Note that two of the CAs, Kerberos CAs from PSC (85ca9edc.0) and FNAL (e1fce4e9.0) don\u2019t really need CRLs since they only generate short lived certificates.\n\n\nChecking CRL\u2019s\n\n\nCertificate revocation lists contain the list of certificates (by serial number) that have been issued by a CA but were then revoked, meaning you should not accept them. CRL\u2019s are updated frequently and typically have a lifetime limited to a month or less. When a CRL has expired, the CRL file will still exist in the trusted certificates directory, but Globus will fail \nall\n authentication attempts for \nall\n certificates issued by the corresponding CA.\n\n\nFor this reason, and others, it is important that CRL files are current and not expired. Another variation of the cert-check-time script will list the remaining lifetime of CRL\u2019s in the trusted certificates directory. This must be run in a directory where you have write access even though it does not create any files. You may want to redirect stdout to a file you can then review.\n\n\nUCL_PROMPT\n \nb\ncert-check-time -r -s /usr/share/osg-cert-scripts/ \n/b\n\n\n\n\n\n\nFor each CRL, the sample output below shows:\n\n\n\n\nthe remaining lifetime,\n\n\nthe name of the CA that issued the CRL\n\n\nand the actual CRL file.\n\n\n\n\nTWISTY_OPTS_OUTPUT\n\n\n         days  name       CRL file\n        365.1 issuer=/C=CA/O=Grid/CN=Grid Canada CA  crl:/opt/osg036/globus/TRUSTED_CA/5f54f417.r0\n        340.8 issuer=/CN=SWITCH CA/emailAddress=switch.ca@switch.ch/O=Switch - Teleinformatikdienste fuer Lehre und Forschung/C=CH  crl:/opt/osg036/globus/TRUSTED_CA/c4435d12.r0\n        317.1 issuer=/C=FR/O=CNRS/CN=CNRS-Projets  crl:/opt/osg036/globus/TRUSTED_CA/34a509c3.r0\n        317.1 issuer=/C=FR/O=CNRS/CN=CNRS  crl:/opt/osg036/globus/TRUSTED_CA/cf4ba8c8.r0\n        257.1 issuer=/CN=SwissSign Silver CA/emailAddress=silver@swisssign.com/O=SwissSign/C=CH  crl:/opt/osg036/globus/TRUSTED_CA/e9d08b40.r0\n        257.1 issuer=/CN=SwissSign Bronze CA/emailAddress=bronze@swisssign.com/O=SwissSign/C=CH  crl:/opt/osg036/globus/TRUSTED_CA/e36e7a72.r0\n        204.4 issuer=/DC=net/DC=ES/O=ESnet/OU=Certificate Authorities/CN=ESnet Root CA 1  crl:/opt/osg036/globus/TRUSTED_CA/d1b603c3.r0\n        149.4 issuer=/C=CH/O=SwissSign/CN=SwissSign CA (RSA IK May 6 1999 18:00:58)/emailAddress=ca@SwissSign.com  crl:/opt/osg036/globus/TRUSTED_CA/7b2d086c.r0\n         31.0 issuer=/C=RU/O=RDIG/CN=Russian Data-Intensive Grid CA  crl:/opt/osg036/globus/TRUSTED_CA/55994d72.r0\n         30.0 issuer=/C=DE/O=DFN-Verein/OU=DFN-PKI/CN=DFN-Verein Server CA Grid - G01  crl:/opt/osg036/globus/TRUSTED_CA/fe102e03.r0\n         30.0 issuer=/C=DE/O=DFN-Verein/OU=DFN-PKI/CN=DFN-Verein User CA Grid - G01  crl:/opt/osg036/globus/TRUSTED_CA/34f8e29c.r0\n         29.9 issuer=/C=IT/O=INFN/CN=INFN Certification Authority  crl:/opt/osg036/globus/TRUSTED_CA/49f18420.r0\n         29.9 issuer=/C=CY/O=CyGrid/O=HPCL/CN=CyGridCA  crl:/opt/osg036/globus/TRUSTED_CA/afe55e66.r0\n         29.9 issuer=/C=IE/O=Grid-Ireland/CN=Grid-Ireland Certification Authority  crl:/opt/osg036/globus/TRUSTED_CA/1e43b9cc.r0\n         29.7 issuer=/DC=es/DC=irisgrid/CN=IRISGridCA  crl:/opt/osg036/globus/TRUSTED_CA/9dd23746.r0\n         29.7 issuer=/C=IL/O=IUCC/CN=IUCC/emailAddress=ca@mail.iucc.ac.il  crl:/opt/osg036/globus/TRUSTED_CA/6fee79b0.r0\n         29.6 issuer=/DC=org/DC=DOEGrids/OU=Certificate Authorities/CN=DOEGrids CA 1  crl:/opt/osg036/globus/TRUSTED_CA/1c3f2ca8.r0\n         29.5 issuer=/C=TW/O=AS/CN=Academia Sinica Grid Computing Certification Authority  crl:/opt/osg036/globus/TRUSTED_CA/a692434d.r0\n         29.3 issuer=/C=FR/O=CNRS/CN=GRID-FR  crl:/opt/osg036/globus/TRUSTED_CA/12a1d8c2.r0\n         29.1 issuer=/C=DE/O=GermanGrid/CN=GridKa-CA  crl:/opt/osg036/globus/TRUSTED_CA/dd4b34ea.r0\n         28.8 issuer=/C=JP/O=National Research Grid Initiative/OU=GRID/CN=NAREGI CA  crl:/opt/osg036/globus/TRUSTED_CA/0cb5fc2c.r0\n         28.3 issuer=/C=AU/O=APACGrid/OU=CA/CN=APACGrid/emailAddress=camanager@vpac.org  crl:/opt/osg036/globus/TRUSTED_CA/1e12d831.r0\n         27.9 issuer=/DC=ORG/DC=SEE-GRID/CN=SEE-GRID CA  crl:/opt/osg036/globus/TRUSTED_CA/468d15b3.r0\n         27.9 issuer=/C=GR/O=HellasGrid/CN=HellasGrid CA  crl:/opt/osg036/globus/TRUSTED_CA/ede78092.r0\n         27.1 issuer=/C=NL/O=NIKHEF/CN=NIKHEF medium-security certification auth  crl:/opt/osg036/globus/TRUSTED_CA/16da7552.r0\n         27.0 issuer=/C=PL/O=GRID/CN=Polish Grid CA  crl:/opt/osg036/globus/TRUSTED_CA/8a661490.r0\n         26.8 issuer=/O=Grid/O=NorduGrid/CN=NorduGrid Certification Authority  crl:/opt/osg036/globus/TRUSTED_CA/1f0e8352.r0\n         25.9 issuer=/C=AM/O=ArmeSFo/CN=ArmeSFo CA  crl:/opt/osg036/globus/TRUSTED_CA/d0c2a341.r0\n         25.9 issuer=/C=BE/O=BELNET/OU=BEGrid/CN=BEGrid CA/emailAddress=gridca@belnet.be  crl:/opt/osg036/globus/TRUSTED_CA/03aa0ecb.r0\n         24.0 issuer=/C=UK/O=eScience/OU=Authority/CN=CA/emailAddress=ca-operator@grid-support.ac.uk  crl:/opt/osg036/globus/TRUSTED_CA/01621954.r0\n         23.9 issuer=/C=HU/O=KFKI RMKI CA/CN=KFKI RMKI CA  crl:/opt/osg036/globus/TRUSTED_CA/5e5501f3.r0\n         23.9 issuer=/C=SK/O=SlovakGrid/CN=SlovakGrid CA  crl:/opt/osg036/globus/TRUSTED_CA/e13e0fcf.r0\n         23.1 issuer=/C=PT/O=LIPCA/CN=LIP Certification Authority  crl:/opt/osg036/globus/TRUSTED_CA/11b4a5a2.r0\n         23.0 issuer=/C=PT/O=LIP/OU=LISCC/CN=LIP Certification Authority  crl:/opt/osg036/globus/TRUSTED_CA/41380387.r0\n         23.0 issuer=/C=AT/O=AustrianGrid/OU=Certification Authority/CN=Certificate Issuer  crl:/opt/osg036/globus/TRUSTED_CA/6e3b436b.r0\n         22.9 issuer=/C=CZ/O=CESNET/CN=CESNET CA  crl:/opt/osg036/globus/TRUSTED_CA/ed99a497.r0\n         21.9 issuer=/C=KR/O=KISTI/CN=KISTI GRID ROOT CA  crl:/opt/osg036/globus/TRUSTED_CA/47183fda.r0\n         21.7 issuer=/C=CN/O=HEP/CN=gridca-cn/emailAddress=gridca@ihep.ac.cn  crl:/opt/osg036/globus/TRUSTED_CA/ba2f39ca.r0\n         21.1 issuer=/C=CH/O=CERN/OU=GRID/CN=CERN CA  crl:/opt/osg036/globus/TRUSTED_CA/fa3af1d7.r0\n         19.1 issuer=/C=SI/O=SiGNET/CN=SiGNET CA/emailAddress=signet-ca@ijs.si  crl:/opt/osg036/globus/TRUSTED_CA/747183a5.r0\n         16.0 issuer=/DC=org/DC=balticgrid/CN=Baltic Grid Certification Authority  crl:/opt/osg036/globus/TRUSTED_CA/2a237f16.r0\n         15.9 issuer=/C=EE/O=Grid/CN=Estonian Grid Certification Authority  crl:/opt/osg036/globus/TRUSTED_CA/566bf40f.r0\n         12.9 issuer=/C=PK/O=NCP/CN=ncp.edu.pk  crl:/opt/osg036/globus/TRUSTED_CA/d2a353a5.r0\n         11.3 issuer=/C=US/ST=California/L=Los Angeles/O=University of Southern California/CN=University of Southern California PKI-Lite CA, release 1/emailAddress=nmiadmin@usc.edu  crl:/opt/osg036/globus/TRUSTED_CA/2ca73e82.r0\n         10.8 issuer=/C=RU/O=DataGrid/CN=Russian DataGrid CA  crl:/opt/osg036/globus/TRUSTED_CA/d64ccb53.r0\n          9.7 issuer=/C=TR/O=TRGrid/CN=TR-Grid CA  crl:/opt/osg036/globus/TRUSTED_CA/1691b9ba.r0\n          9.3 issuer=/C=US/O=Pittsburgh Supercomputing Center/CN=PSC Root Certificate Authority  crl:/opt/osg036/globus/TRUSTED_CA/aa99c057.r0\n          9.2 issuer=/C=ES/O=DATAGRID-ES/CN=DATAGRID-ES CA  crl:/opt/osg036/globus/TRUSTED_CA/13eab55e.r0\n          8.0 issuer=/C=DE/O=DFN-Verein/OU=DFN-PKI/CN=DFN-Verein PCA Grid - G01  crl:/opt/osg036/globus/TRUSTED_CA/1149214e.r0\n          7.7 issuer=/C=JP/O=AIST/OU=GRID/CN=Certificate Authority  crl:/opt/osg036/globus/TRUSTED_CA/a317c467.r0\n          7.2 issuer=/DC=cz/DC=cesnet-ca/CN=CESNET CA  crl:/opt/osg036/globus/TRUSTED_CA/9b59ecad.r0\n ***      6.8 issuer=/C=US/O=SDSC/OU=SDSC-CA/CN=Certificate Authority/UID=certman  crl:/opt/osg036/globus/TRUSTED_CA/3deda549.r0\n ***      6.2 issuer=/C=CA/O=Grid/CN=Grid Canada Certificate Authority  crl:/opt/osg036/globus/TRUSTED_CA/bffbd7d0.r0\n ***      4.4 issuer=/C=HU/O=NIIF/OU=Certificate Authorities/CN=NIIF Root CA  crl:/opt/osg036/globus/TRUSTED_CA/cc800af0.r0\n ***      4.2 issuer=/C=US/O=UTAustin/OU=TACC/CN=TACC Certification Authority/UID=caman  crl:/opt/osg036/globus/TRUSTED_CA/9a1da9f9.r0\n ***      1.1 issuer=/CN=PurdueCA/O=Purdue University/ST=Indiana/C=US  crl:/opt/osg036/globus/TRUSTED_CA/95009ddc.r0\n ***      1.0 issuer=/C=CH/O=SWITCH - Teleinformatikdienste fuer Lehre und Forschung/CN=SWITCH Server CA/emailAddress=switch.server.ca@switch.ch  crl:/opt/osg036/globus/TRUSTED_CA/072fe468.r0\n ***      1.0 issuer=/C=CH/O=SWITCH - Teleinformatikdienste fuer Lehre und Forschung/CN=SWITCH Personal CA/emailAddress=switch.personal.ca@switch.ch  crl:/opt/osg036/globus/TRUSTED_CA/4aa5ef7d.r0\n ***      1.0 issuer=/CN=SWITCH Personal CA/emailAddress=switch.personal.ca@switch.ch/O=SWITCH - Teleinformatikdienste fuer Lehre und Forschung/C=CH  crl:/opt/osg036/globus/TRUSTED_CA/7c0f6d74.r0\n ***      1.0 issuer=/CN=SWITCH Server CA/emailAddress=switch.server.ca@switch.ch/O=SWITCH - Teleinformatikdienste fuer Lehre und Forschung/C=CH  crl:/opt/osg036/globus/TRUSTED_CA/f8b4299c.r0\n ***      1.0 issuer=/CN=Purdue TeraGrid RA/OU=Purdue TeraGrid/O=Purdue University/ST=Indiana/C=US  crl:/opt/osg036/globus/TRUSTED_CA/67e8acfa.r0\nnearest CRL expiration 0.951088 days\n\n\n\n\n\n\n\nSite administrators may find it useful to run this command in a daily cron job following the edg-crl-upgraded daemon as a way to monitor the status of the CRL\u2019s.\n\n\nReferences\n\n\nFor additional information on the functionality of a script execute it with the -help option.\n\n\nFiles in the package:\n\n\n\n\n\n\n\n\nFile\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nREADME\n\n\ndescribes the package, includes release notes\n\n\n\n\n\n\ncert-check-time\n\n\nchecks lifetime of certificates and revocation lists\n\n\n\n\n\n\ncert-gridadmin\n\n\nimmediate issuance of service certificates for authorized requestors\n\n\n\n\n\n\ncert-lookup\n\n\nqueries directory based on DN of certificates\n\n\n\n\n\n\ncert-request\n\n\ngenerates and submits a certificate signing request\n\n\n\n\n\n\ncert-retrieve\n\n\nretrieves signed certificate previously requested\n\n\n\n\n\n\ncert-renew\n\n\nrenews existing person certificate (not host or service)\n\n\n\n\n\n\nmulti-cert-gridadmin\n\n\nimmediate issuance of multiple service certificates for authorized administrators (new with V2-3)\n\n\n\n\n\n\nInstallationNotes.txt\n\n\nextra installation requirements for multi-cert-gridadmin (new with V2-3)\n\n\n\n\n\n\n\n\nFAQ\n\n\nHow to perform common tasks. In \nred\n the items you have to change.\n\n\nRequest a certificate for myself (personal certificate)\n\n\nUCL_PROMPT\n cert-request -ou p\n\n\n\n\n\n\nFull details in the \ncommand line document\n or in the \nWeb interface document\n (for a browser based alt.).\n\n\nRequest a certificate for my computer (host certificate)\n\n\nUCL_PROMPT\n cert-request -ou s\n\n\n\n\n\n\nFull details in the \nhost and service certificates document\n.\n\n\nRequest a certificate for the http service on my computer (service certificate)\n\n\nUCL_PROMPT\n cert-request -ou s -service http -host \nmy-computer.some.domain\n -label \nhttp-my-computer\n\n\n\n\n\n\nFull details in the \nhost and service certificates document\n.\n\n\nRetrieve a certificate\n\n\n\n\nCheck the email notice you got when the certificate was granted for the serial number (\n0xNNNN\n)\n\n\n\n\nUCL_PROMPT\n cert-retrieve -serial \n0xNNNN\n [-label \nlabel-matching-cert-request\n]\n\n\n\n\n\n\nUse the \n-p12\n option to create the PKCS12 format file useful for importing your certificate into a web browser or email program.\n\n\nIf you need to get lots of service certificates\n\n\n\n\nAsk your RA to grant you the \ngridadmin\n privilege. 2. Use \ncert-gridadmin\n and you can get service certificates issued immediately without using the web interface.\n\n\n\n\nMy personal certificate is about to expire, how do I get another with the same DN?\n\n\n\n\nUse \ncert-renew\n\n\n\n\nFull details in the \ncommand line document\n or in the \nWeb interface document\n (for a browser based alt.).", 
            "title": "Certificate Request Scripts"
        }, 
        {
            "location": "/common/cert_scripts/#certificate-scripts-package", 
            "text": "", 
            "title": "Certificate Scripts package"
        }, 
        {
            "location": "/common/cert_scripts/#about-this-document", 
            "text": "This the home page for documenting the cert-scripts package that provides a command-line interface to the DOEGrids CA website and some additional utilities for dealing with X509 certificates. This package was developed originally by the PPDG project and is now maintained by the OSG RA.  As an alternative to the web browser interface, these scripts are contributed to the DOEGrids PKI to allow a command-line interface to the certificate authority for submitting certificate requests, retrieving signed certificates, renewing certificates, directory lookup of existing certificates, and checking the remaining lifetime of certificates and certificate revocation lists. They work directly with the PEM format files used by Globus. These are perl scripts and bash shell scripts (some awk), depend upon openssl, ldapsearch and the perl LWP:: module with  SSL support . Click on the File link below for the usage description of the script, or to download the tar file package containing the scripts.", 
            "title": "About This Document"
        }, 
        {
            "location": "/common/cert_scripts/#how-to-get-help", 
            "text": "To get assistance please use  Help Procedure .", 
            "title": "How to get Help?"
        }, 
        {
            "location": "/common/cert_scripts/#requirements", 
            "text": "A host to install the Cert Scripts package. It is normally included in the CE.  OS is  . Currently most of our testing has been done on Scientific Linux 5.  Root access  Allow outbound network connection to the CA", 
            "title": "Requirements"
        }, 
        {
            "location": "/common/cert_scripts/#installation-procedure-osgallinstallcertscripts", 
            "text": "YumRepositories  InstallCertAuth  OSGBriefInstallCertScripts", 
            "title": "Installation Procedure OSGAllInstallCertScripts"
        }, 
        {
            "location": "/common/cert_scripts/#install-the-certificate-scripts-package-the-cert-scripts-package-can-be-installed-with-the-following-command", 
            "text": "[root@client ~]$ yum install osg-cert-scripts   OSGBriefInstallCertScripts   OSGAllInstallCertScripts", 
            "title": "Install the certificate scripts package The Cert Scripts package can be installed with the following command:"
        }, 
        {
            "location": "/common/cert_scripts/#usage-of-certificate-scripts-package-this-package-is-mainly-used-to-request-certificates-via-the-command-line-either-host-and-service-certificates-or-user-certificates", 
            "text": "", 
            "title": "Usage of certificate scripts package This package is mainly used to request certificates via the command line: either host and service certificates or user certificates."
        }, 
        {
            "location": "/common/cert_scripts/#get-host-and-service-certificates-using-command-line", 
            "text": "", 
            "title": "Get host and service certificates using command line"
        }, 
        {
            "location": "/common/cert_scripts/#example-usage-of-check-cert-time-the-cert-check-time-script-is-helpful-in-setting-up-and-monitoring-the-ca-certificates-and-crls-that-get-installed-in-your-trusted-certificates-directory-this-section-describes-using-these-scripts-to-check-the-ca-and-crl-status-checking-ca-certificates", 
            "text": "There are numerous CA certificates installed with VDT and you may not want to allow all of them on your site. The  cert-check-time  is a helpful command for reviewing them. This must be run in a directory where you have write access even though it does not create any permanent files. You may want to redirect stdout to a file you can then review.  UCL_PROMPT   b cert-check-time -cR -s /usr/share/osg-cert-scripts/ /b   For each CA, the output shows:   remaining lifetime of the CA certificate (in days),  the human readable name of the CA,  and the location of the actual certificate file.   TWISTY_OPTS_OUTPUT           days  name       CA certificate file\n       6712.9 subject= /DC=HK/DC=HKU/DC=GRID/CN=HKU Grid CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/4798da47.0\n       6674.9 subject= /DC=cz/DC=cesnet-ca/O=CESNET CA/CN=CESNET CA Root  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/edca0fc0.0\n       6640.8 subject= /C=FR/O=CNRS/CN=CNRS2  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/163af95c.0\n       6639.8 subject= /C=FR/O=CNRS/CN=CNRS2-Projets  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/09ff08b7.0\n       6638.8 subject= /C=FR/O=CNRS/CN=GRID2-FR  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/d11f973e.0\n       6620.4 subject= /C=US/ST=UT/L=Salt Lake City/O=The USERTRUST Network/OU=http://www.usertrust.com/CN=UTN-USERFirst-Client Authentication and Email  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/9ec3a561.0\n       6620.4 subject= /C=NL/O=TERENA/CN=TERENA eScience Personal CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/169d7f9c.0\n       6620.4 subject= /C=GB/ST=Greater Manchester/L=Salford/O=Comodo CA Limited/CN=AAA Certificate Services  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/75680d2e.0\n       6542.2 subject= /DC=by/DC=grid/O=uiip.bas-net.by/CN=Belarusian Grid Certification Authority  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/709bed08.0\n       6274.0 subject= /C=MK/O=MARGI/CN=MARGI-CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/7d0d064a.0\n       6191.7 subject= /C=UK/O=eScienceRoot/OU=Authority/CN=UK e-Science Root  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/98ef0ee5.0\n       6165.7 subject= /C=TW/O=AS/CN=Academia Sinica Grid Computing Certification Authority Mercury  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/9cd75e87.0\n       5929.1 subject= /C=CH/O=Switch - Teleinformatikdienste fuer Lehre und Forschung/CN=SWITCHgrid Root CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/d0b701c0.0\n       5799.7 subject= /DC=ch/DC=cern/CN=CERN Root CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/d254cc30.0\n       5719.6 subject= /C=GR/O=HellasGrid/OU=Certification Authorities/CN=HellasGrid Root CA 2006  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/28a58577.0\n       5690.1 subject= /C=HR/O=edu/OU=srce/CN=SRCE CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/ff94d436.0\n       5581.6 subject= /DC=CN/DC=Grid/CN=Root Certificate Authority at CNIC  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/b2771d44.0\n       5536.3 subject= /C=CA/O=Grid/CN=Grid Canada Certificate Authority  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/bffbd7d0.0\n       5437.9 subject= /C=TR/O=TRGrid/CN=TR-Grid CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/1691b9ba.0\n       5327.0 subject= /DC=cz/DC=cesnet-ca/CN=CESNET CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/9b59ecad.0\n       5084.8 subject= /C=JP/O=AIST/OU=GRID/CN=Certificate Authority  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/a317c467.0\n       4947.1 subject= /C=PT/O=LIPCA/CN=LIP Certification Authority  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/11b4a5a2.0\n       4361.6 subject= /DC=net/DC=ES/O=ESnet/OU=Certificate Authorities/CN=ESnet Root CA 1  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/d1b603c3.0\n       3774.1 subject= /C=BM/O=QuoVadis Limited/OU=Root Certification Authority/CN=QuoVadis Root Certification Authority  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/5cf9d536.0\n       3737.4 subject= /C=NL/O=NIKHEF/CN=NIKHEF medium-security certification auth  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/16da7552.0\n       3572.8 subject= /C=PL/O=GRID/CN=Polish Grid CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/8a661490.0\n       3482.8 subject= /C=US/ST=UT/L=Salt Lake City/O=The USERTRUST Network/OU=http://www.usertrust.com/CN=UTN-USERFirst-Hardware  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/ff783690.0\n       3482.8 subject= /C=SE/O=AddTrust AB/OU=AddTrust External TTP Network/CN=AddTrust External CA Root  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/3c58f906.0\n       3482.8 subject= /C=NL/O=TERENA/CN=TERENA eScience SSL CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/20ce830e.0\n       3319.1 subject= /DC=cz/DC=cesnet-ca/O=CESNET CA/CN=CESNET CA 3  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/712ae4cc.0\n       3089.1 subject= /DC=gov/DC=fnal/O=Fermilab/OU=Certificate Authorities/CN=Kerberized CA HSM  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/99f9f5a3.0\n       3087.2 subject= /C=BM/O=QuoVadis Limited/OU=Issuing Certification Authority/CN=QuoVadis Grid ICA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/e72045ce.0\n       3039.3 subject= /DC=MD/DC=MD-Grid/O=RENAM/OU=Certification Authority/CN=MD-Grid CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/9ff26ea4.0\n       2939.0 subject= /C=BE/OU=BEGRID/O=BELNET/CN=BEgrid CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/e8d818e6.0\n       2906.9 subject= /C=DE/O=DFN-Verein/OU=DFN-PKI/CN=DFN SLCS-CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/a02131f7.0\n       2904.9 subject= /C=VE/O=Grid/O=Universidad de Los Andes/OU=CeCalCULA/CN=ULAGrid Certification Authority  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/3f0f4285.0\n       2879.6 subject= /DC=IN/DC=GARUDAINDIA/CN=Indian Grid Certification Authority  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/da75f6a8.0\n       2874.5 subject= /DC=EDU/DC=UTEXAS/DC=TACC/O=UT-AUSTIN/CN=TACC Root CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/684261aa.0\n       2850.4 subject= /DC=TW/DC=ORG/DC=NCHC/CN=NCHC CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/71a89a47.0\n       2769.2 subject= /DC=NET/DC=PRAGMA-GRID/CN=PRAGMA-UCSD CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/7721d4d3.0\n       2763.2 subject= /DC=LV/DC=latgrid/CN=Certification Authority for Latvian Grid  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/742edd45.0\n       2756.7 subject= /DC=me/DC=ac/DC=MREN/CN=MREN-CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/3232b9bc.0\n       2581.9 subject= /C=PK/O=NCP/CN=PK-GRID-CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/f5ead794.0\n       2560.4 subject= /C=MX/O=UNAMgrid/OU=UNAM/CN=CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/24c3ccde.0\n       2549.2 subject= /C=MA/O=MaGrid/CN=MaGrid CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/7b54708e.0\n       2510.1 subject= /DC=RO/DC=RomanianGRID/O=ROSA/OU=Certification Authority/CN=RomanianGRID CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/1f3834d0.0\n       2485.1 subject= /C=AR/O=e-Ciencia/OU=UNLP/L=CeSPI/CN=PKIGrid  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/b7bcb7b2.0\n       2449.6 subject= /C=KR/O=KISTI/O=GRID/CN=KISTI Grid Certificate Authority  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/722e5071.0\n       2446.1 subject= /DC=BR/DC=UFF/DC=IC/O=UFF LACGrid CA/CN=UFF Latin American and Caribbean Catch-all Grid CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/a9082267.0\n       2367.8 subject= /C=CL/O=REUNACA/CN=REUNA Certification Authority  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/295adc19.0\n       2343.9 subject= /C=RS/O=AEGIS/CN=AEGIS-CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/393f7863.0\n       2279.2 subject= /DC=bg/DC=acad/CN=BG.ACAD CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/2418a3f3.0\n       2238.5 subject= /C=TH/O=NECTEC/OU=GOC/CN=NECTEC GOC CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/8a047de1.0\n       2147.9 subject= /C=IT/O=INFN/CN=INFN CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/2f3fadf6.0\n       2147.8 subject= /DC=ch/DC=cern/CN=CERN Trusted Certification Authority  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/1d879c6c.0\n       2068.6 subject= /C=JP/O=National Research Grid Initiative/OU=CGRD/CN=NAREGI CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/a87d9192.0\n       2067.7 subject= /C=GR/O=HellasGrid/OU=Certification Authorities/CN=HellasGrid CA 2006  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/82b36fca.0\n       2064.1 subject= /C=BR/O=ICPEDU/O=UFF BrGrid CA/CN=UFF Brazilian Grid Certification Authority  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/0a2bac92.0\n       1928.6 subject= /DC=CN/DC=Grid/DC=SDG/CN=Scientific Data Grid CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/c48c63f3.0\n       1877.5 subject= /C=AU/O=APACGrid/OU=CA/CN=APACGrid/emailAddress=camanager@vpac.org  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/1e12d831.0\n       1769.8 subject= /DC=org/DC=balticgrid/CN=Baltic Grid Certification Authority  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/2a237f16.0\n       1725.0 subject= /C=RU/O=RDIG/CN=Russian Data-Intensive Grid CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/55994d72.0\n       1682.6 subject= /DC=es/DC=irisgrid/CN=IRISGridCA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/9dd23746.0\n       1649.8 subject= /C=CN/O=HEP/CN=gridca-cn/emailAddress=gridca@ihep.ac.cn  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/ba2f39ca.0\n       1575.2 subject= /C=AT/O=AustrianGrid/OU=Certification Authority/CN=Certificate Issuer  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/6e3b436b.0\n       1571.4 subject= /C=HU/O=NIIF/OU=Certificate Authorities/CN=NIIF Root CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/cc800af0.0\n       1389.9 subject= /CN=Purdue TeraGrid RA/OU=Purdue TeraGrid/O=Purdue University/ST=Indiana/C=US  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/67e8acfa.0\n       1378.2 subject= /CN=PurdueCA/O=Purdue University/ST=Indiana/C=US  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/95009ddc.0\n       1374.7 subject= /DC=ORG/DC=SEE-GRID/CN=SEE-GRID CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/468d15b3.0\n       1301.9 subject= /C=DE/O=GermanGrid/CN=GridKa-CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/dd4b34ea.0\n       1211.2 subject= /C=US/O=National Center for Supercomputing Applications/OU=Certificate Authorities/CN=GridShib CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/e8ac4b61.0\n       1141.9 subject= /C=IL/O=IUCC/CN=IUCC/emailAddress=ca@mail.iucc.ac.il  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/6fee79b0.0\n       1111.4 subject= /C=AM/O=ArmeSFo/CN=ArmeSFo CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/d0c2a341.0\n       1049.5 subject= /DC=EDU/DC=UTEXAS/DC=TACC/O=UT-AUSTIN/CN=TACC MICS CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/2ac09305.0\n       1049.5 subject= /DC=EDU/DC=UTEXAS/DC=TACC/O=UT-AUSTIN/CN=TACC Classic CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/e5cc84c2.0\n       1025.9 subject= /C=DE/O=DFN-Verein/OU=DFN-PKI/CN=DFN-Verein PCA Grid - G01  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/1149214e.0\n        943.2 subject= /DC=net/DC=ES/OU=Certificate Authorities/CN=NERSC Online CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/b93d6240.0\n        910.1 subject= /C=IR/O=IPM/O=IRAN-GRID/CN=IRAN-GRID CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/ce33db76.0\n        815.9 subject= /C=CY/O=CyGrid/O=HPCL/CN=CyGridCA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/afe55e66.0\n        800.7 subject= /DC=org/DC=DOEGrids/OU=Certificate Authorities/CN=DOEGrids CA 1  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/1c3f2ca8.0\n        795.3 subject= /DC=org/DC=ugrid/CN=UGRID CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/0a12b607.0\n        761.9 subject= /C=SK/O=SlovakGrid/CN=SlovakGrid CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/e13e0fcf.0\n        713.7 subject= /C=UK/O=eScienceCA/OU=Authority/CN=UK e-Science CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/367b75c3.0\n        619.1 subject= /C=IE/O=Grid-Ireland/CN=Grid-Ireland Certification Authority  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/1e43b9cc.0\n        523.2 subject= /C=US/O=National Center for Supercomputing Applications/OU=Certificate Authorities/CN=MyProxy  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/f2e89fe3.0\n        523.2 subject= /C=US/O=National Center for Supercomputing Applications/OU=Certificate Authorities/CN=CACL  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/9b95bbf2.0\n        450.1 subject= /C=CH/O=Switch - Teleinformatikdienste fuer Lehre und Forschung/CN=SWITCHslcs CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/304cf809.0\n        279.7 subject= /C=SI/O=SiGNET/CN=SiGNET CA  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/3d5be7bc.0\n        179.9 subject= /O=Grid/O=NorduGrid/CN=NorduGrid Certification Authority  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/1f0e8352.0\n        135.0 subject= /C=JP/O=KEK/OU=CRC/CN=KEK GRID Certificate Authority  cert:/ncsa/apps-local/itb-1.2/globus/TRUSTED_CA/617ff41b.0\nnearest CA certificate expiration 134.984 days   In addition, at the bottom of the listing it points out which CA\u2019s do not have a CRL. This is useful AFTER the edg-crl-upgraded daemon has run at least once because then it shows those CA\u2019s which have not published a certificate revocation list. Note that two of the CAs, Kerberos CAs from PSC (85ca9edc.0) and FNAL (e1fce4e9.0) don\u2019t really need CRLs since they only generate short lived certificates.", 
            "title": "Example usage of check-cert-time The cert-check-time script is helpful in setting up and monitoring the CA certificates and CRL\u2019s that get installed in your trusted certificates directory. This section describes using these scripts to check the CA and CRL status. \u2014+++! Checking CA certificates"
        }, 
        {
            "location": "/common/cert_scripts/#checking-crls", 
            "text": "Certificate revocation lists contain the list of certificates (by serial number) that have been issued by a CA but were then revoked, meaning you should not accept them. CRL\u2019s are updated frequently and typically have a lifetime limited to a month or less. When a CRL has expired, the CRL file will still exist in the trusted certificates directory, but Globus will fail  all  authentication attempts for  all  certificates issued by the corresponding CA.  For this reason, and others, it is important that CRL files are current and not expired. Another variation of the cert-check-time script will list the remaining lifetime of CRL\u2019s in the trusted certificates directory. This must be run in a directory where you have write access even though it does not create any files. You may want to redirect stdout to a file you can then review.  UCL_PROMPT   b cert-check-time -r -s /usr/share/osg-cert-scripts/  /b   For each CRL, the sample output below shows:   the remaining lifetime,  the name of the CA that issued the CRL  and the actual CRL file.   TWISTY_OPTS_OUTPUT           days  name       CRL file\n        365.1 issuer=/C=CA/O=Grid/CN=Grid Canada CA  crl:/opt/osg036/globus/TRUSTED_CA/5f54f417.r0\n        340.8 issuer=/CN=SWITCH CA/emailAddress=switch.ca@switch.ch/O=Switch - Teleinformatikdienste fuer Lehre und Forschung/C=CH  crl:/opt/osg036/globus/TRUSTED_CA/c4435d12.r0\n        317.1 issuer=/C=FR/O=CNRS/CN=CNRS-Projets  crl:/opt/osg036/globus/TRUSTED_CA/34a509c3.r0\n        317.1 issuer=/C=FR/O=CNRS/CN=CNRS  crl:/opt/osg036/globus/TRUSTED_CA/cf4ba8c8.r0\n        257.1 issuer=/CN=SwissSign Silver CA/emailAddress=silver@swisssign.com/O=SwissSign/C=CH  crl:/opt/osg036/globus/TRUSTED_CA/e9d08b40.r0\n        257.1 issuer=/CN=SwissSign Bronze CA/emailAddress=bronze@swisssign.com/O=SwissSign/C=CH  crl:/opt/osg036/globus/TRUSTED_CA/e36e7a72.r0\n        204.4 issuer=/DC=net/DC=ES/O=ESnet/OU=Certificate Authorities/CN=ESnet Root CA 1  crl:/opt/osg036/globus/TRUSTED_CA/d1b603c3.r0\n        149.4 issuer=/C=CH/O=SwissSign/CN=SwissSign CA (RSA IK May 6 1999 18:00:58)/emailAddress=ca@SwissSign.com  crl:/opt/osg036/globus/TRUSTED_CA/7b2d086c.r0\n         31.0 issuer=/C=RU/O=RDIG/CN=Russian Data-Intensive Grid CA  crl:/opt/osg036/globus/TRUSTED_CA/55994d72.r0\n         30.0 issuer=/C=DE/O=DFN-Verein/OU=DFN-PKI/CN=DFN-Verein Server CA Grid - G01  crl:/opt/osg036/globus/TRUSTED_CA/fe102e03.r0\n         30.0 issuer=/C=DE/O=DFN-Verein/OU=DFN-PKI/CN=DFN-Verein User CA Grid - G01  crl:/opt/osg036/globus/TRUSTED_CA/34f8e29c.r0\n         29.9 issuer=/C=IT/O=INFN/CN=INFN Certification Authority  crl:/opt/osg036/globus/TRUSTED_CA/49f18420.r0\n         29.9 issuer=/C=CY/O=CyGrid/O=HPCL/CN=CyGridCA  crl:/opt/osg036/globus/TRUSTED_CA/afe55e66.r0\n         29.9 issuer=/C=IE/O=Grid-Ireland/CN=Grid-Ireland Certification Authority  crl:/opt/osg036/globus/TRUSTED_CA/1e43b9cc.r0\n         29.7 issuer=/DC=es/DC=irisgrid/CN=IRISGridCA  crl:/opt/osg036/globus/TRUSTED_CA/9dd23746.r0\n         29.7 issuer=/C=IL/O=IUCC/CN=IUCC/emailAddress=ca@mail.iucc.ac.il  crl:/opt/osg036/globus/TRUSTED_CA/6fee79b0.r0\n         29.6 issuer=/DC=org/DC=DOEGrids/OU=Certificate Authorities/CN=DOEGrids CA 1  crl:/opt/osg036/globus/TRUSTED_CA/1c3f2ca8.r0\n         29.5 issuer=/C=TW/O=AS/CN=Academia Sinica Grid Computing Certification Authority  crl:/opt/osg036/globus/TRUSTED_CA/a692434d.r0\n         29.3 issuer=/C=FR/O=CNRS/CN=GRID-FR  crl:/opt/osg036/globus/TRUSTED_CA/12a1d8c2.r0\n         29.1 issuer=/C=DE/O=GermanGrid/CN=GridKa-CA  crl:/opt/osg036/globus/TRUSTED_CA/dd4b34ea.r0\n         28.8 issuer=/C=JP/O=National Research Grid Initiative/OU=GRID/CN=NAREGI CA  crl:/opt/osg036/globus/TRUSTED_CA/0cb5fc2c.r0\n         28.3 issuer=/C=AU/O=APACGrid/OU=CA/CN=APACGrid/emailAddress=camanager@vpac.org  crl:/opt/osg036/globus/TRUSTED_CA/1e12d831.r0\n         27.9 issuer=/DC=ORG/DC=SEE-GRID/CN=SEE-GRID CA  crl:/opt/osg036/globus/TRUSTED_CA/468d15b3.r0\n         27.9 issuer=/C=GR/O=HellasGrid/CN=HellasGrid CA  crl:/opt/osg036/globus/TRUSTED_CA/ede78092.r0\n         27.1 issuer=/C=NL/O=NIKHEF/CN=NIKHEF medium-security certification auth  crl:/opt/osg036/globus/TRUSTED_CA/16da7552.r0\n         27.0 issuer=/C=PL/O=GRID/CN=Polish Grid CA  crl:/opt/osg036/globus/TRUSTED_CA/8a661490.r0\n         26.8 issuer=/O=Grid/O=NorduGrid/CN=NorduGrid Certification Authority  crl:/opt/osg036/globus/TRUSTED_CA/1f0e8352.r0\n         25.9 issuer=/C=AM/O=ArmeSFo/CN=ArmeSFo CA  crl:/opt/osg036/globus/TRUSTED_CA/d0c2a341.r0\n         25.9 issuer=/C=BE/O=BELNET/OU=BEGrid/CN=BEGrid CA/emailAddress=gridca@belnet.be  crl:/opt/osg036/globus/TRUSTED_CA/03aa0ecb.r0\n         24.0 issuer=/C=UK/O=eScience/OU=Authority/CN=CA/emailAddress=ca-operator@grid-support.ac.uk  crl:/opt/osg036/globus/TRUSTED_CA/01621954.r0\n         23.9 issuer=/C=HU/O=KFKI RMKI CA/CN=KFKI RMKI CA  crl:/opt/osg036/globus/TRUSTED_CA/5e5501f3.r0\n         23.9 issuer=/C=SK/O=SlovakGrid/CN=SlovakGrid CA  crl:/opt/osg036/globus/TRUSTED_CA/e13e0fcf.r0\n         23.1 issuer=/C=PT/O=LIPCA/CN=LIP Certification Authority  crl:/opt/osg036/globus/TRUSTED_CA/11b4a5a2.r0\n         23.0 issuer=/C=PT/O=LIP/OU=LISCC/CN=LIP Certification Authority  crl:/opt/osg036/globus/TRUSTED_CA/41380387.r0\n         23.0 issuer=/C=AT/O=AustrianGrid/OU=Certification Authority/CN=Certificate Issuer  crl:/opt/osg036/globus/TRUSTED_CA/6e3b436b.r0\n         22.9 issuer=/C=CZ/O=CESNET/CN=CESNET CA  crl:/opt/osg036/globus/TRUSTED_CA/ed99a497.r0\n         21.9 issuer=/C=KR/O=KISTI/CN=KISTI GRID ROOT CA  crl:/opt/osg036/globus/TRUSTED_CA/47183fda.r0\n         21.7 issuer=/C=CN/O=HEP/CN=gridca-cn/emailAddress=gridca@ihep.ac.cn  crl:/opt/osg036/globus/TRUSTED_CA/ba2f39ca.r0\n         21.1 issuer=/C=CH/O=CERN/OU=GRID/CN=CERN CA  crl:/opt/osg036/globus/TRUSTED_CA/fa3af1d7.r0\n         19.1 issuer=/C=SI/O=SiGNET/CN=SiGNET CA/emailAddress=signet-ca@ijs.si  crl:/opt/osg036/globus/TRUSTED_CA/747183a5.r0\n         16.0 issuer=/DC=org/DC=balticgrid/CN=Baltic Grid Certification Authority  crl:/opt/osg036/globus/TRUSTED_CA/2a237f16.r0\n         15.9 issuer=/C=EE/O=Grid/CN=Estonian Grid Certification Authority  crl:/opt/osg036/globus/TRUSTED_CA/566bf40f.r0\n         12.9 issuer=/C=PK/O=NCP/CN=ncp.edu.pk  crl:/opt/osg036/globus/TRUSTED_CA/d2a353a5.r0\n         11.3 issuer=/C=US/ST=California/L=Los Angeles/O=University of Southern California/CN=University of Southern California PKI-Lite CA, release 1/emailAddress=nmiadmin@usc.edu  crl:/opt/osg036/globus/TRUSTED_CA/2ca73e82.r0\n         10.8 issuer=/C=RU/O=DataGrid/CN=Russian DataGrid CA  crl:/opt/osg036/globus/TRUSTED_CA/d64ccb53.r0\n          9.7 issuer=/C=TR/O=TRGrid/CN=TR-Grid CA  crl:/opt/osg036/globus/TRUSTED_CA/1691b9ba.r0\n          9.3 issuer=/C=US/O=Pittsburgh Supercomputing Center/CN=PSC Root Certificate Authority  crl:/opt/osg036/globus/TRUSTED_CA/aa99c057.r0\n          9.2 issuer=/C=ES/O=DATAGRID-ES/CN=DATAGRID-ES CA  crl:/opt/osg036/globus/TRUSTED_CA/13eab55e.r0\n          8.0 issuer=/C=DE/O=DFN-Verein/OU=DFN-PKI/CN=DFN-Verein PCA Grid - G01  crl:/opt/osg036/globus/TRUSTED_CA/1149214e.r0\n          7.7 issuer=/C=JP/O=AIST/OU=GRID/CN=Certificate Authority  crl:/opt/osg036/globus/TRUSTED_CA/a317c467.r0\n          7.2 issuer=/DC=cz/DC=cesnet-ca/CN=CESNET CA  crl:/opt/osg036/globus/TRUSTED_CA/9b59ecad.r0\n ***      6.8 issuer=/C=US/O=SDSC/OU=SDSC-CA/CN=Certificate Authority/UID=certman  crl:/opt/osg036/globus/TRUSTED_CA/3deda549.r0\n ***      6.2 issuer=/C=CA/O=Grid/CN=Grid Canada Certificate Authority  crl:/opt/osg036/globus/TRUSTED_CA/bffbd7d0.r0\n ***      4.4 issuer=/C=HU/O=NIIF/OU=Certificate Authorities/CN=NIIF Root CA  crl:/opt/osg036/globus/TRUSTED_CA/cc800af0.r0\n ***      4.2 issuer=/C=US/O=UTAustin/OU=TACC/CN=TACC Certification Authority/UID=caman  crl:/opt/osg036/globus/TRUSTED_CA/9a1da9f9.r0\n ***      1.1 issuer=/CN=PurdueCA/O=Purdue University/ST=Indiana/C=US  crl:/opt/osg036/globus/TRUSTED_CA/95009ddc.r0\n ***      1.0 issuer=/C=CH/O=SWITCH - Teleinformatikdienste fuer Lehre und Forschung/CN=SWITCH Server CA/emailAddress=switch.server.ca@switch.ch  crl:/opt/osg036/globus/TRUSTED_CA/072fe468.r0\n ***      1.0 issuer=/C=CH/O=SWITCH - Teleinformatikdienste fuer Lehre und Forschung/CN=SWITCH Personal CA/emailAddress=switch.personal.ca@switch.ch  crl:/opt/osg036/globus/TRUSTED_CA/4aa5ef7d.r0\n ***      1.0 issuer=/CN=SWITCH Personal CA/emailAddress=switch.personal.ca@switch.ch/O=SWITCH - Teleinformatikdienste fuer Lehre und Forschung/C=CH  crl:/opt/osg036/globus/TRUSTED_CA/7c0f6d74.r0\n ***      1.0 issuer=/CN=SWITCH Server CA/emailAddress=switch.server.ca@switch.ch/O=SWITCH - Teleinformatikdienste fuer Lehre und Forschung/C=CH  crl:/opt/osg036/globus/TRUSTED_CA/f8b4299c.r0\n ***      1.0 issuer=/CN=Purdue TeraGrid RA/OU=Purdue TeraGrid/O=Purdue University/ST=Indiana/C=US  crl:/opt/osg036/globus/TRUSTED_CA/67e8acfa.r0\nnearest CRL expiration 0.951088 days   Site administrators may find it useful to run this command in a daily cron job following the edg-crl-upgraded daemon as a way to monitor the status of the CRL\u2019s.", 
            "title": "Checking CRL\u2019s"
        }, 
        {
            "location": "/common/cert_scripts/#references", 
            "text": "For additional information on the functionality of a script execute it with the -help option.  Files in the package:     File  Description      README  describes the package, includes release notes    cert-check-time  checks lifetime of certificates and revocation lists    cert-gridadmin  immediate issuance of service certificates for authorized requestors    cert-lookup  queries directory based on DN of certificates    cert-request  generates and submits a certificate signing request    cert-retrieve  retrieves signed certificate previously requested    cert-renew  renews existing person certificate (not host or service)    multi-cert-gridadmin  immediate issuance of multiple service certificates for authorized administrators (new with V2-3)    InstallationNotes.txt  extra installation requirements for multi-cert-gridadmin (new with V2-3)", 
            "title": "References"
        }, 
        {
            "location": "/common/cert_scripts/#faq", 
            "text": "How to perform common tasks. In  red  the items you have to change.", 
            "title": "FAQ"
        }, 
        {
            "location": "/common/cert_scripts/#request-a-certificate-for-myself-personal-certificate", 
            "text": "UCL_PROMPT  cert-request -ou p   Full details in the  command line document  or in the  Web interface document  (for a browser based alt.).", 
            "title": "Request a certificate for myself (personal certificate)"
        }, 
        {
            "location": "/common/cert_scripts/#request-a-certificate-for-my-computer-host-certificate", 
            "text": "UCL_PROMPT  cert-request -ou s   Full details in the  host and service certificates document .", 
            "title": "Request a certificate for my computer (host certificate)"
        }, 
        {
            "location": "/common/cert_scripts/#request-a-certificate-for-the-http-service-on-my-computer-service-certificate", 
            "text": "UCL_PROMPT  cert-request -ou s -service http -host  my-computer.some.domain  -label  http-my-computer   Full details in the  host and service certificates document .", 
            "title": "Request a certificate for the http service on my computer (service certificate)"
        }, 
        {
            "location": "/common/cert_scripts/#retrieve-a-certificate", 
            "text": "Check the email notice you got when the certificate was granted for the serial number ( 0xNNNN )   UCL_PROMPT  cert-retrieve -serial  0xNNNN  [-label  label-matching-cert-request ]   Use the  -p12  option to create the PKCS12 format file useful for importing your certificate into a web browser or email program.", 
            "title": "Retrieve a certificate"
        }, 
        {
            "location": "/common/cert_scripts/#if-you-need-to-get-lots-of-service-certificates", 
            "text": "Ask your RA to grant you the  gridadmin  privilege. 2. Use  cert-gridadmin  and you can get service certificates issued immediately without using the web interface.", 
            "title": "If you need to get lots of service certificates"
        }, 
        {
            "location": "/common/cert_scripts/#my-personal-certificate-is-about-to-expire-how-do-i-get-another-with-the-same-dn", 
            "text": "Use  cert-renew   Full details in the  command line document  or in the  Web interface document  (for a browser based alt.).", 
            "title": "My personal certificate is about to expire, how do I get another with the same DN?"
        }, 
        {
            "location": "/compute-element/job_router/", 
            "text": "Writing Routes For HTCondor-CE\n\n\n\n\nAbout This Guide\n\n\nThe \nJobRouter\n is at the heart of HTCondor-CE and allows admins to transform and direct jobs to specific batch systems. Customizations are made in the form of job routes where each route corresponds to a separate job transformation: If an incoming job matches a job route\u2018s requirements, the route creates a transformed job (referred to as the \u2019routed job\u2019) that is then submitted to the batch system. The CE package comes with default routes located in \n/etc/condor-ce/config.d/02-ce-*.conf\n that provide enough basic functionality for a small site.\n\n\nIf you have needs beyond delegating all incoming jobs to your batch system as they are, this document provides examples of common job routes and job route problems.\n\n\nRoutePitfalls\n\n\nQuirks and Pitfalls\n\n\n\n\nThe JobRouter matches jobs to routes in a round-robin fashion. This means that if a job can match to multiple routes, it can be routed by any of them! So when writing job routes, make sure that they are exclusive to each other and that your jobs can only match to a single route.\n\n\nIf a value is set in \nJOB_ROUTER_DEFAULTS\n with \neval_set_\nvariable\n, override it by using \neval_set_\nvariable\n in the \nJOB_ROUTER_ENTRIES\n. Do this at your own risk as it may cause the CE to break.\n\n\nMake sure to run \ncondor_ce_reconfig\n after changing your routes, otherwise they will not take effect.\n\n\nBefore the last square bracket, make sure all lines end in a line continuation character (backslash). You can inspect the syntax of your routes with \ncondor_ce_config_val JOB_ROUTER_ENTRIES\n to see if HTCondor-CE has ingested them properly.\n\n\nDo \nnot\n set the \nJOB_ROUTER_DEFAULTS\n configuration variable yourself. This will cause the CE to stop functioning.\n\n\nDo \nnot\n set the job environment through the JobRouter. Instead, add any changes to the /etc/osg/config.d/ \n[Local Settings]\n section and run osg-configure, as documented \nhere\n.\n\n\nHTCondor batch system only: Local universe jobs are excluded from any routing.\n\n\n\n\n\n\n#JobRouteConstruction\n\n\nHow Job Routes are Constructed\n\n\nEach job route\u2019s \nClassAd\n is constructed by combining each entry from the \nJOB_ROUTER_ENTRIES\n with the \nJOB_ROUTER_DEFAULTS\n. Attributes that are set in \nJOB_ROUTER_ENTRIES\n will override those set in \nJOB_ROUTER_DEFAULTS\n\n\nJOB_ROUTER_ENTRIES\n\n\nJOB_ROUTER_ENTRIES\n is a configuration variable whose default is set in \n/etc/condor-ce/config.d/02-ce-*.conf\n but may be overriden by the administrator in \n/etc/condor-ce/config.d/99-local.conf\n. This document outlines the many changes you can make to \nJOB_ROUTER_ENTRIES\n to fit your site\u2019s needs.\n\n\n#JobRouterDefaults\n\n\nJOB_ROUTER_DEFAULTS\n\n\nJOB_ROUTER_DEFAULTS\n is a python-generated configuration variable that sets default job route values that are required for the HTCondor-CE\u2019s functionality. To view its contents, run the following command:\n\n\nUCL_PROMPT\n condor_ce_config_val JOB_ROUTER_DEFAULTS | sed \ns/;/;\\n/g\n\n\n\n\n\n\nTWISTY_OPTS_OUTPUT\n showlink=\"Show sample output\"\n\n\n[\n \nMaxIdleJobs\n =\n \n2000\n;\n\n \nMaxJobs\n =\n \n10000\n;\n\n \n/* by default, accept all jobs */\n \nRequirements\n =\n \nTrue\n;\n\n \n/* now modify routed job attributes */\n \n/* remove routed job if the client disappears for 48 hours or it is idle for 6 */\n \n/*set_PeriodicRemove = (LastClientContact - time() \n 48*60*60) || (JobStatus == 1 \n (time() - QDate) \n 6*60);\n\n\n*/\n \ndelete_PeriodicRemove\n =\n \ntrue\n;\n\n \ndelete_CondorCE\n =\n \ntrue\n;\n\n \nset_RoutedJob\n =\n \ntrue\n;\n\n \ncopy_environment\n =\n \norig_environment\n;\n\n \nset_osg_environment\n =\n \nOSG_GRID=\n/etc/osg/wn-client/\n OSG_SQUID_LOCATION=\nfermicloud133.fnal.gov:3128\n OSG_SITE_READ=\nNone\n OSG_APP=\n/share/osg/app\n OSG_GLEXEC_LOCATION=\nNone\n OSG_DATA=\nUNAVAILABLE\n OSG_HOSTNAME=\nfermicloud136.fnal.gov\n OSG_STORAGE_ELEMENT=\nFalse\n OSG_SITE_NAME=\nherp\n GLOBUS_LOCATION=\n/usr\n OSG_WN_TMP=\nNone\n OSG_DEFAULT_SE=\nNone\n OSG_SITE_WRITE=\nNone\n;\n\n \neval_set_environment\n =\n \ndebug\n(\nstrcat\n(\nHOME=\n,\n \nuserHome\n(\nOwner\n,\n \n/\n),\n \n \n,\n \nifThenElse\n(\norig_environment\n \nis\n \nundefined\n,\n \nosg_environment\n,\n \nstrcat\n(\nosg_environment\n,\n \n \n,\n \norig_environment\n)\n \n)));\n\n \n/* Set new requirements */\n \n/* set_requirements = LastClientContact - time() \n 30*60;\n\n\n */\n \nset_requirements\n =\n \nTrue\n;\n\n \nset_InputRSL\n =\n \nifThenElse\n(\nGlobusRSL\n \nis\n \nnull\n,\n \n[\n]\n,\n \neval_rsl\n(\nGlobusRSL\n));\n\n \n/* Note default memory request of 2GB */\n \n/* Note yet another nested condition allow pass attributes (maxMemory,xcount,jobtype,queue) via gWMS Factory described within ClassAd if undefined via RSL */\n \neval_set_RequestMemory\n \n=\n \nifThenElse\n(\nInputRSL\n.\nmaxMemory\n \nisnt\n \nnull\n,\n \nInputRSL\n.\nmaxMemory\n,\n \nifThenElse\n(\nmaxMemory\n \nisnt\n \nnull\n,\n \nmaxMemory\n,\n \nifThenElse\n(\ndefault_maxMemory\n \nisnt\n \nnull\n,\n \ndefault_maxMemory\n,\n \n2000\n)));\n\n \neval_set_remote_queue\n \n=\n \nifThenElse\n(\nInputRSL\n.\nqueue\n \nisnt\n \nnull\n,\n \nInputRSL\n.\nqueue\n,\n \nifThenElse\n(\nqueue\n \nisnt\n \nnull\n,\n \nqueue\n,\n \nifThenElse\n(\ndefault_queue\n \nisnt\n \nnull\n,\n \ndefault_queue\n,\n \n)));\n\n \n/* HTCondor uses RequestCpus;\n\n\n blahp uses SMPGranularity and NodeNumber.  Default is 1 core. */\n \neval_set_RequestCpus\n \n=\n \nifThenElse\n(\nInputRSL\n.\nxcount\n \nisnt\n \nnull\n,\n \nInputRSL\n.\nxcount\n,\n \nifThenElse\n(\nxcount\n \nisnt\n \nnull\n,\n \nxcount\n,\n \nifThenElse\n(\ndefault_xcount\n \nisnt\n \nnull\n,\n \ndefault_xcount\n,\n \n1\n)));\n\n \neval_set_remote_SMPGranularity\n \n=\n \nifThenElse\n(\nInputRSL\n.\nxcount\n \nisnt\n \nnull\n,\n \nInputRSL\n.\nxcount\n,\n \nifThenElse\n(\nxcount\n \nisnt\n \nnull\n,\n \nxcount\n,\n \nifThenElse\n(\ndefault_xcount\n \nisnt\n \nnull\n,\n \ndefault_xcount\n,\n \n1\n)));\n\n \neval_set_remote_NodeNumber\n \n=\n \nifThenElse\n(\nInputRSL\n.\nxcount\n \nisnt\n \nnull\n,\n \nInputRSL\n.\nxcount\n,\n \nifThenElse\n(\nxcount\n \nisnt\n \nnull\n,\n \nxcount\n,\n \nifThenElse\n(\ndefault_xcount\n \nisnt\n \nnull\n,\n \ndefault_xcount\n,\n \n1\n)));\n\n \n/* If remote_cerequirements is a string, BLAH will parse it as an expression before examining it */\n \neval_set_remote_cerequirements\n \n=\n \nifThenElse\n(\nInputRSL\n.\nmaxWalTlime\n \nisnt\n \nnull\n,\n \nstrcat\n(\nWalltime == \n,\n \nstring\n(\n60\n*\nInputRSL\n.\nmaxWallTime\n),\n \n \n CondorCE == 1\n),\n \nifThenElse\n(\nmaxWallTime\n \nisnt\n \nnull\n,\n \nstrcat\n(\nWalltime == \n,\n \nstring\n(\n60\n*\nmaxWallTime\n),\n \n \n CondorCE == 1\n),\n \nifThenElse\n(\ndefault_maxWallTime\n \nisnt\n \nnull\n,\n \nstrcat\n(\nWalltime == \n,\n \nstring\n(\n60\n*\ndefault_maxWallTime\n),\n \n \n CondorCE == 1\n),\n \nCondorCE == 1\n)));\n\n \n]\n\n\n\n\n\n\n\n\n If a value is set in \nJOB_ROUTER_DEFAULTS\n with \neval_set_\nvariable\n, override it by using \neval_set_\nvariable\n in the \nJOB_ROUTER_ENTRIES\n. Do this at your own risk as it may cause the CE to break. \n Do \nnot\n set the \nJOB_ROUTER_DEFAULTS\n configuration variable yourself. This will cause the CE to stop functioning.\n\n\nGeneric Routes\n\n\nNew routes should be placed in \n/etc/condor-ce/config.d/99-local.conf\n, not the original \n02-ce-*.conf\n.\n\n\nRequired fields\n\n\nThe minimum requirements for a route are that you specify the type of batch system that jobs should be routed to and a name for each route. Default routes can be found in \n/usr/share/condor-ce/config.d/02-ce-\nbatch system\n-defaults.conf\n, provided by the \nosg-ce-\nbatch system\n packages.\n\n\nBatch system\n\n\nEach route needs to indicate the type of batch system that jobs should be routed to. For HTCondor batch systems, the \nTargetUniverse\n attribute needs to be set to \n5\n or \n\"vanilla\"\n. For all other batch systems, the \nTargetUniverse\n attribute needs to be set to \n9\n or \n\"grid\"\n and the \nGridResource\n attribute needs to be set to \n\"batch \nbatch system\n\"\n (where \nbatch system\n can be one of \npbs\n (for both users of \npbs\n and \nSLURM\n), \nlsf\n, or \nsge\n).\n\n\nJOB_ROUTER_ENTRIES = [ \\\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\n# Route to an HTCondor-CE batch system \\\n/b\n/span\n\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\nTargetUniverse = 5; \\\n/b\n/span\n\n     name = \nRoute jobs to HTCondor\n; \\\n] \\\n[ \\\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\n# Route to a PBS batch system \\\n/b\n/span\n\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\nGridResource = \nbatch pbs\n; \\\n/b\n/span\n\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\nTargetUniverse = 9; \\\n/b\n/span\n\n     name = \nRoute jobs to PBS\n; \\\n]\n\n\n\n\n\nRoute name\n\n\nTo identify routes, you will need to assign a name to the route with the \nname\n attribute:\n\n\nJOB_ROUTER_ENTRIES = [ \\\n     TargetUniverse = 5; \\\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\nname = \nRoute jobs to HTCondor\n; \\\n/b\n/span\n\n]\n\n\n\n\n\nThe name of the route will be useful in debugging since it shows up in the output of \ncondor_ce_job_router_info\n, the \nJobRouterLog\n, and in the ClassAd of the routed job, which can be viewed with \ncondor_ce_q\n or \ncondor_ce_history\n.\n\n\nWriting multiple routes\n\n\nIf your batch system needs incoming jobs to be sorted (e.g. if different VO\u2019s need to go to separate queues), you will need to write multiple job routes. Each route is enclosed by square brackets and unless they\u2019re the last closing bracket, they need to be followed by the line continuation character. The following routes takes incoming jobs that have a \nqueue\n attribute set to \n\"analy\"\n and routes them to the site\u2019s HTCondor batch system. Any other jobs will be sent to that site\u2019s PBS batch system.\n\n\n The JobRouter matches jobs to routes in a round-robin fashion. This means that if a job can match to multiple routes, it can be routed by any of them! So when writing job routes, make sure that they are exclusive to each other and that your jobs can only match to a single route.\n\n\nJOB_ROUTER_ENTRIES = \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\n[ \\\n/b\n/span\n\n     TargetUniverse = 5; \\\n     name = \nRoute jobs to HTCondor\n; \\\n     Requirements = (TARGET.queue =?= \nanaly\n); \\\n\nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\n] \\\n/b\n/span\n\n\nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\n[ \\\n/b\n/span\n\n     GridResource = \nbatch pbs\n; \\\n     TargetUniverse = 9; \\\n     name = \nRoute jobs to PBS\n; \\\n     Requirements = (TARGET.queue =!= \nanaly\n); \\\n\nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\n]\n/b\n/span\n\n\n\n\n\n\nWriting comments\n\n\nTo write comments you can use C-style comments, text enclosed by \n/* */\n. If the comment is at the end of a line, it still has to be followed by the line continuation character.\n\n\nJOB_ROUTER_ENTRIES = [ \\\n     TargetUniverse = 5; \\\n     name = \nC-style comments\n; \\\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\n/* This is a comment */ \\\n/b\n/span\n\n] \n\n\n\n\n\nFor \ncondor_ce_version\n 8.2.x or greater, you can also use \n#\n to comment out single lines:\n\n\nJOB_ROUTER_ENTRIES = [ \\\n     TargetUniverse = 5; \\\n     name = \nHash comments\n; \\\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\n# BrokenAttribute = \ncommented out\n; \\\n/b\n/span\n \n] \n\n\n\n\n\nSetting attributes for all routes\n\n\nTo set an attribute that will be applied to all routes, you will need to use the \n[[#SettingAttributes][set_]]\n function for each route.\n\n\n Do \nnot\n try to do this by setting the \nJOB_ROUTER_DEFAULTS\n configuration variable, as this will cause the CE to stop functioning.\n\n\nThe following routes set the \nPeriodic_Hold\n attribute for both routes:\n\n\nJOB_ROUTER_ENTRIES = [ \\\n     TargetUniverse = 5; \\\n     name = \nRoute jobs to HTCondor\n; \\\n     Requirements = (TARGET.queue =?= \nanaly\n); \\\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\n/* Puts the routed job on hold if the job\ns been idle and has been started at least once or if the job has tried to start more than once */ \\ \n/b\n/span\n\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\nset_Periodic_Hold = (NumJobStarts \n= 1 \n JobStatus == 1) || NumJobStarts \n 1; \\\n/b\n/span\n\n] \\\n[ \\\n     GridResource = \nbatch pbs\n; \\\n     TargetUniverse = 9; \\\n     name = \nRoute jobs to PBS\n; \\\n     Requirements = (TARGET.queue =!= \nanaly\n); \\\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\n/* Puts the routed job on hold if the job\ns been idle and has been started at least once or if the job has tried to start more than once */ \\ \n/b\n/span\n\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\nset_Periodic_Hold = (NumJobStarts \n= 1 \n JobStatus == 1) || NumJobStarts \n 1; \\\n/b\n/span\n\n] \n\n\n\n\n\nFiltering jobs based on\u2026\n\n\nTo filter jobs, use the \nRequirements\n attribute. Jobs will evaluate against the ClassAd expression set in the \nRequirements\n and if the expression evaluates to \nTRUE\n, the route will match. More information on the syntax of ClassAd's can be found in the \nHTCondor manual\n. For an example on how incoming jobs interact with filtering in job routes, consult \nthis document\n.\n\n\nWhen setting requirements, you need to prefix job attributes that you are filtering with \nTARGET.\n so that the job route knows to compare the attribute of the incoming job rather than the route\u2019s own attribute. For example, if an incoming job has a =queue = \u201canaly\u201d= attribute, then the following job route will not match:\n\n\nJOB_ROUTER_ENTRIES = [ \\\n     TargetUniverse = 5; \\\n     name = \nFiltering by queue\n; \\\n     queue = \nnot-analy\n; \\\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\nRequirements = (TARGET.queue =?= \nanaly\n); \\\n/b\n/span\n\n] \n\n\n\n\n\nThis is because when evaluating the route requirement, the job route will compare its own \nqueue\n attribute to \u201canaly\u201d and see that it does not match. You can read more about comparing two ClassAds in the \nHTCondor manual\n.\n\n\n If you have an HTCondor batch system, note the difference with \nset_requirements\n. \n The JobRouter matches jobs to routes in a round-robin fashion. This means that if a job can match to multiple routes, it can be routed by any of them! So when writing job routes, make sure that they are exclusive to each other and that your jobs can only match to a single route.\n\n\n#GlideIn\n\n\nGlidein queue\n\n\nTo filter jobs based on their glidein queue attribute, your routes will need a \nRequirements\n expression using the incoming job\u2019s \nqueue\n attribute. The following entry routes jobs to the PBS queue if the incoming job (specified by \nTARGET\n) is an \nanaly\n (Analysis) glidein:\n\n\nJOB_ROUTER_ENTRIES = [ \\\n     TargetUniverse = 5; \\\n     name = \nFiltering by queue\n; \\\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\nRequirements = (TARGET.queue =?= \nanaly\n); \\\n/b\n/span\n\n] \n\n\n\n\n\nJob submitter\n\n\nTo filter jobs based on who submitted it, your routes will need a \nRequirements\n expression using the incoming job\u2019s \nOwner\n attribute. The following entry routes jobs to the HTCondor batch system iff the submitter is \nusatlas2\n:\n\n\nJOB_ROUTER_ENTRIES = [ \\\n     TargetUniverse = 5; \\\n     name = \nFiltering by job submitter\n; \\\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\nRequirements = (TARGET.Owner =?= \nusatlas2\n); \\\n/b\n/span\n\n] \n\n\n\n\n\nAlternatively, you can match based on regular expression. The following entry routes jobs to the PBS batch system iff the submitter\u2019s name begins with \nusatlas\n:\n\n\nJOB_ROUTER_ENTRIES = [ \\\n     GridResource = \nbatch pbs\n; \\\n     TargetUniverse = 9; \\\n     name = \nFiltering by job submitter (regular expression)\n; \\\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\nRequirements = regexp(\n^usatlas\n, TARGET.Owner); \\\n/b\n/span\n\n] \n\n\n\n\n\nVOMS attribute\n\n\nTo filter jobs based on the subject of the job\u2019s proxy, your routes will need a \nRequirements\n expression using the incoming job\u2019s \nx509UserProxyFirstFQAN\n attribute. The following entry routes jobs to the PBS batch system if the proxy subject contains \n/cms/Role=Pilot\n:\n\n\nJOB_ROUTER_ENTRIES = [ \\\n     GridResource = \nbatch pbs\n; \\\n     TargetUniverse = 9; \\\n     name = \nFiltering by VOMS attribute (regex)\n; \\\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\nRequirements = regexp(\n\\/cms\\/Role\\=pilot\n, TARGET.x509UserProxyFirstFQAN); \\\n/b\n/span\n\n] \n\n\n\n\n\nSetting a default\u2026\n\n\nThis section outlines how to set default job limits, memory, cores, queue, and maximum walltime. For an example on how users can override these defaults, consult \nthis document\n.\n\n\nMaximum number of jobs\n\n\nTo set a default limit to the maximum number of jobs per route, you can edit the configuration variable \nCONDORCE_MAX_JOBS\n in \n/etc/condor-ce/config.d/01-ce-router.conf\n:\n\n\nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\nCONDORCE_MAX_JOBS = 10000\n/b\n/span\n\n\n\n\n\n\nNote that this is to be placed directly into the HTCondor-CE configuration, not into a job route.\n\n\nMaximum memory\n\n\nTo set a default maximum memory for routed jobs, set the attribute \ndefault_maxMemory\n:\n\n\nJOB_ROUTER_ENTRIES = [ \\\n     GridResource = \nbatch pbs\n; \\\n     TargetUniverse = 9; \\\n     name = \nRequest memory\n; \\\n     /* Set the requested memory to 1 GB */ \\\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\nset_default_maxMemory = 1000; \\\n/b\n/span\n\n] \n\n\n\n\n\nNumber of cores to request\n\n\nTo set a default number of cores for routed jobs, set the attribute \ndefault_xcount\n:\n\n\nJOB_ROUTER_ENTRIES = [ \\\n     GridResource = \nbatch pbs\n; \\\n     TargetUniverse = 9; \\\n     name = \nRequest CPU\n; \\\n     /* Set the requested cores to 8 */ \\\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\nset_default_xcount = 8; \\\n/b\n/span\n\n] \n\n\n\n\n\nMaximum walltime\n\n\nTo set a default maximum walltime (in minutes) for routed jobs, set the attribute \ndefault_maxWallTime\n:\n\n\nJOB_ROUTER_ENTRIES = [ \\\n     GridResource = \nbatch pbs\n; \\\n     TargetUniverse = 9; \\\n     name = \nSetting WallTime\n; \\\n     /* Set the max walltime to 1 hr */ \\\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\nset_default_maxWallTime = 60; \\\n/b\n/span\n\n] \n\n\n\n\n\nEditing attributes\u2026\n\n\nThe following functions are operations that affect job attributes and are evaluated in the following order:\n\n\n\n\ncopy_*\n\n\ndelete_*\n\n\nset_*\n\n\neval_set_*\n\n\n\n\nAfter each job route\u2019s ClassAd is \nconstructed\n, the above operations are evaluated in order. For example, if the attribute \nfoo\n is set using \neval_set_foo\n in the \nJOB_ROUTER_DEFAULTS\n, you\u2018ll be unable to use \ndelete_foo\n to remote it from your jobs since the attribute is set using \neval_set_foo\n after the deletion occurs according to the order of operations. To get around this, we can take advantage of the fact that operations defined in \nJOB_ROUTER_DEFAULTS\n get overriden by the same operation in \nJOB_ROUTER_ENTRIES\n. So to \u2019delete\u2019 \nfoo\n, we would add =eval_set_foo = \u201c\u201d= to the route in the \nJOB_ROUTER_ENTRIES\n, resulting in \nfoo\n being absent from the routed job.\n\n\nMore documentation can be found in the \nHTCondor manual\n.\n\n\nCopying attributes\n\n\nTo copy the value of an attribute of the incoming job to an attribute of the routed job, use \ncopy_\n. The following route copies the \nenvironment\n attribute of the incoming job and sets the attribute \nOriginal_Environment\n on the routed job to the same value:\n\n\nJOB_ROUTER_ENTRIES = [ \\\n     GridResource = \nbatch pbs\n; \\\n     TargetUniverse = 9; \\\n     name = \nCopying attributes\n; \\\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\ncopy_environment = \nOriginal_Environment\n; \\\n/b\n/span\n\n] \n\n\n\n\n\nRemoving attributes\n\n\nTo remove an attribute of the incoming job from the routed job, use \ndelete_\n. The following route removes the \nenvironment\n attribute from the routed job:\n\n\nJOB_ROUTER_ENTRIES = [ \\\n     GridResource = \nbatch pbs\n; \\\n     TargetUniverse = 9; \\\n     name = \nCopying attributes\n; \\\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\ndelete_environment = True; \\\n/b\n/span\n\n] \n\n\n\n\n\n#SettingAttributes\n\n\nSetting attributes\n\n\nTo set an attribute on the routed job, use \nset_\n. The following route sets the Job\u2019s \nRank\n attribute to 5:\n\n\nJOB_ROUTER_ENTRIES = [ \\\n     GridResource = \nbatch pbs\n; \\\n     TargetUniverse = 9; \\\n     name = \nSetting an attribute\n; \\\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\nset_Rank = 5; \\\n/b\n/span\n\n] \n\n\n\n\n\nSetting attributes with ClassAd expressions\n\n\nTo set an attribute to a ClassAd expression to be evaluated, use \nset_eval\n. The following route sets the \nExperiment\n attribute to \natlas.osguser\n if the Owner of the incoming job is \nosguser\n:\n\n\n If a value is set in JOB_ROUTER_DEFAULTS with \neval_set_\nvariable\n, override it by using \neval_set_\nvariable\n in the \nJOB_ROUTER_ENTRIES\n.\n\n\nJOB_ROUTER_ENTRIES = [ \\\n     GridResource = \nbatch pbs\n; \\\n     TargetUniverse = 9; \\\n     name = \nSetting an attribute with a !ClassAd expression\n; \\\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\neval_set_Experiment = strcat(\natlas.\n, Owner); \\\n/b\n/span\n\n] \n\n\n\n\n\nLimiting the number of\u2026\n\n\nThis section outlines how to limit the number of total or idle jobs in a specific route (i.e., if this limit is reached, jobs will no longer be placed in this route).\n\n\n If you are using an HTCondor batch system, limiting the number of jobs is not the preferred solution: HTCondor manages fair share on its own via \nuser priorities and group accounting\n.\n\n\nTotal jobs\n\n\nTo set a limit on the number of jobs for a specific route, set the \nMaxJobs\n attribute:\n\n\nJOB_ROUTER_ENTRIES = [ \\\n     GridResource = \nbatch pbs\n; \\\n     TargetUniverse = 9; \\\n     name = \nLimit the total number of jobs to 100\n; \\\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\nMaxJobs = 100; \\\n/b\n/span\n\n] \\\n[ \\\n     GridResource = \nbatch pbs\n; \\\n     TargetUniverse = 9; \\\n     name = \nLimit the total number of jobs to 75\n; \\\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\nMaxJobs = 75; \\\n/b\n/span\n\n]\n\n\n\n\n\nIdle jobs\n\n\nTo set a limit on the number of idle jobs for a specific route, set the \nMaxIdleJobs\n attribute:\n\n\nJOB_ROUTER_ENTRIES = [ \\\n     TargetUniverse = 5; \\\n     name = \nLimit the total number of idle jobs to 100\n; \\\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\nMaxIdleJobs = 100; \\\n/b\n/span\n\n] \\\n[ \\\n     TargetUniverse = 5; \\\n     name = \nLimit the total number of idle jobs to 75\n; \\\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\nMaxIdleJobs = 75; \\\n/b\n/span\n\n]\n\n\n\n\n\nDebugRoutes\n\n\nDebugging routes\n\n\nTo help debug expressions in your routes, you can use the \ndebug()\n function. First, set the debug mode for the JobRouter by editing a file in \n/etc/condor-ce/config.d/\n to read\n\n\nJOB_ROUTER_DEBUG = D_FULLDEBUG\n\n\n\n\n\nThen wrap the problematic attribute in \ndebug()\n:\n\n\nJOB_ROUTER_ENTRIES = [ \\\n     GridResource = \nbatch pbs\n; \\\n     TargetUniverse = 9; \\\n     name = \nDebugging a difficult !ClassAd expression\n; \\\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\neval_set_Experiment = debug(strcat(\natlas\n, Name)); \\\n/b\n/span\n\n] \n\n\n\n\n\n\n\nYou will find the debugging output in \n/var/log/condor-ce/JobRouterLog\n.\n\n\nRoutes for HTCondor Batch Systems\n\n\nSetting periodic hold, release or remove\n\n\nTo release, remove or put a job on hold if it meets certain criteria, use the \nPERIODIC_*\n family of attributes. By default, periodic expressions are evaluated once every 300 seconds but this can be changed by setting PERIODIC_EXPR_INTERVAL in your CE\u2019s configuration.\n\n\nJOB_ROUTER_ENTRIES = [ \\\n     TargetUniverse = 5; \\\n     name = \nSetting periodic statements\n; \\\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\n/* Puts the routed job on hold if the job\ns been idle and has been started at least once or if the job has tried to start more than once */ \\\n/b\n/span\n\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\nset_Periodic_Hold = (NumJobStarts \n= 1 \n JobStatus == 1) || NumJobStarts \n 1; \\\n/b\n/span\n\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\n/* Remove routed jobs if their walltime is longer than 3 days and 5 minutes */ \\\n/b\n/span\n\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\nset_Periodic_Remove = ( RemoteWallClockTime \n (3*24*60*60 + 5*60) ); \\\n/b\n/span\n\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\n/* Release routed jobs if the condor_starter couldn\nt start the executable and \nVMGAHP_ERR_INTERNAL\n is in the HoldReason */ \\\n/b\n/span\n\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\nset_Periodic_Release = HoldReasonCode == 6 \n regexp(\nVMGAHP_ERR_INTERNAL\n, HoldReason); \\\n/b\n/span\n\n] \n\n\n\n\n\n#RoutedReq\n\n\nSetting routed job requirements\n\n\nIf you need to set requirements on your routed job, you will need to use \nset_Requirements\n instead of \nRequirements\n. The \nRequirements\n attribute filters jobs coming into your CE into different job routes whereas \nset_requirements\n will set conditions on the routed job that must be met by the worker node it lands on. For more information on requirements, consult the \nHTCondor manual\n.\n\n\nTo ensure that your job lands on a Linux machine in your pool:\n\n\nJOB_ROUTER_ENTRIES = [ \\\n     TargetUniverse = 5; \\\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\nset_Requirements =  OpSys == \nLINUX\n \\\n/b\n/span\n\n]\n\n\n\n\n\nSetting accounting groups\n\n\nTo assign jobs to an HTCondor accounting group to manage fair share on your local batch system, we recommend using \nUID and ExtAttr tables\n.\n\n\nRoutes for non-HTCondor Batch Systems\n\n\nSetting a default batch queue\n\n\nTo set a default queue for routed jobs, set the attribute \ndefault_queue\n:\n\n\nJOB_ROUTER_ENTRIES = [ \\\n     GridResource = \nbatch pbs\n; \\\n     TargetUniverse = 9; \\\n     name = \nSetting batch system queues\n; \\\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\nset_default_queue = \nosg_queue\n; \\\n/b\n/span\n\n] \n\n\n\n\n\nSetting batch system directives\n\n\nTo write batch system directives that are not supported in the route examples above, you will need to edit the job submit script for your local batch system in \n/etc/blahp/\n (e.g., if your local batch system is PBS, edit \n/etc/blahp/pbs_local_submit_attributes.sh\n). This file is sourced during submit time and anything printed to stdout is appended to the job submit script that gets submitted to your batch system. ClassAd attributes can be passed from the routed job to the local submit attributes script via the \ndefault_remote_cerequirements\n attribute, which can take the following form:\n\n\ndefault_remote_cerequirements = foo == X \n bar == Y \n ...\n\n\n\n\n\nThis sets \nfoo\n to value \nX\n and \nbar\n to \nY\n in the environment of the local submit attributes script. The following example sets the maximum walltime to 1 hour and the accounting group to the \nx509UserProxyFirstFQAN\n attribute of the job submitted to a PBS batch system\n\n\nJOB_ROUTER_ENTRIES = [ \\\n     GridResource = \nbatch pbs\n; \\\n     TargetUniverse = 9; \\\n     name = \nSetting job submit variables\n; \\\n     \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nb\nset_default_remote_cerequirements = strcat(\nWalltime == 3600 \n AccountingGroup == \\\n, x509UserProxyFirstFQAN, \n\\\n); \\\n/b\n/span\n\n] \n\n\n\n\n\nWith \n/etc/blahp/pbs_local_submit_attributes.sh\n containing.\n\n\n#!/bin/bash\n\n\necho\n \n#PBS -l walltime=\n$Walltime\n\n\necho\n \n#PBS -A \n$AccountingGroup\n\n\n\n\n\n\nThe result is that the following will be appended to the script that gets submitted to your batch system:\n\n\n#PBS -l walltime=3600\n#PBS -A \nspan\n \nstyle=\nbackground-color: #FFCCFF;\nlt;\nCE job\ns x509UserProxyFirstFQAN attribute\ngt;\n/span\n\n\n\n\n\n\nExample Configurations\n\n\nAGLT2\u2019s job routes\n\n\nAtlas AGLT2 is using an HTCondor batch system. Here are some things to note about their routes.\n\n\n\n\nSetting various HTCondor-specific attributes like \nRank\n, \nAccountingGroup\n, \nJobPrio\n and \nPeriodic_Remove\n (see the \nHTCondor manual\n for more). Some of these are site-specific like \nLastandFrac\n, \nIdleMP8Pressure\n, \nlocalQue\n, \nIsAnalyJob\n and \nJobMemoryLimit\n.\n\n\nThere is a difference between \nRequirements\n and \nset_requirements\n. The \nRequirements\n attribute matches jobs to specific routes while the \nset_requirements\n sets the \nRequirements\n attribute on the \nrouted\n job, which confines which machines that the routed job can land on.\n\n\n\n\nSource: \nhttps://www.aglt2.org/wiki/bin/view/AGLT2/CondorCE#The_JobRouter_configuration_file_content\n\n\nTWISTY_OPTS_OUTPUT\n showlink=\"Click to expand full job route\u2026\"\n\n\nJOB_ROUTER_ENTRIES\n \n=\n \n\\\n\n/* Still to \ndo\n on all routes, get job requirements and add them here */ \n\\\n\n/* ***** Route no \n1\n ***** */ \n\\\n\n/* ***** Analysis queue ***** */ \n\\\n\n  \n[\n \n\\\n\n    \nGridResource\n \n=\n \ncondor localhost localhost\n;\n \n\\\n\n    \neval_set_GridResource\n \n=\n strcat\n(\ncondor \n, \n$(\nFULL_HOSTNAME\n)\n, \n \n$(\nJOB_ROUTER_SCHEDD2_POOL\n)\n)\n;\n \n\\\n\n    \nRequirements\n \n=\n target.queue\n==\nanaly\n;\n \n\\\n\n    \nName\n \n=\n \nAnalysis Queue\n;\n \n\\\n\n    \nTargetUniverse\n \n=\n \n5\n;\n \n\\\n\n    \neval_set_IdleMP8Pressure\n \n=\n \n$(\nIdleMP8Pressure\n)\n;\n \n\\\n\n    \neval_set_LastAndFrac\n \n=\n \n$(\nLastAndFrac\n)\n;\n \n\\\n\n    \nset_requirements\n \n=\n \n(\n \n(\n TARGET.TotalDisk \n=\n?\n=\n undefined \n)\n \n||\n \n(\n TARGET.TotalDisk \n=\n \n21000000\n \n)\n \n)\n \n \n(\n TARGET.Arch \n==\n \nX86_64\n \n)\n \n \n(\n TARGET.OpSys \n==\n \nLINUX\n \n)\n \n \n(\n TARGET.Disk \n=\n RequestDisk \n)\n \n \n(\n TARGET.Memory \n=\n RequestMemory \n)\n \n \n(\n TARGET.HasFileTransfer \n)\n \n \n(\nIfThenElse\n((\nOwner\n \n==\n \natlasconnect\n \n||\n \nOwner\n \n==\n \nmuoncal\n)\n,IfThenElse\n(\nIdleMP8Pressure,\n(\nTARGET.PARTITIONED \n=\n!\n=\n TRUE\n)\n,True\n)\n,IfThenElse\n(\nLastAndFrac,\n(\nTARGET.PARTITIONED \n=\n!\n=\n TRUE\n)\n,True\n)))\n;\n \n\\\n\n    \neval_set_AccountingGroup\n \n=\n strcat\n(\ngroup_gatekpr.prod.analy.\n,Owner\n)\n;\n \n\\\n\n    \nset_localQue\n \n=\n \nAnalysis\n;\n \n\\\n\n    \nset_IsAnalyJob\n \n=\n True\n;\n \n\\\n\n    \nset_JobPrio\n \n=\n \n5\n;\n \n\\\n\n    \nset_Rank\n \n=\n \n(\nSlotID + \n(\n64\n-TARGET.DETECTED_CORES\n))\n*1.0\n;\n \n\\\n\n    \nset_JobMemoryLimit\n \n=\n \n4194000\n;\n \n\\\n\n    \nset_Periodic_Remove\n \n=\n \n(\n \n(\n RemoteWallClockTime \n \n(\n3\n*24*60*60 + \n5\n*60\n)\n \n)\n \n||\n \n(\nImageSize \n JobMemoryLimit\n)\n \n)\n;\n \n\\\n\n  \n]\n \n\\\n\n/* ***** Route no \n2\n ***** */ \n\\\n\n/* ***** splitterNT queue ***** */ \n\\\n\n  \n[\n \n\\\n\n    \nGridResource\n \n=\n \ncondor localhost localhost\n;\n \n\\\n\n    \neval_set_GridResource\n \n=\n strcat\n(\ncondor \n, \n$(\nFULL_HOSTNAME\n)\n, \n \n$(\nJOB_ROUTER_SCHEDD2_POOL\n)\n)\n;\n \n\\\n\n    \nRequirements\n \n=\n target.queue \n==\n \nsplitterNT\n;\n \n\\\n\n    \nName\n \n=\n \nSplitter ntuple queue\n;\n \n\\\n\n    \nTargetUniverse\n \n=\n \n5\n;\n \n\\\n\n    \nset_requirements\n \n=\n \n(\n \n(\n TARGET.TotalDisk \n=\n?\n=\n undefined \n)\n \n||\n \n(\n TARGET.TotalDisk \n=\n \n21000000\n \n)\n \n)\n \n \n(\n TARGET.Arch \n==\n \nX86_64\n \n)\n \n \n(\n TARGET.OpSys \n==\n \nLINUX\n \n)\n \n \n(\n TARGET.Disk \n=\n RequestDisk \n)\n \n \n(\n TARGET.Memory \n=\n RequestMemory \n)\n \n \n(\n TARGET.HasFileTransfer \n)\n;\n \n\\\n\n    \neval_set_AccountingGroup\n \n=\n \ngroup_calibrate.muoncal\n;\n \n\\\n\n    \nset_localQue\n \n=\n \nSplitter\n;\n \n\\\n\n    \nset_IsAnalyJob\n \n=\n False\n;\n \n\\\n\n    \nset_JobPrio\n \n=\n \n10\n;\n \n\\\n\n    \nset_Rank\n \n=\n \n(\nSlotID + \n(\n64\n-TARGET.DETECTED_CORES\n))\n*1.0\n;\n \n\\\n\n    \nset_JobMemoryLimit\n \n=\n \n4194000\n;\n \n\\\n\n    \nset_Periodic_Remove\n \n=\n \n(\n \n(\n RemoteWallClockTime \n \n(\n3\n*24*60*60 + \n5\n*60\n)\n \n)\n \n||\n \n(\nImageSize \n JobMemoryLimit\n)\n \n)\n;\n \n\\\n\n  \n]\n \n\\\n\n/* ***** Route no \n3\n ***** */ \n\\\n\n/* ***** splitter queue ***** */ \n\\\n\n  \n[\n \n\\\n\n    \nGridResource\n \n=\n \ncondor localhost localhost\n;\n \n\\\n\n    \neval_set_GridResource\n \n=\n strcat\n(\ncondor \n, \n$(\nFULL_HOSTNAME\n)\n, \n \n$(\nJOB_ROUTER_SCHEDD2_POOL\n)\n)\n;\n \n\\\n\n    \nRequirements\n \n=\n target.queue \n==\n \nsplitter\n;\n \n\\\n\n    \nName\n \n=\n \nSplitter queue\n;\n \n\\\n\n    \nTargetUniverse\n \n=\n \n5\n;\n \n\\\n\n    \nset_requirements\n \n=\n \n(\n \n(\n TARGET.TotalDisk \n=\n?\n=\n undefined \n)\n \n||\n \n(\n TARGET.TotalDisk \n=\n \n21000000\n \n)\n \n)\n \n \n(\n TARGET.Arch \n==\n \nX86_64\n \n)\n \n \n(\n TARGET.OpSys \n==\n \nLINUX\n \n)\n \n \n(\n TARGET.Disk \n=\n RequestDisk \n)\n \n \n(\n TARGET.Memory \n=\n RequestMemory \n)\n \n \n(\n TARGET.HasFileTransfer \n)\n;\n \n\\\n\n    \neval_set_AccountingGroup\n \n=\n \ngroup_calibrate.muoncal\n;\n \n\\\n\n    \nset_localQue\n \n=\n \nSplitter\n;\n \n\\\n\n    \nset_IsAnalyJob\n \n=\n False\n;\n \n\\\n\n    \nset_JobPrio\n \n=\n \n15\n;\n \n\\\n\n    \nset_Rank\n \n=\n \n(\nSlotID + \n(\n64\n-TARGET.DETECTED_CORES\n))\n*1.0\n;\n \n\\\n\n    \nset_JobMemoryLimit\n \n=\n \n4194000\n;\n \n\\\n\n    \nset_Periodic_Remove\n \n=\n \n(\n \n(\n RemoteWallClockTime \n \n(\n3\n*24*60*60 + \n5\n*60\n)\n \n)\n \n||\n \n(\nImageSize \n JobMemoryLimit\n)\n \n)\n;\n \n\\\n\n  \n]\n \n\\\n\n/* ***** Route no \n4\n ***** */ \n\\\n\n/* ***** xrootd queue ***** */ \n\\\n\n  \n[\n \n\\\n\n    \nGridResource\n \n=\n \ncondor localhost localhost\n;\n \n\\\n\n    \neval_set_GridResource\n \n=\n strcat\n(\ncondor \n, \n$(\nFULL_HOSTNAME\n)\n, \n \n$(\nJOB_ROUTER_SCHEDD2_POOL\n)\n)\n;\n \n\\\n\n    \nRequirements\n \n=\n target.queue \n==\n \nxrootd\n;\n \n\\\n\n    \nName\n \n=\n \nXrootd queue\n;\n \n\\\n\n    \nTargetUniverse\n \n=\n \n5\n;\n \n\\\n\n    \nset_requirements\n \n=\n \n(\n \n(\n TARGET.TotalDisk \n=\n?\n=\n undefined \n)\n \n||\n \n(\n TARGET.TotalDisk \n=\n \n21000000\n \n)\n \n)\n \n \n(\n TARGET.Arch \n==\n \nX86_64\n \n)\n \n \n(\n TARGET.OpSys \n==\n \nLINUX\n \n)\n \n \n(\n TARGET.Disk \n=\n RequestDisk \n)\n \n \n(\n TARGET.Memory \n=\n RequestMemory \n)\n \n \n(\n TARGET.HasFileTransfer \n)\n;\n \n\\\n\n    \neval_set_AccountingGroup\n \n=\n strcat\n(\ngroup_gatekpr.prod.analy.\n,Owner\n)\n;\n \n\\\n\n    \nset_localQue\n \n=\n \nAnalysis\n;\n \n\\\n\n    \nset_IsAnalyJob\n \n=\n True\n;\n \n\\\n\n    \nset_JobPrio\n \n=\n \n35\n;\n \n\\\n\n    \nset_Rank\n \n=\n \n(\nSlotID + \n(\n64\n-TARGET.DETECTED_CORES\n))\n*1.0\n;\n \n\\\n\n    \nset_JobMemoryLimit\n \n=\n \n4194000\n;\n \n\\\n\n    \nset_Periodic_Remove\n \n=\n \n(\n \n(\n RemoteWallClockTime \n \n(\n3\n*24*60*60 + \n5\n*60\n)\n \n)\n \n||\n \n(\nImageSize \n JobMemoryLimit\n)\n \n)\n;\n \n\\\n\n  \n]\n \n\\\n\n/* ***** Route no \n5\n ***** */ \n\\\n\n/* ***** Tier3Test queue ***** */ \n\\\n\n  \n[\n \n\\\n\n    \nGridResource\n \n=\n \ncondor localhost localhost\n;\n \n\\\n\n    \neval_set_GridResource\n \n=\n strcat\n(\ncondor \n, \n$(\nFULL_HOSTNAME\n)\n, \n \n$(\nJOB_ROUTER_SCHEDD2_POOL\n)\n)\n;\n \n\\\n\n    \nRequirements\n \n=\n target.queue \n==\n \nTier3Test\n;\n \n\\\n\n    \nName\n \n=\n \nTier3 Test Queue\n;\n \n\\\n\n    \nTargetUniverse\n \n=\n \n5\n;\n \n\\\n\n    \nset_requirements\n \n=\n \n(\n \n(\n TARGET.TotalDisk \n=\n?\n=\n undefined \n)\n \n||\n \n(\n TARGET.TotalDisk \n=\n \n21000000\n \n)\n \n)\n \n \n(\n TARGET.Arch \n==\n \nX86_64\n \n)\n \n \n(\n TARGET.OpSys \n==\n \nLINUX\n \n)\n \n \n(\n TARGET.Disk \n=\n RequestDisk \n)\n \n \n(\n TARGET.Memory \n=\n RequestMemory \n)\n \n \n(\n TARGET.HasFileTransfer \n)\n \n \n(\n \nIS_TIER3_TEST_QUEUE\n \n=\n?\n=\n True \n)\n;\n \n\\\n\n    \neval_set_AccountingGroup\n \n=\n strcat\n(\ngroup_gatekpr.prod.analy.\n,Owner\n)\n;\n \n\\\n\n    \nset_localQue\n \n=\n \nTier3Test\n;\n \n\\\n\n    \nset_IsTier3TestJob\n \n=\n True\n;\n \n\\\n\n    \nset_IsAnalyJob\n \n=\n True\n;\n \n\\\n\n    \nset_JobPrio\n \n=\n \n20\n;\n \n\\\n\n    \nset_Rank\n \n=\n \n(\nSlotID + \n(\n64\n-TARGET.DETECTED_CORES\n))\n*1.0\n;\n \n\\\n\n    \nset_JobMemoryLimit\n \n=\n \n4194000\n;\n \n\\\n\n    \nset_Periodic_Remove\n \n=\n \n(\n \n(\n RemoteWallClockTime \n \n(\n3\n*24*60*60 + \n5\n*60\n)\n \n)\n \n||\n \n(\nImageSize \n JobMemoryLimit\n)\n \n)\n;\n \n\\\n\n  \n]\n \n\\\n\n/* ***** Route no \n6\n ***** */ \n\\\n\n/* ***** mp8 queue ***** */ \n\\\n\n  \n[\n \n\\\n\n    \nGridResource\n \n=\n \ncondor localhost localhost\n;\n \n\\\n\n    \neval_set_GridResource\n \n=\n strcat\n(\ncondor \n, \n$(\nFULL_HOSTNAME\n)\n, \n \n$(\nJOB_ROUTER_SCHEDD2_POOL\n)\n)\n;\n \n\\\n\n    \nRequirements\n \n=\n target.queue\n==\nmp8\n;\n \n\\\n\n    \nName\n \n=\n \nMCORE Queue\n;\n \n\\\n\n    \nTargetUniverse\n \n=\n \n5\n;\n \n\\\n\n    \nset_requirements\n \n=\n \n(\n \n(\n TARGET.TotalDisk \n=\n?\n=\n undefined \n)\n \n||\n \n(\n TARGET.TotalDisk \n=\n \n21000000\n \n)\n \n)\n \n \n(\n TARGET.Arch \n==\n \nX86_64\n \n)\n \n \n(\n TARGET.OpSys \n==\n \nLINUX\n \n)\n \n \n(\n TARGET.Disk \n=\n RequestDisk \n)\n \n \n(\n TARGET.Memory \n=\n RequestMemory \n)\n \n \n(\n TARGET.HasFileTransfer \n)\n \n \n((\n TARGET.Cpus \n==\n \n8\n \n TARGET.CPU_TYPE \n=\n?\n=\n \nmp8\n \n)\n \n||\n TARGET.PARTITIONED \n=\n?\n=\n True \n)\n;\n \n\\\n\n    \neval_set_AccountingGroup\n \n=\n strcat\n(\ngroup_gatekpr.prod.mcore.\n,Owner\n)\n;\n \n\\\n\n    \nset_localQue\n \n=\n \nMP8\n;\n \n\\\n\n    \nset_IsAnalyJob\n \n=\n False\n;\n \n\\\n\n    \nset_JobPrio\n \n=\n \n25\n;\n \n\\\n\n    \nset_Rank\n \n=\n \n0\n.0\n;\n \n\\\n\n    \neval_set_RequestCpus\n \n=\n \n8\n;\n \n\\\n\n    \nset_JobMemoryLimit\n \n=\n \n33552000\n;\n \n\\\n\n    \nset_Slot_Type\n \n=\n \nmp8\n;\n \n\\\n\n    \nset_Periodic_Remove\n \n=\n \n(\n \n(\n RemoteWallClockTime \n \n(\n3\n*24*60*60 + \n5\n*60\n)\n \n)\n \n||\n \n(\nImageSize \n JobMemoryLimit\n)\n \n)\n;\n \n\\\n\n  \n]\n \n\\\n\n/* ***** Route no \n7\n ***** */ \n\\\n\n/* ***** Installation queue, triggered by usatlas2 user ***** */ \n\\\n\n  \n[\n \n\\\n\n    \nGridResource\n \n=\n \ncondor localhost localhost\n;\n \n\\\n\n    \neval_set_GridResource\n \n=\n strcat\n(\ncondor \n, \n$(\nFULL_HOSTNAME\n)\n, \n \n$(\nJOB_ROUTER_SCHEDD2_POOL\n)\n)\n;\n \n\\\n\n    \nRequirements\n \n=\n target.queue is undefined \n target.Owner \n==\n \nusatlas2\n;\n \n\\\n\n    \nName\n \n=\n \nInstall Queue\n;\n \n\\\n\n    \nTargetUniverse\n \n=\n \n5\n;\n \n\\\n\n    \nset_requirements\n \n=\n \n(\n \n(\n TARGET.TotalDisk \n=\n?\n=\n undefined \n)\n \n||\n \n(\n TARGET.TotalDisk \n=\n \n21000000\n \n)\n \n)\n \n \n(\n TARGET.Arch \n==\n \nX86_64\n \n)\n \n \n(\n TARGET.OpSys \n==\n \nLINUX\n \n)\n \n \n(\n TARGET.Disk \n=\n RequestDisk \n)\n \n \n(\n TARGET.Memory \n=\n RequestMemory \n)\n \n \n(\n TARGET.HasFileTransfer \n)\n \n \n(\n TARGET.IS_INSTALL_QUE \n=\n?\n=\n True \n)\n \n \n(\nTARGET.AGLT2_SITE \n==\n \nUM\n \n)\n;\n \n\\\n\n    \neval_set_AccountingGroup\n \n=\n strcat\n(\ngroup_gatekpr.other.\n,Owner\n)\n;\n \n\\\n\n    \nset_localQue\n \n=\n \nDefault\n;\n \n\\\n\n    \nset_IsAnalyJob\n \n=\n False\n;\n \n\\\n\n    \nset_IsInstallJob\n \n=\n True\n;\n \n\\\n\n    \nset_JobPrio\n \n=\n \n15\n;\n \n\\\n\n    \nset_Rank\n \n=\n \n(\nSlotID + \n(\n64\n-TARGET.DETECTED_CORES\n))\n*1.0\n;\n \n\\\n\n    \nset_JobMemoryLimit\n \n=\n \n4194000\n;\n \n\\\n\n    \nset_Periodic_Remove\n \n=\n \n(\n \n(\n RemoteWallClockTime \n \n(\n3\n*24*60*60 + \n5\n*60\n)\n \n)\n \n||\n \n(\nImageSize \n JobMemoryLimit\n)\n \n)\n;\n \n\\\n\n  \n]\n \n\\\n\n/* ***** Route no \n8\n ***** */ \n\\\n\n/* ***** Default queue \nfor\n usatlas1 user ***** */ \n\\\n\n  \n[\n \n\\\n\n    \nGridResource\n \n=\n \ncondor localhost localhost\n;\n \n\\\n\n    \neval_set_GridResource\n \n=\n strcat\n(\ncondor \n, \n$(\nFULL_HOSTNAME\n)\n, \n \n$(\nJOB_ROUTER_SCHEDD2_POOL\n)\n)\n;\n \n\\\n\n    \nRequirements\n \n=\n target.queue is undefined \n regexp\n(\nusatlas1\n,target.Owner\n)\n;\n \n\\\n\n    \nName\n \n=\n \nATLAS Production Queue\n;\n \n\\\n\n    \nTargetUniverse\n \n=\n \n5\n;\n \n\\\n\n    \nset_requirements\n \n=\n \n(\n \n(\n TARGET.TotalDisk \n=\n?\n=\n undefined \n)\n \n||\n \n(\n TARGET.TotalDisk \n=\n \n21000000\n \n)\n \n)\n \n \n(\n TARGET.Arch \n==\n \nX86_64\n \n)\n \n \n(\n TARGET.OpSys \n==\n \nLINUX\n \n)\n \n \n(\n TARGET.Disk \n=\n RequestDisk \n)\n \n \n(\n TARGET.Memory \n=\n RequestMemory \n)\n \n \n(\n TARGET.HasFileTransfer \n)\n;\n \n\\\n\n    \neval_set_AccountingGroup\n \n=\n strcat\n(\ngroup_gatekpr.prod.prod.\n,Owner\n)\n;\n \n\\\n\n    \nset_localQue\n \n=\n \nDefault\n;\n \n\\\n\n    \nset_IsAnalyJob\n \n=\n False\n;\n \n\\\n\n    \nset_Rank\n \n=\n \n(\nSlotID + \n(\n64\n-TARGET.DETECTED_CORES\n))\n*1.0\n;\n \n\\\n\n    \nset_JobMemoryLimit\n \n=\n \n4194000\n;\n \n\\\n\n    \nset_Periodic_Remove\n \n=\n \n(\n \n(\n RemoteWallClockTime \n \n(\n3\n*24*60*60 + \n5\n*60\n)\n \n)\n \n||\n \n(\nImageSize \n JobMemoryLimit\n)\n \n)\n;\n \n\\\n\n  \n]\n \n\\\n\n/* ***** Route no \n9\n ***** */ \n\\\n\n/* ***** Default queue \nfor\n any other usatlas account ***** */ \n\\\n\n  \n[\n \n\\\n\n    \nGridResource\n \n=\n \ncondor localhost localhost\n;\n \n\\\n\n    \neval_set_GridResource\n \n=\n strcat\n(\ncondor \n, \n$(\nFULL_HOSTNAME\n)\n, \n \n$(\nJOB_ROUTER_SCHEDD2_POOL\n)\n)\n;\n \n\\\n\n    \nRequirements\n \n=\n target.queue is undefined \n \n(\nregexp\n(\nusatlas2\n,target.Owner\n)\n \n||\n regexp\n(\nusatlas3\n,target.Owner\n))\n;\n \n\\\n\n    \nName\n \n=\n \nOther ATLAS Production\n;\n \n\\\n\n    \nTargetUniverse\n \n=\n \n5\n;\n \n\\\n\n    \nset_requirements\n \n=\n \n(\n \n(\n TARGET.TotalDisk \n=\n?\n=\n undefined \n)\n \n||\n \n(\n TARGET.TotalDisk \n=\n \n21000000\n \n)\n \n)\n \n \n(\n TARGET.Arch \n==\n \nX86_64\n \n)\n \n \n(\n TARGET.OpSys \n==\n \nLINUX\n \n)\n \n \n(\n TARGET.Disk \n=\n RequestDisk \n)\n \n \n(\n TARGET.Memory \n=\n RequestMemory \n)\n \n \n(\n TARGET.HasFileTransfer \n)\n;\n \n\\\n\n    \neval_set_AccountingGroup\n \n=\n strcat\n(\ngroup_gatekpr.other.\n,Owner\n)\n;\n \n\\\n\n    \nset_localQue\n \n=\n \nDefault\n;\n \n\\\n\n    \nset_IsAnalyJob\n \n=\n False\n;\n \n\\\n\n    \nset_Rank\n \n=\n \n(\nSlotID + \n(\n64\n-TARGET.DETECTED_CORES\n))\n*1.0\n;\n \n\\\n\n    \nset_JobMemoryLimit\n \n=\n \n4194000\n;\n \n\\\n\n    \nset_Periodic_Remove\n \n=\n \n(\n \n(\n RemoteWallClockTime \n \n(\n3\n*24*60*60 + \n5\n*60\n)\n \n)\n \n||\n \n(\nImageSize \n JobMemoryLimit\n)\n \n)\n;\n \n\\\n\n  \n]\n \n\\\n\n/* ***** Route no \n10\n ***** */ \n\\\n\n/* ***** Anything \nelse\n. Set queue as Default and assign to other VOs  ***** */ \n\\\n\n  \n[\n \n\\\n\n    \nGridResource\n \n=\n \ncondor localhost localhost\n;\n \n\\\n\n    \neval_set_GridResource\n \n=\n strcat\n(\ncondor \n, \n$(\nFULL_HOSTNAME\n)\n, \n \n$(\nJOB_ROUTER_SCHEDD2_POOL\n)\n)\n;\n \n\\\n\n    \nRequirements\n \n=\n target.queue is undefined \n ifThenElse\n(\nregexp\n(\nusatlas\n,target.Owner\n)\n,false,true\n)\n;\n \n\\\n\n    \nName\n \n=\n \nOther Jobs\n;\n \n\\\n\n    \nTargetUniverse\n \n=\n \n5\n;\n \n\\\n\n    \nset_requirements\n \n=\n \n(\n \n(\n TARGET.TotalDisk \n=\n?\n=\n undefined \n)\n \n||\n \n(\n TARGET.TotalDisk \n=\n \n21000000\n \n)\n \n)\n \n \n(\n TARGET.Arch \n==\n \nX86_64\n \n)\n \n \n(\n TARGET.OpSys \n==\n \nLINUX\n \n)\n \n \n(\n TARGET.Disk \n=\n RequestDisk \n)\n \n \n(\n TARGET.Memory \n=\n RequestMemory \n)\n \n \n(\n TARGET.HasFileTransfer \n)\n;\n \n\\\n\n    \neval_set_AccountingGroup\n \n=\n strcat\n(\ngroup_VOgener.\n,Owner\n)\n;\n \n\\\n\n    \nset_localQue\n \n=\n \nDefault\n;\n \n\\\n\n    \nset_IsAnalyJob\n \n=\n False\n;\n \n\\\n\n    \nset_Rank\n \n=\n \n(\nSlotID + \n(\n64\n-TARGET.DETECTED_CORES\n))\n*1.0\n;\n \n\\\n\n    \nset_JobMemoryLimit\n \n=\n \n4194000\n;\n \n\\\n\n    \nset_Periodic_Remove\n \n=\n \n(\n \n(\n RemoteWallClockTime \n \n(\n3\n*24*60*60 + \n5\n*60\n)\n \n)\n \n||\n \n(\nImageSize \n JobMemoryLimit\n)\n \n)\n;\n \n\\\n\n  \n]\n\n\n\n\n\n\n\n\nBNL\u2019s job routes\n\n\nAtlas BNL T1, they are using an HTCondor batch system. Here are some things to note about their routes:\n\n\n\n\nSetting various HTCondor-specific attributes like \nJobLeaseDuration\n, \nRequirements\n and \nPeriodic_Hold\n (see the \nHTCondor manual\n for more). Some of these are site-specific like \nRACF_Group\n, \nExperiment\n, \nJob_Type\n and \nVO\n.\n\n\nJobs are split into different routes based on the \nGlideIn\n queue that they\u2019re in.\n\n\nThere is a difference between \nRequirements\n and \nset_requirements\n. The \nRequirements\n attribute matches \nincoming\n jobs to specific routes while the \nset_requirements\n sets the \nRequirements\n attribute on the \nrouted\n job, which confines which machines that the routed job can land on.\n\n\n\n\nSource: \nhttp://www.usatlas.bnl.gov/twiki/bin/view/Admins/HTCondorCE.html\n\n\nTWISTY_OPTS_OUTPUT\n showlink=\"Click to expand full job route\u2026\"\n\n\n###############################################################################\n\n\n#\n\n\n# HTCondor-CE HTCondor batch system configuration file.\n\n\n#\n\n\n###############################################################################\n\n\n\n# Submit the job to the site Condor\n\n\n\nJOB_ROUTER_ENTRIES\n \n=\n \n\\\n\n   \n[\n \n\\\n\n     \nGridResource\n \n=\n \ncondor localhost localhost\n;\n \n\\\n\n     \neval_set_GridResource\n \n=\n strcat\n(\ncondor \n, \n$(\nFULL_HOSTNAME\n)\n, \n$(\nFULL_HOSTNAME\n)\n)\n;\n \n\\\n\n     \nTargetUniverse\n \n=\n \n5\n;\n \n\\\n\n     \nname\n \n=\n \nBNL_Condor_Pool_long\n;\n \n\\\n\n     \nRequirements\n \n=\n target.queue\n==\nanalysis.long\n;\n \n\\\n\n     \neval_set_RACF_Group\n \n=\n \nlong\n;\n \n\\\n\n     \nset_Experiment\n \n=\n \natlas\n;\n \n\\\n\n     \nset_requirements\n \n=\n \n(\n \n(\n \nArch\n \n==\n \nINTEL\n \n||\n \nArch\n \n==\n \nX86_64\n \n)\n \n \n(\n \nCPU_Experiment\n \n==\n \natlas\n \n)\n \n)\n \n \n(\n TARGET.OpSys \n==\n \nLINUX\n \n)\n \n \n(\n TARGET.Disk \n=\n RequestDisk \n)\n \n \n(\n TARGET.Memory \n=\n RequestMemory \n)\n \n \n(\n TARGET.HasFileTransfer \n)\n;\n \n\\\n\n     \nset_Job_Type\n \n=\n \ncas\n;\n \n\\\n\n     \nset_JobLeaseDuration\n \n=\n \n3600\n;\n \n\\\n\n     \nset_Periodic_Hold\n \n=\n \n(\nNumJobStarts \n=\n \n1\n \n \nJobStatus\n \n==\n \n1\n)\n \n||\n NumJobStarts \n \n1\n;\n \n\\\n\n     \neval_set_VO\n \n=\n x509UserProxyVOName\n;\n \n\\\n\n   \n]\n \n\\\n\n   \n[\n \n\\\n\n     \nGridResource\n \n=\n \ncondor localhost localhost\n;\n \n\\\n\n     \neval_set_GridResource\n \n=\n strcat\n(\ncondor \n, \n$(\nFULL_HOSTNAME\n)\n, \n$(\nFULL_HOSTNAME\n)\n)\n;\n \n\\\n\n     \nTargetUniverse\n \n=\n \n5\n;\n \n\\\n\n     \nname\n \n=\n \nBNL_Condor_Pool_short\n;\n \n\\\n\n     \nRequirements\n \n=\n target.queue\n==\nanalysis.short\n;\n \n\\\n\n     \neval_set_RACF_Group\n \n=\n \nshort\n;\n \n\\\n\n     \nset_Experiment\n \n=\n \natlas\n;\n \n\\\n\n     \nset_requirements\n \n=\n \n(\n \n(\n \nArch\n \n==\n \nINTEL\n \n||\n \nArch\n \n==\n \nX86_64\n \n)\n \n \n(\n \nCPU_Experiment\n \n==\n \natlas\n \n)\n \n)\n \n \n(\n TARGET.OpSys \n==\n \nLINUX\n \n)\n \n \n(\n TARGET.Disk \n=\n RequestDisk \n)\n \n \n(\n TARGET.Memory \n=\n RequestMemory \n)\n \n \n(\n TARGET.HasFileTransfer \n)\n;\n \n\\\n\n     \nset_Job_Type\n \n=\n \ncas\n;\n \n\\\n\n     \nset_JobLeaseDuration\n \n=\n \n3600\n;\n \n\\\n\n     \nset_Periodic_Hold\n \n=\n \n(\nNumJobStarts \n=\n \n1\n \n \nJobStatus\n \n==\n \n1\n)\n \n||\n NumJobStarts \n \n1\n;\n \n\\\n\n     \neval_set_VO\n \n=\n x509UserProxyVOName\n;\n \n\\\n\n   \n]\n \n\\\n\n   \n[\n \n\\\n\n     \nGridResource\n \n=\n \ncondor localhost localhost\n;\n \n\\\n\n     \neval_set_GridResource\n \n=\n strcat\n(\ncondor \n, \n$(\nFULL_HOSTNAME\n)\n, \n$(\nFULL_HOSTNAME\n)\n)\n;\n \n\\\n\n     \nTargetUniverse\n \n=\n \n5\n;\n \n\\\n\n     \nname\n \n=\n \nBNL_Condor_Pool_grid\n;\n \n\\\n\n     \nRequirements\n \n=\n target.queue\n==\ngrid\n;\n \n\\\n\n     \neval_set_RACF_Group\n \n=\n \ngrid\n;\n \n\\\n\n     \nset_Experiment\n \n=\n \natlas\n;\n \n\\\n\n     \nset_requirements\n \n=\n \n(\n \n(\n \nArch\n \n==\n \nINTEL\n \n||\n \nArch\n \n==\n \nX86_64\n \n)\n \n \n(\n \nCPU_Experiment\n \n==\n \natlas\n \n)\n \n)\n \n \n(\n TARGET.OpSys \n==\n \nLINUX\n \n)\n \n \n(\n TARGET.Disk \n=\n RequestDisk \n)\n \n \n(\n TARGET.Memory \n=\n RequestMemory \n)\n \n \n(\n TARGET.HasFileTransfer \n)\n;\n \n\\\n\n     \nset_Job_Type\n \n=\n \ncas\n;\n \n\\\n\n     \nset_JobLeaseDuration\n \n=\n \n3600\n;\n \n\\\n\n     \nset_Periodic_Hold\n \n=\n \n(\nNumJobStarts \n=\n \n1\n \n \nJobStatus\n \n==\n \n1\n)\n \n||\n NumJobStarts \n \n1\n;\n \n\\\n\n     \neval_set_VO\n \n=\n x509UserProxyVOName\n;\n \n\\\n\n   \n]\n \n\\\n\n   \n[\n \n\\\n\n     \nGridResource\n \n=\n \ncondor localhost localhost\n;\n \n\\\n\n     \neval_set_GridResource\n \n=\n strcat\n(\ncondor \n, \n$(\nFULL_HOSTNAME\n)\n, \n$(\nFULL_HOSTNAME\n)\n)\n;\n \n\\\n\n     \nTargetUniverse\n \n=\n \n5\n;\n \n\\\n\n     \nname\n \n=\n \nBNL_Condor_Pool\n;\n \n\\\n\n     \nRequirements\n \n=\n target.queue is undefined\n;\n \n\\\n\n     \neval_set_RACF_Group\n \n=\n \ngrid\n;\n \n\\\n\n     \nset_requirements\n \n=\n \n(\n \n(\n \nArch\n \n==\n \nINTEL\n \n||\n \nArch\n \n==\n \nX86_64\n \n)\n \n \n(\n \nCPU_Experiment\n \n==\n \nrcf\n \n)\n \n)\n \n \n(\n TARGET.OpSys \n==\n \nLINUX\n \n)\n \n \n(\n TARGET.Disk \n=\n RequestDisk \n)\n \n \n(\n TARGET.Memory \n=\n RequestMemory \n)\n \n \n(\n TARGET.HasFileTransfer \n)\n;\n \n\\\n\n     \nset_Experiment\n \n=\n \natlas\n;\n \n\\\n\n     \nset_Job_Type\n \n=\n \ncas\n;\n \n\\\n\n     \nset_JobLeaseDuration\n \n=\n \n3600\n;\n \n\\\n\n     \nset_Periodic_Hold\n \n=\n \n(\nNumJobStarts \n=\n \n1\n \n \nJobStatus\n \n==\n \n1\n)\n \n||\n NumJobStarts \n \n1\n;\n \n\\\n\n     \neval_set_VO\n \n=\n x509UserProxyVOName\n;\n \n\\\n\n   \n]\n\n\n\n\n\n\n\n\nReference\n\n\nHere are some other HTCondor-CE documents that might be helpful:\n\n\n\n\nHTCondor-CE overview and architecture\n\n\nInstalling HTCondor-CE\n\n\nThe HTCondor-CE troubleshooting guide\n\n\nSubmitting Jobs to HTCondor-CE", 
            "title": "Job Router Recipe"
        }, 
        {
            "location": "/compute-element/job_router/#writing-routes-for-htcondor-ce", 
            "text": "", 
            "title": "Writing Routes For HTCondor-CE"
        }, 
        {
            "location": "/compute-element/job_router/#about-this-guide", 
            "text": "The  JobRouter  is at the heart of HTCondor-CE and allows admins to transform and direct jobs to specific batch systems. Customizations are made in the form of job routes where each route corresponds to a separate job transformation: If an incoming job matches a job route\u2018s requirements, the route creates a transformed job (referred to as the \u2019routed job\u2019) that is then submitted to the batch system. The CE package comes with default routes located in  /etc/condor-ce/config.d/02-ce-*.conf  that provide enough basic functionality for a small site.  If you have needs beyond delegating all incoming jobs to your batch system as they are, this document provides examples of common job routes and job route problems.  RoutePitfalls", 
            "title": "About This Guide"
        }, 
        {
            "location": "/compute-element/job_router/#quirks-and-pitfalls", 
            "text": "The JobRouter matches jobs to routes in a round-robin fashion. This means that if a job can match to multiple routes, it can be routed by any of them! So when writing job routes, make sure that they are exclusive to each other and that your jobs can only match to a single route.  If a value is set in  JOB_ROUTER_DEFAULTS  with  eval_set_ variable , override it by using  eval_set_ variable  in the  JOB_ROUTER_ENTRIES . Do this at your own risk as it may cause the CE to break.  Make sure to run  condor_ce_reconfig  after changing your routes, otherwise they will not take effect.  Before the last square bracket, make sure all lines end in a line continuation character (backslash). You can inspect the syntax of your routes with  condor_ce_config_val JOB_ROUTER_ENTRIES  to see if HTCondor-CE has ingested them properly.  Do  not  set the  JOB_ROUTER_DEFAULTS  configuration variable yourself. This will cause the CE to stop functioning.  Do  not  set the job environment through the JobRouter. Instead, add any changes to the /etc/osg/config.d/  [Local Settings]  section and run osg-configure, as documented  here .  HTCondor batch system only: Local universe jobs are excluded from any routing.    #JobRouteConstruction", 
            "title": "Quirks and Pitfalls"
        }, 
        {
            "location": "/compute-element/job_router/#how-job-routes-are-constructed", 
            "text": "Each job route\u2019s  ClassAd  is constructed by combining each entry from the  JOB_ROUTER_ENTRIES  with the  JOB_ROUTER_DEFAULTS . Attributes that are set in  JOB_ROUTER_ENTRIES  will override those set in  JOB_ROUTER_DEFAULTS", 
            "title": "How Job Routes are Constructed"
        }, 
        {
            "location": "/compute-element/job_router/#job95router95entries", 
            "text": "JOB_ROUTER_ENTRIES  is a configuration variable whose default is set in  /etc/condor-ce/config.d/02-ce-*.conf  but may be overriden by the administrator in  /etc/condor-ce/config.d/99-local.conf . This document outlines the many changes you can make to  JOB_ROUTER_ENTRIES  to fit your site\u2019s needs.  #JobRouterDefaults", 
            "title": "JOB_ROUTER_ENTRIES"
        }, 
        {
            "location": "/compute-element/job_router/#job95router95defaults", 
            "text": "JOB_ROUTER_DEFAULTS  is a python-generated configuration variable that sets default job route values that are required for the HTCondor-CE\u2019s functionality. To view its contents, run the following command:  UCL_PROMPT  condor_ce_config_val JOB_ROUTER_DEFAULTS | sed  s/;/;\\n/g   TWISTY_OPTS_OUTPUT  showlink=\"Show sample output\"  [   MaxIdleJobs  =   2000 ; \n  MaxJobs  =   10000 ; \n  /* by default, accept all jobs */   Requirements  =   True ; \n  /* now modify routed job attributes */   /* remove routed job if the client disappears for 48 hours or it is idle for 6 */   /*set_PeriodicRemove = (LastClientContact - time()   48*60*60) || (JobStatus == 1   (time() - QDate)   6*60);  */   delete_PeriodicRemove  =   true ; \n  delete_CondorCE  =   true ; \n  set_RoutedJob  =   true ; \n  copy_environment  =   orig_environment ; \n  set_osg_environment  =   OSG_GRID= /etc/osg/wn-client/  OSG_SQUID_LOCATION= fermicloud133.fnal.gov:3128  OSG_SITE_READ= None  OSG_APP= /share/osg/app  OSG_GLEXEC_LOCATION= None  OSG_DATA= UNAVAILABLE  OSG_HOSTNAME= fermicloud136.fnal.gov  OSG_STORAGE_ELEMENT= False  OSG_SITE_NAME= herp  GLOBUS_LOCATION= /usr  OSG_WN_TMP= None  OSG_DEFAULT_SE= None  OSG_SITE_WRITE= None ; \n  eval_set_environment  =   debug ( strcat ( HOME= ,   userHome ( Owner ,   / ),     ,   ifThenElse ( orig_environment   is   undefined ,   osg_environment ,   strcat ( osg_environment ,     ,   orig_environment )   ))); \n  /* Set new requirements */   /* set_requirements = LastClientContact - time()   30*60;   */   set_requirements  =   True ; \n  set_InputRSL  =   ifThenElse ( GlobusRSL   is   null ,   [ ] ,   eval_rsl ( GlobusRSL )); \n  /* Note default memory request of 2GB */   /* Note yet another nested condition allow pass attributes (maxMemory,xcount,jobtype,queue) via gWMS Factory described within ClassAd if undefined via RSL */   eval_set_RequestMemory   =   ifThenElse ( InputRSL . maxMemory   isnt   null ,   InputRSL . maxMemory ,   ifThenElse ( maxMemory   isnt   null ,   maxMemory ,   ifThenElse ( default_maxMemory   isnt   null ,   default_maxMemory ,   2000 ))); \n  eval_set_remote_queue   =   ifThenElse ( InputRSL . queue   isnt   null ,   InputRSL . queue ,   ifThenElse ( queue   isnt   null ,   queue ,   ifThenElse ( default_queue   isnt   null ,   default_queue ,   ))); \n  /* HTCondor uses RequestCpus;   blahp uses SMPGranularity and NodeNumber.  Default is 1 core. */   eval_set_RequestCpus   =   ifThenElse ( InputRSL . xcount   isnt   null ,   InputRSL . xcount ,   ifThenElse ( xcount   isnt   null ,   xcount ,   ifThenElse ( default_xcount   isnt   null ,   default_xcount ,   1 ))); \n  eval_set_remote_SMPGranularity   =   ifThenElse ( InputRSL . xcount   isnt   null ,   InputRSL . xcount ,   ifThenElse ( xcount   isnt   null ,   xcount ,   ifThenElse ( default_xcount   isnt   null ,   default_xcount ,   1 ))); \n  eval_set_remote_NodeNumber   =   ifThenElse ( InputRSL . xcount   isnt   null ,   InputRSL . xcount ,   ifThenElse ( xcount   isnt   null ,   xcount ,   ifThenElse ( default_xcount   isnt   null ,   default_xcount ,   1 ))); \n  /* If remote_cerequirements is a string, BLAH will parse it as an expression before examining it */   eval_set_remote_cerequirements   =   ifThenElse ( InputRSL . maxWalTlime   isnt   null ,   strcat ( Walltime ==  ,   string ( 60 * InputRSL . maxWallTime ),      CondorCE == 1 ),   ifThenElse ( maxWallTime   isnt   null ,   strcat ( Walltime ==  ,   string ( 60 * maxWallTime ),      CondorCE == 1 ),   ifThenElse ( default_maxWallTime   isnt   null ,   strcat ( Walltime ==  ,   string ( 60 * default_maxWallTime ),      CondorCE == 1 ),   CondorCE == 1 ))); \n  ]     If a value is set in  JOB_ROUTER_DEFAULTS  with  eval_set_ variable , override it by using  eval_set_ variable  in the  JOB_ROUTER_ENTRIES . Do this at your own risk as it may cause the CE to break.   Do  not  set the  JOB_ROUTER_DEFAULTS  configuration variable yourself. This will cause the CE to stop functioning.", 
            "title": "JOB_ROUTER_DEFAULTS"
        }, 
        {
            "location": "/compute-element/job_router/#generic-routes", 
            "text": "New routes should be placed in  /etc/condor-ce/config.d/99-local.conf , not the original  02-ce-*.conf .", 
            "title": "Generic Routes"
        }, 
        {
            "location": "/compute-element/job_router/#required-fields", 
            "text": "The minimum requirements for a route are that you specify the type of batch system that jobs should be routed to and a name for each route. Default routes can be found in  /usr/share/condor-ce/config.d/02-ce- batch system -defaults.conf , provided by the  osg-ce- batch system  packages.", 
            "title": "Required fields"
        }, 
        {
            "location": "/compute-element/job_router/#batch-system", 
            "text": "Each route needs to indicate the type of batch system that jobs should be routed to. For HTCondor batch systems, the  TargetUniverse  attribute needs to be set to  5  or  \"vanilla\" . For all other batch systems, the  TargetUniverse  attribute needs to be set to  9  or  \"grid\"  and the  GridResource  attribute needs to be set to  \"batch  batch system \"  (where  batch system  can be one of  pbs  (for both users of  pbs  and  SLURM ),  lsf , or  sge ).  JOB_ROUTER_ENTRIES = [ \\\n      span   style= background-color: #FFCCFF; b # Route to an HTCondor-CE batch system \\ /b /span \n      span   style= background-color: #FFCCFF; b TargetUniverse = 5; \\ /b /span \n     name =  Route jobs to HTCondor ; \\\n] \\\n[ \\\n      span   style= background-color: #FFCCFF; b # Route to a PBS batch system \\ /b /span \n      span   style= background-color: #FFCCFF; b GridResource =  batch pbs ; \\ /b /span \n      span   style= background-color: #FFCCFF; b TargetUniverse = 9; \\ /b /span \n     name =  Route jobs to PBS ; \\\n]", 
            "title": "Batch system"
        }, 
        {
            "location": "/compute-element/job_router/#route-name", 
            "text": "To identify routes, you will need to assign a name to the route with the  name  attribute:  JOB_ROUTER_ENTRIES = [ \\\n     TargetUniverse = 5; \\\n      span   style= background-color: #FFCCFF; b name =  Route jobs to HTCondor ; \\ /b /span \n]  The name of the route will be useful in debugging since it shows up in the output of  condor_ce_job_router_info , the  JobRouterLog , and in the ClassAd of the routed job, which can be viewed with  condor_ce_q  or  condor_ce_history .", 
            "title": "Route name"
        }, 
        {
            "location": "/compute-element/job_router/#writing-multiple-routes", 
            "text": "If your batch system needs incoming jobs to be sorted (e.g. if different VO\u2019s need to go to separate queues), you will need to write multiple job routes. Each route is enclosed by square brackets and unless they\u2019re the last closing bracket, they need to be followed by the line continuation character. The following routes takes incoming jobs that have a  queue  attribute set to  \"analy\"  and routes them to the site\u2019s HTCondor batch system. Any other jobs will be sent to that site\u2019s PBS batch system.   The JobRouter matches jobs to routes in a round-robin fashion. This means that if a job can match to multiple routes, it can be routed by any of them! So when writing job routes, make sure that they are exclusive to each other and that your jobs can only match to a single route.  JOB_ROUTER_ENTRIES =  span   style= background-color: #FFCCFF; b [ \\ /b /span \n     TargetUniverse = 5; \\\n     name =  Route jobs to HTCondor ; \\\n     Requirements = (TARGET.queue =?=  analy ); \\ span   style= background-color: #FFCCFF; b ] \\ /b /span  span   style= background-color: #FFCCFF; b [ \\ /b /span \n     GridResource =  batch pbs ; \\\n     TargetUniverse = 9; \\\n     name =  Route jobs to PBS ; \\\n     Requirements = (TARGET.queue =!=  analy ); \\ span   style= background-color: #FFCCFF; b ] /b /span", 
            "title": "Writing multiple routes"
        }, 
        {
            "location": "/compute-element/job_router/#writing-comments", 
            "text": "To write comments you can use C-style comments, text enclosed by  /* */ . If the comment is at the end of a line, it still has to be followed by the line continuation character.  JOB_ROUTER_ENTRIES = [ \\\n     TargetUniverse = 5; \\\n     name =  C-style comments ; \\\n      span   style= background-color: #FFCCFF; b /* This is a comment */ \\ /b /span \n]   For  condor_ce_version  8.2.x or greater, you can also use  #  to comment out single lines:  JOB_ROUTER_ENTRIES = [ \\\n     TargetUniverse = 5; \\\n     name =  Hash comments ; \\\n      span   style= background-color: #FFCCFF; b # BrokenAttribute =  commented out ; \\ /b /span  \n]", 
            "title": "Writing comments"
        }, 
        {
            "location": "/compute-element/job_router/#setting-attributes-for-all-routes", 
            "text": "To set an attribute that will be applied to all routes, you will need to use the  [[#SettingAttributes][set_]]  function for each route.   Do  not  try to do this by setting the  JOB_ROUTER_DEFAULTS  configuration variable, as this will cause the CE to stop functioning.  The following routes set the  Periodic_Hold  attribute for both routes:  JOB_ROUTER_ENTRIES = [ \\\n     TargetUniverse = 5; \\\n     name =  Route jobs to HTCondor ; \\\n     Requirements = (TARGET.queue =?=  analy ); \\\n      span   style= background-color: #FFCCFF; b /* Puts the routed job on hold if the job s been idle and has been started at least once or if the job has tried to start more than once */ \\  /b /span \n      span   style= background-color: #FFCCFF; b set_Periodic_Hold = (NumJobStarts  = 1   JobStatus == 1) || NumJobStarts   1; \\ /b /span \n] \\\n[ \\\n     GridResource =  batch pbs ; \\\n     TargetUniverse = 9; \\\n     name =  Route jobs to PBS ; \\\n     Requirements = (TARGET.queue =!=  analy ); \\\n      span   style= background-color: #FFCCFF; b /* Puts the routed job on hold if the job s been idle and has been started at least once or if the job has tried to start more than once */ \\  /b /span \n      span   style= background-color: #FFCCFF; b set_Periodic_Hold = (NumJobStarts  = 1   JobStatus == 1) || NumJobStarts   1; \\ /b /span \n]", 
            "title": "Setting attributes for all routes"
        }, 
        {
            "location": "/compute-element/job_router/#filtering-jobs-based-on", 
            "text": "To filter jobs, use the  Requirements  attribute. Jobs will evaluate against the ClassAd expression set in the  Requirements  and if the expression evaluates to  TRUE , the route will match. More information on the syntax of ClassAd's can be found in the  HTCondor manual . For an example on how incoming jobs interact with filtering in job routes, consult  this document .  When setting requirements, you need to prefix job attributes that you are filtering with  TARGET.  so that the job route knows to compare the attribute of the incoming job rather than the route\u2019s own attribute. For example, if an incoming job has a =queue = \u201canaly\u201d= attribute, then the following job route will not match:  JOB_ROUTER_ENTRIES = [ \\\n     TargetUniverse = 5; \\\n     name =  Filtering by queue ; \\\n     queue =  not-analy ; \\\n      span   style= background-color: #FFCCFF; b Requirements = (TARGET.queue =?=  analy ); \\ /b /span \n]   This is because when evaluating the route requirement, the job route will compare its own  queue  attribute to \u201canaly\u201d and see that it does not match. You can read more about comparing two ClassAds in the  HTCondor manual .   If you have an HTCondor batch system, note the difference with  set_requirements .   The JobRouter matches jobs to routes in a round-robin fashion. This means that if a job can match to multiple routes, it can be routed by any of them! So when writing job routes, make sure that they are exclusive to each other and that your jobs can only match to a single route.  #GlideIn", 
            "title": "Filtering jobs based on\u2026"
        }, 
        {
            "location": "/compute-element/job_router/#glidein-queue", 
            "text": "To filter jobs based on their glidein queue attribute, your routes will need a  Requirements  expression using the incoming job\u2019s  queue  attribute. The following entry routes jobs to the PBS queue if the incoming job (specified by  TARGET ) is an  analy  (Analysis) glidein:  JOB_ROUTER_ENTRIES = [ \\\n     TargetUniverse = 5; \\\n     name =  Filtering by queue ; \\\n      span   style= background-color: #FFCCFF; b Requirements = (TARGET.queue =?=  analy ); \\ /b /span \n]", 
            "title": "Glidein queue"
        }, 
        {
            "location": "/compute-element/job_router/#job-submitter", 
            "text": "To filter jobs based on who submitted it, your routes will need a  Requirements  expression using the incoming job\u2019s  Owner  attribute. The following entry routes jobs to the HTCondor batch system iff the submitter is  usatlas2 :  JOB_ROUTER_ENTRIES = [ \\\n     TargetUniverse = 5; \\\n     name =  Filtering by job submitter ; \\\n      span   style= background-color: #FFCCFF; b Requirements = (TARGET.Owner =?=  usatlas2 ); \\ /b /span \n]   Alternatively, you can match based on regular expression. The following entry routes jobs to the PBS batch system iff the submitter\u2019s name begins with  usatlas :  JOB_ROUTER_ENTRIES = [ \\\n     GridResource =  batch pbs ; \\\n     TargetUniverse = 9; \\\n     name =  Filtering by job submitter (regular expression) ; \\\n      span   style= background-color: #FFCCFF; b Requirements = regexp( ^usatlas , TARGET.Owner); \\ /b /span \n]", 
            "title": "Job submitter"
        }, 
        {
            "location": "/compute-element/job_router/#voms-attribute", 
            "text": "To filter jobs based on the subject of the job\u2019s proxy, your routes will need a  Requirements  expression using the incoming job\u2019s  x509UserProxyFirstFQAN  attribute. The following entry routes jobs to the PBS batch system if the proxy subject contains  /cms/Role=Pilot :  JOB_ROUTER_ENTRIES = [ \\\n     GridResource =  batch pbs ; \\\n     TargetUniverse = 9; \\\n     name =  Filtering by VOMS attribute (regex) ; \\\n      span   style= background-color: #FFCCFF; b Requirements = regexp( \\/cms\\/Role\\=pilot , TARGET.x509UserProxyFirstFQAN); \\ /b /span \n]", 
            "title": "VOMS attribute"
        }, 
        {
            "location": "/compute-element/job_router/#setting-a-default", 
            "text": "This section outlines how to set default job limits, memory, cores, queue, and maximum walltime. For an example on how users can override these defaults, consult  this document .", 
            "title": "Setting a default\u2026"
        }, 
        {
            "location": "/compute-element/job_router/#maximum-number-of-jobs", 
            "text": "To set a default limit to the maximum number of jobs per route, you can edit the configuration variable  CONDORCE_MAX_JOBS  in  /etc/condor-ce/config.d/01-ce-router.conf :  span   style= background-color: #FFCCFF; b CONDORCE_MAX_JOBS = 10000 /b /span   Note that this is to be placed directly into the HTCondor-CE configuration, not into a job route.", 
            "title": "Maximum number of jobs"
        }, 
        {
            "location": "/compute-element/job_router/#maximum-memory", 
            "text": "To set a default maximum memory for routed jobs, set the attribute  default_maxMemory :  JOB_ROUTER_ENTRIES = [ \\\n     GridResource =  batch pbs ; \\\n     TargetUniverse = 9; \\\n     name =  Request memory ; \\\n     /* Set the requested memory to 1 GB */ \\\n      span   style= background-color: #FFCCFF; b set_default_maxMemory = 1000; \\ /b /span \n]", 
            "title": "Maximum memory"
        }, 
        {
            "location": "/compute-element/job_router/#number-of-cores-to-request", 
            "text": "To set a default number of cores for routed jobs, set the attribute  default_xcount :  JOB_ROUTER_ENTRIES = [ \\\n     GridResource =  batch pbs ; \\\n     TargetUniverse = 9; \\\n     name =  Request CPU ; \\\n     /* Set the requested cores to 8 */ \\\n      span   style= background-color: #FFCCFF; b set_default_xcount = 8; \\ /b /span \n]", 
            "title": "Number of cores to request"
        }, 
        {
            "location": "/compute-element/job_router/#maximum-walltime", 
            "text": "To set a default maximum walltime (in minutes) for routed jobs, set the attribute  default_maxWallTime :  JOB_ROUTER_ENTRIES = [ \\\n     GridResource =  batch pbs ; \\\n     TargetUniverse = 9; \\\n     name =  Setting WallTime ; \\\n     /* Set the max walltime to 1 hr */ \\\n      span   style= background-color: #FFCCFF; b set_default_maxWallTime = 60; \\ /b /span \n]", 
            "title": "Maximum walltime"
        }, 
        {
            "location": "/compute-element/job_router/#editing-attributes", 
            "text": "The following functions are operations that affect job attributes and are evaluated in the following order:   copy_*  delete_*  set_*  eval_set_*   After each job route\u2019s ClassAd is  constructed , the above operations are evaluated in order. For example, if the attribute  foo  is set using  eval_set_foo  in the  JOB_ROUTER_DEFAULTS , you\u2018ll be unable to use  delete_foo  to remote it from your jobs since the attribute is set using  eval_set_foo  after the deletion occurs according to the order of operations. To get around this, we can take advantage of the fact that operations defined in  JOB_ROUTER_DEFAULTS  get overriden by the same operation in  JOB_ROUTER_ENTRIES . So to \u2019delete\u2019  foo , we would add =eval_set_foo = \u201c\u201d= to the route in the  JOB_ROUTER_ENTRIES , resulting in  foo  being absent from the routed job.  More documentation can be found in the  HTCondor manual .", 
            "title": "Editing attributes\u2026"
        }, 
        {
            "location": "/compute-element/job_router/#copying-attributes", 
            "text": "To copy the value of an attribute of the incoming job to an attribute of the routed job, use  copy_ . The following route copies the  environment  attribute of the incoming job and sets the attribute  Original_Environment  on the routed job to the same value:  JOB_ROUTER_ENTRIES = [ \\\n     GridResource =  batch pbs ; \\\n     TargetUniverse = 9; \\\n     name =  Copying attributes ; \\\n      span   style= background-color: #FFCCFF; b copy_environment =  Original_Environment ; \\ /b /span \n]", 
            "title": "Copying attributes"
        }, 
        {
            "location": "/compute-element/job_router/#removing-attributes", 
            "text": "To remove an attribute of the incoming job from the routed job, use  delete_ . The following route removes the  environment  attribute from the routed job:  JOB_ROUTER_ENTRIES = [ \\\n     GridResource =  batch pbs ; \\\n     TargetUniverse = 9; \\\n     name =  Copying attributes ; \\\n      span   style= background-color: #FFCCFF; b delete_environment = True; \\ /b /span \n]   #SettingAttributes", 
            "title": "Removing attributes"
        }, 
        {
            "location": "/compute-element/job_router/#setting-attributes", 
            "text": "To set an attribute on the routed job, use  set_ . The following route sets the Job\u2019s  Rank  attribute to 5:  JOB_ROUTER_ENTRIES = [ \\\n     GridResource =  batch pbs ; \\\n     TargetUniverse = 9; \\\n     name =  Setting an attribute ; \\\n      span   style= background-color: #FFCCFF; b set_Rank = 5; \\ /b /span \n]", 
            "title": "Setting attributes"
        }, 
        {
            "location": "/compute-element/job_router/#setting-attributes-with-classad-expressions", 
            "text": "To set an attribute to a ClassAd expression to be evaluated, use  set_eval . The following route sets the  Experiment  attribute to  atlas.osguser  if the Owner of the incoming job is  osguser :   If a value is set in JOB_ROUTER_DEFAULTS with  eval_set_ variable , override it by using  eval_set_ variable  in the  JOB_ROUTER_ENTRIES .  JOB_ROUTER_ENTRIES = [ \\\n     GridResource =  batch pbs ; \\\n     TargetUniverse = 9; \\\n     name =  Setting an attribute with a !ClassAd expression ; \\\n      span   style= background-color: #FFCCFF; b eval_set_Experiment = strcat( atlas. , Owner); \\ /b /span \n]", 
            "title": "Setting attributes with ClassAd expressions"
        }, 
        {
            "location": "/compute-element/job_router/#limiting-the-number-of", 
            "text": "This section outlines how to limit the number of total or idle jobs in a specific route (i.e., if this limit is reached, jobs will no longer be placed in this route).   If you are using an HTCondor batch system, limiting the number of jobs is not the preferred solution: HTCondor manages fair share on its own via  user priorities and group accounting .", 
            "title": "Limiting the number of\u2026"
        }, 
        {
            "location": "/compute-element/job_router/#total-jobs", 
            "text": "To set a limit on the number of jobs for a specific route, set the  MaxJobs  attribute:  JOB_ROUTER_ENTRIES = [ \\\n     GridResource =  batch pbs ; \\\n     TargetUniverse = 9; \\\n     name =  Limit the total number of jobs to 100 ; \\\n      span   style= background-color: #FFCCFF; b MaxJobs = 100; \\ /b /span \n] \\\n[ \\\n     GridResource =  batch pbs ; \\\n     TargetUniverse = 9; \\\n     name =  Limit the total number of jobs to 75 ; \\\n      span   style= background-color: #FFCCFF; b MaxJobs = 75; \\ /b /span \n]", 
            "title": "Total jobs"
        }, 
        {
            "location": "/compute-element/job_router/#idle-jobs", 
            "text": "To set a limit on the number of idle jobs for a specific route, set the  MaxIdleJobs  attribute:  JOB_ROUTER_ENTRIES = [ \\\n     TargetUniverse = 5; \\\n     name =  Limit the total number of idle jobs to 100 ; \\\n      span   style= background-color: #FFCCFF; b MaxIdleJobs = 100; \\ /b /span \n] \\\n[ \\\n     TargetUniverse = 5; \\\n     name =  Limit the total number of idle jobs to 75 ; \\\n      span   style= background-color: #FFCCFF; b MaxIdleJobs = 75; \\ /b /span \n]  DebugRoutes", 
            "title": "Idle jobs"
        }, 
        {
            "location": "/compute-element/job_router/#debugging-routes", 
            "text": "To help debug expressions in your routes, you can use the  debug()  function. First, set the debug mode for the JobRouter by editing a file in  /etc/condor-ce/config.d/  to read  JOB_ROUTER_DEBUG = D_FULLDEBUG  Then wrap the problematic attribute in  debug() :  JOB_ROUTER_ENTRIES = [ \\\n     GridResource =  batch pbs ; \\\n     TargetUniverse = 9; \\\n     name =  Debugging a difficult !ClassAd expression ; \\\n      span   style= background-color: #FFCCFF; b eval_set_Experiment = debug(strcat( atlas , Name)); \\ /b /span \n]    You will find the debugging output in  /var/log/condor-ce/JobRouterLog .", 
            "title": "Debugging routes"
        }, 
        {
            "location": "/compute-element/job_router/#routes-for-htcondor-batch-systems", 
            "text": "", 
            "title": "Routes for HTCondor Batch Systems"
        }, 
        {
            "location": "/compute-element/job_router/#setting-periodic-hold-release-or-remove", 
            "text": "To release, remove or put a job on hold if it meets certain criteria, use the  PERIODIC_*  family of attributes. By default, periodic expressions are evaluated once every 300 seconds but this can be changed by setting PERIODIC_EXPR_INTERVAL in your CE\u2019s configuration.  JOB_ROUTER_ENTRIES = [ \\\n     TargetUniverse = 5; \\\n     name =  Setting periodic statements ; \\\n      span   style= background-color: #FFCCFF; b /* Puts the routed job on hold if the job s been idle and has been started at least once or if the job has tried to start more than once */ \\ /b /span \n      span   style= background-color: #FFCCFF; b set_Periodic_Hold = (NumJobStarts  = 1   JobStatus == 1) || NumJobStarts   1; \\ /b /span \n      span   style= background-color: #FFCCFF; b /* Remove routed jobs if their walltime is longer than 3 days and 5 minutes */ \\ /b /span \n      span   style= background-color: #FFCCFF; b set_Periodic_Remove = ( RemoteWallClockTime   (3*24*60*60 + 5*60) ); \\ /b /span \n      span   style= background-color: #FFCCFF; b /* Release routed jobs if the condor_starter couldn t start the executable and  VMGAHP_ERR_INTERNAL  is in the HoldReason */ \\ /b /span \n      span   style= background-color: #FFCCFF; b set_Periodic_Release = HoldReasonCode == 6   regexp( VMGAHP_ERR_INTERNAL , HoldReason); \\ /b /span \n]   #RoutedReq", 
            "title": "Setting periodic hold, release or remove"
        }, 
        {
            "location": "/compute-element/job_router/#setting-routed-job-requirements", 
            "text": "If you need to set requirements on your routed job, you will need to use  set_Requirements  instead of  Requirements . The  Requirements  attribute filters jobs coming into your CE into different job routes whereas  set_requirements  will set conditions on the routed job that must be met by the worker node it lands on. For more information on requirements, consult the  HTCondor manual .  To ensure that your job lands on a Linux machine in your pool:  JOB_ROUTER_ENTRIES = [ \\\n     TargetUniverse = 5; \\\n      span   style= background-color: #FFCCFF; b set_Requirements =  OpSys ==  LINUX  \\ /b /span \n]", 
            "title": "Setting routed job requirements"
        }, 
        {
            "location": "/compute-element/job_router/#setting-accounting-groups", 
            "text": "To assign jobs to an HTCondor accounting group to manage fair share on your local batch system, we recommend using  UID and ExtAttr tables .", 
            "title": "Setting accounting groups"
        }, 
        {
            "location": "/compute-element/job_router/#routes-for-non-htcondor-batch-systems", 
            "text": "", 
            "title": "Routes for non-HTCondor Batch Systems"
        }, 
        {
            "location": "/compute-element/job_router/#setting-a-default-batch-queue", 
            "text": "To set a default queue for routed jobs, set the attribute  default_queue :  JOB_ROUTER_ENTRIES = [ \\\n     GridResource =  batch pbs ; \\\n     TargetUniverse = 9; \\\n     name =  Setting batch system queues ; \\\n      span   style= background-color: #FFCCFF; b set_default_queue =  osg_queue ; \\ /b /span \n]", 
            "title": "Setting a default batch queue"
        }, 
        {
            "location": "/compute-element/job_router/#setting-batch-system-directives", 
            "text": "To write batch system directives that are not supported in the route examples above, you will need to edit the job submit script for your local batch system in  /etc/blahp/  (e.g., if your local batch system is PBS, edit  /etc/blahp/pbs_local_submit_attributes.sh ). This file is sourced during submit time and anything printed to stdout is appended to the job submit script that gets submitted to your batch system. ClassAd attributes can be passed from the routed job to the local submit attributes script via the  default_remote_cerequirements  attribute, which can take the following form:  default_remote_cerequirements = foo == X   bar == Y   ...  This sets  foo  to value  X  and  bar  to  Y  in the environment of the local submit attributes script. The following example sets the maximum walltime to 1 hour and the accounting group to the  x509UserProxyFirstFQAN  attribute of the job submitted to a PBS batch system  JOB_ROUTER_ENTRIES = [ \\\n     GridResource =  batch pbs ; \\\n     TargetUniverse = 9; \\\n     name =  Setting job submit variables ; \\\n      span   style= background-color: #FFCCFF; b set_default_remote_cerequirements = strcat( Walltime == 3600   AccountingGroup == \\ , x509UserProxyFirstFQAN,  \\ ); \\ /b /span \n]   With  /etc/blahp/pbs_local_submit_attributes.sh  containing.  #!/bin/bash  echo   #PBS -l walltime= $Walltime  echo   #PBS -A  $AccountingGroup   The result is that the following will be appended to the script that gets submitted to your batch system:  #PBS -l walltime=3600\n#PBS -A  span   style= background-color: #FFCCFF; lt; CE job s x509UserProxyFirstFQAN attribute gt; /span", 
            "title": "Setting batch system directives"
        }, 
        {
            "location": "/compute-element/job_router/#example-configurations", 
            "text": "", 
            "title": "Example Configurations"
        }, 
        {
            "location": "/compute-element/job_router/#aglt2s-job-routes", 
            "text": "Atlas AGLT2 is using an HTCondor batch system. Here are some things to note about their routes.   Setting various HTCondor-specific attributes like  Rank ,  AccountingGroup ,  JobPrio  and  Periodic_Remove  (see the  HTCondor manual  for more). Some of these are site-specific like  LastandFrac ,  IdleMP8Pressure ,  localQue ,  IsAnalyJob  and  JobMemoryLimit .  There is a difference between  Requirements  and  set_requirements . The  Requirements  attribute matches jobs to specific routes while the  set_requirements  sets the  Requirements  attribute on the  routed  job, which confines which machines that the routed job can land on.   Source:  https://www.aglt2.org/wiki/bin/view/AGLT2/CondorCE#The_JobRouter_configuration_file_content  TWISTY_OPTS_OUTPUT  showlink=\"Click to expand full job route\u2026\"  JOB_ROUTER_ENTRIES   =   \\ \n/* Still to  do  on all routes, get job requirements and add them here */  \\ \n/* ***** Route no  1  ***** */  \\ \n/* ***** Analysis queue ***** */  \\ \n   [   \\ \n     GridResource   =   condor localhost localhost ;   \\ \n     eval_set_GridResource   =  strcat ( condor  ,  $( FULL_HOSTNAME ) ,    $( JOB_ROUTER_SCHEDD2_POOL ) ) ;   \\ \n     Requirements   =  target.queue == analy ;   \\ \n     Name   =   Analysis Queue ;   \\ \n     TargetUniverse   =   5 ;   \\ \n     eval_set_IdleMP8Pressure   =   $( IdleMP8Pressure ) ;   \\ \n     eval_set_LastAndFrac   =   $( LastAndFrac ) ;   \\ \n     set_requirements   =   (   (  TARGET.TotalDisk  = ? =  undefined  )   ||   (  TARGET.TotalDisk  =   21000000   )   )     (  TARGET.Arch  ==   X86_64   )     (  TARGET.OpSys  ==   LINUX   )     (  TARGET.Disk  =  RequestDisk  )     (  TARGET.Memory  =  RequestMemory  )     (  TARGET.HasFileTransfer  )     ( IfThenElse (( Owner   ==   atlasconnect   ||   Owner   ==   muoncal ) ,IfThenElse ( IdleMP8Pressure, ( TARGET.PARTITIONED  = ! =  TRUE ) ,True ) ,IfThenElse ( LastAndFrac, ( TARGET.PARTITIONED  = ! =  TRUE ) ,True ))) ;   \\ \n     eval_set_AccountingGroup   =  strcat ( group_gatekpr.prod.analy. ,Owner ) ;   \\ \n     set_localQue   =   Analysis ;   \\ \n     set_IsAnalyJob   =  True ;   \\ \n     set_JobPrio   =   5 ;   \\ \n     set_Rank   =   ( SlotID +  ( 64 -TARGET.DETECTED_CORES )) *1.0 ;   \\ \n     set_JobMemoryLimit   =   4194000 ;   \\ \n     set_Periodic_Remove   =   (   (  RemoteWallClockTime    ( 3 *24*60*60 +  5 *60 )   )   ||   ( ImageSize   JobMemoryLimit )   ) ;   \\ \n   ]   \\ \n/* ***** Route no  2  ***** */  \\ \n/* ***** splitterNT queue ***** */  \\ \n   [   \\ \n     GridResource   =   condor localhost localhost ;   \\ \n     eval_set_GridResource   =  strcat ( condor  ,  $( FULL_HOSTNAME ) ,    $( JOB_ROUTER_SCHEDD2_POOL ) ) ;   \\ \n     Requirements   =  target.queue  ==   splitterNT ;   \\ \n     Name   =   Splitter ntuple queue ;   \\ \n     TargetUniverse   =   5 ;   \\ \n     set_requirements   =   (   (  TARGET.TotalDisk  = ? =  undefined  )   ||   (  TARGET.TotalDisk  =   21000000   )   )     (  TARGET.Arch  ==   X86_64   )     (  TARGET.OpSys  ==   LINUX   )     (  TARGET.Disk  =  RequestDisk  )     (  TARGET.Memory  =  RequestMemory  )     (  TARGET.HasFileTransfer  ) ;   \\ \n     eval_set_AccountingGroup   =   group_calibrate.muoncal ;   \\ \n     set_localQue   =   Splitter ;   \\ \n     set_IsAnalyJob   =  False ;   \\ \n     set_JobPrio   =   10 ;   \\ \n     set_Rank   =   ( SlotID +  ( 64 -TARGET.DETECTED_CORES )) *1.0 ;   \\ \n     set_JobMemoryLimit   =   4194000 ;   \\ \n     set_Periodic_Remove   =   (   (  RemoteWallClockTime    ( 3 *24*60*60 +  5 *60 )   )   ||   ( ImageSize   JobMemoryLimit )   ) ;   \\ \n   ]   \\ \n/* ***** Route no  3  ***** */  \\ \n/* ***** splitter queue ***** */  \\ \n   [   \\ \n     GridResource   =   condor localhost localhost ;   \\ \n     eval_set_GridResource   =  strcat ( condor  ,  $( FULL_HOSTNAME ) ,    $( JOB_ROUTER_SCHEDD2_POOL ) ) ;   \\ \n     Requirements   =  target.queue  ==   splitter ;   \\ \n     Name   =   Splitter queue ;   \\ \n     TargetUniverse   =   5 ;   \\ \n     set_requirements   =   (   (  TARGET.TotalDisk  = ? =  undefined  )   ||   (  TARGET.TotalDisk  =   21000000   )   )     (  TARGET.Arch  ==   X86_64   )     (  TARGET.OpSys  ==   LINUX   )     (  TARGET.Disk  =  RequestDisk  )     (  TARGET.Memory  =  RequestMemory  )     (  TARGET.HasFileTransfer  ) ;   \\ \n     eval_set_AccountingGroup   =   group_calibrate.muoncal ;   \\ \n     set_localQue   =   Splitter ;   \\ \n     set_IsAnalyJob   =  False ;   \\ \n     set_JobPrio   =   15 ;   \\ \n     set_Rank   =   ( SlotID +  ( 64 -TARGET.DETECTED_CORES )) *1.0 ;   \\ \n     set_JobMemoryLimit   =   4194000 ;   \\ \n     set_Periodic_Remove   =   (   (  RemoteWallClockTime    ( 3 *24*60*60 +  5 *60 )   )   ||   ( ImageSize   JobMemoryLimit )   ) ;   \\ \n   ]   \\ \n/* ***** Route no  4  ***** */  \\ \n/* ***** xrootd queue ***** */  \\ \n   [   \\ \n     GridResource   =   condor localhost localhost ;   \\ \n     eval_set_GridResource   =  strcat ( condor  ,  $( FULL_HOSTNAME ) ,    $( JOB_ROUTER_SCHEDD2_POOL ) ) ;   \\ \n     Requirements   =  target.queue  ==   xrootd ;   \\ \n     Name   =   Xrootd queue ;   \\ \n     TargetUniverse   =   5 ;   \\ \n     set_requirements   =   (   (  TARGET.TotalDisk  = ? =  undefined  )   ||   (  TARGET.TotalDisk  =   21000000   )   )     (  TARGET.Arch  ==   X86_64   )     (  TARGET.OpSys  ==   LINUX   )     (  TARGET.Disk  =  RequestDisk  )     (  TARGET.Memory  =  RequestMemory  )     (  TARGET.HasFileTransfer  ) ;   \\ \n     eval_set_AccountingGroup   =  strcat ( group_gatekpr.prod.analy. ,Owner ) ;   \\ \n     set_localQue   =   Analysis ;   \\ \n     set_IsAnalyJob   =  True ;   \\ \n     set_JobPrio   =   35 ;   \\ \n     set_Rank   =   ( SlotID +  ( 64 -TARGET.DETECTED_CORES )) *1.0 ;   \\ \n     set_JobMemoryLimit   =   4194000 ;   \\ \n     set_Periodic_Remove   =   (   (  RemoteWallClockTime    ( 3 *24*60*60 +  5 *60 )   )   ||   ( ImageSize   JobMemoryLimit )   ) ;   \\ \n   ]   \\ \n/* ***** Route no  5  ***** */  \\ \n/* ***** Tier3Test queue ***** */  \\ \n   [   \\ \n     GridResource   =   condor localhost localhost ;   \\ \n     eval_set_GridResource   =  strcat ( condor  ,  $( FULL_HOSTNAME ) ,    $( JOB_ROUTER_SCHEDD2_POOL ) ) ;   \\ \n     Requirements   =  target.queue  ==   Tier3Test ;   \\ \n     Name   =   Tier3 Test Queue ;   \\ \n     TargetUniverse   =   5 ;   \\ \n     set_requirements   =   (   (  TARGET.TotalDisk  = ? =  undefined  )   ||   (  TARGET.TotalDisk  =   21000000   )   )     (  TARGET.Arch  ==   X86_64   )     (  TARGET.OpSys  ==   LINUX   )     (  TARGET.Disk  =  RequestDisk  )     (  TARGET.Memory  =  RequestMemory  )     (  TARGET.HasFileTransfer  )     (   IS_TIER3_TEST_QUEUE   = ? =  True  ) ;   \\ \n     eval_set_AccountingGroup   =  strcat ( group_gatekpr.prod.analy. ,Owner ) ;   \\ \n     set_localQue   =   Tier3Test ;   \\ \n     set_IsTier3TestJob   =  True ;   \\ \n     set_IsAnalyJob   =  True ;   \\ \n     set_JobPrio   =   20 ;   \\ \n     set_Rank   =   ( SlotID +  ( 64 -TARGET.DETECTED_CORES )) *1.0 ;   \\ \n     set_JobMemoryLimit   =   4194000 ;   \\ \n     set_Periodic_Remove   =   (   (  RemoteWallClockTime    ( 3 *24*60*60 +  5 *60 )   )   ||   ( ImageSize   JobMemoryLimit )   ) ;   \\ \n   ]   \\ \n/* ***** Route no  6  ***** */  \\ \n/* ***** mp8 queue ***** */  \\ \n   [   \\ \n     GridResource   =   condor localhost localhost ;   \\ \n     eval_set_GridResource   =  strcat ( condor  ,  $( FULL_HOSTNAME ) ,    $( JOB_ROUTER_SCHEDD2_POOL ) ) ;   \\ \n     Requirements   =  target.queue == mp8 ;   \\ \n     Name   =   MCORE Queue ;   \\ \n     TargetUniverse   =   5 ;   \\ \n     set_requirements   =   (   (  TARGET.TotalDisk  = ? =  undefined  )   ||   (  TARGET.TotalDisk  =   21000000   )   )     (  TARGET.Arch  ==   X86_64   )     (  TARGET.OpSys  ==   LINUX   )     (  TARGET.Disk  =  RequestDisk  )     (  TARGET.Memory  =  RequestMemory  )     (  TARGET.HasFileTransfer  )     ((  TARGET.Cpus  ==   8    TARGET.CPU_TYPE  = ? =   mp8   )   ||  TARGET.PARTITIONED  = ? =  True  ) ;   \\ \n     eval_set_AccountingGroup   =  strcat ( group_gatekpr.prod.mcore. ,Owner ) ;   \\ \n     set_localQue   =   MP8 ;   \\ \n     set_IsAnalyJob   =  False ;   \\ \n     set_JobPrio   =   25 ;   \\ \n     set_Rank   =   0 .0 ;   \\ \n     eval_set_RequestCpus   =   8 ;   \\ \n     set_JobMemoryLimit   =   33552000 ;   \\ \n     set_Slot_Type   =   mp8 ;   \\ \n     set_Periodic_Remove   =   (   (  RemoteWallClockTime    ( 3 *24*60*60 +  5 *60 )   )   ||   ( ImageSize   JobMemoryLimit )   ) ;   \\ \n   ]   \\ \n/* ***** Route no  7  ***** */  \\ \n/* ***** Installation queue, triggered by usatlas2 user ***** */  \\ \n   [   \\ \n     GridResource   =   condor localhost localhost ;   \\ \n     eval_set_GridResource   =  strcat ( condor  ,  $( FULL_HOSTNAME ) ,    $( JOB_ROUTER_SCHEDD2_POOL ) ) ;   \\ \n     Requirements   =  target.queue is undefined   target.Owner  ==   usatlas2 ;   \\ \n     Name   =   Install Queue ;   \\ \n     TargetUniverse   =   5 ;   \\ \n     set_requirements   =   (   (  TARGET.TotalDisk  = ? =  undefined  )   ||   (  TARGET.TotalDisk  =   21000000   )   )     (  TARGET.Arch  ==   X86_64   )     (  TARGET.OpSys  ==   LINUX   )     (  TARGET.Disk  =  RequestDisk  )     (  TARGET.Memory  =  RequestMemory  )     (  TARGET.HasFileTransfer  )     (  TARGET.IS_INSTALL_QUE  = ? =  True  )     ( TARGET.AGLT2_SITE  ==   UM   ) ;   \\ \n     eval_set_AccountingGroup   =  strcat ( group_gatekpr.other. ,Owner ) ;   \\ \n     set_localQue   =   Default ;   \\ \n     set_IsAnalyJob   =  False ;   \\ \n     set_IsInstallJob   =  True ;   \\ \n     set_JobPrio   =   15 ;   \\ \n     set_Rank   =   ( SlotID +  ( 64 -TARGET.DETECTED_CORES )) *1.0 ;   \\ \n     set_JobMemoryLimit   =   4194000 ;   \\ \n     set_Periodic_Remove   =   (   (  RemoteWallClockTime    ( 3 *24*60*60 +  5 *60 )   )   ||   ( ImageSize   JobMemoryLimit )   ) ;   \\ \n   ]   \\ \n/* ***** Route no  8  ***** */  \\ \n/* ***** Default queue  for  usatlas1 user ***** */  \\ \n   [   \\ \n     GridResource   =   condor localhost localhost ;   \\ \n     eval_set_GridResource   =  strcat ( condor  ,  $( FULL_HOSTNAME ) ,    $( JOB_ROUTER_SCHEDD2_POOL ) ) ;   \\ \n     Requirements   =  target.queue is undefined   regexp ( usatlas1 ,target.Owner ) ;   \\ \n     Name   =   ATLAS Production Queue ;   \\ \n     TargetUniverse   =   5 ;   \\ \n     set_requirements   =   (   (  TARGET.TotalDisk  = ? =  undefined  )   ||   (  TARGET.TotalDisk  =   21000000   )   )     (  TARGET.Arch  ==   X86_64   )     (  TARGET.OpSys  ==   LINUX   )     (  TARGET.Disk  =  RequestDisk  )     (  TARGET.Memory  =  RequestMemory  )     (  TARGET.HasFileTransfer  ) ;   \\ \n     eval_set_AccountingGroup   =  strcat ( group_gatekpr.prod.prod. ,Owner ) ;   \\ \n     set_localQue   =   Default ;   \\ \n     set_IsAnalyJob   =  False ;   \\ \n     set_Rank   =   ( SlotID +  ( 64 -TARGET.DETECTED_CORES )) *1.0 ;   \\ \n     set_JobMemoryLimit   =   4194000 ;   \\ \n     set_Periodic_Remove   =   (   (  RemoteWallClockTime    ( 3 *24*60*60 +  5 *60 )   )   ||   ( ImageSize   JobMemoryLimit )   ) ;   \\ \n   ]   \\ \n/* ***** Route no  9  ***** */  \\ \n/* ***** Default queue  for  any other usatlas account ***** */  \\ \n   [   \\ \n     GridResource   =   condor localhost localhost ;   \\ \n     eval_set_GridResource   =  strcat ( condor  ,  $( FULL_HOSTNAME ) ,    $( JOB_ROUTER_SCHEDD2_POOL ) ) ;   \\ \n     Requirements   =  target.queue is undefined    ( regexp ( usatlas2 ,target.Owner )   ||  regexp ( usatlas3 ,target.Owner )) ;   \\ \n     Name   =   Other ATLAS Production ;   \\ \n     TargetUniverse   =   5 ;   \\ \n     set_requirements   =   (   (  TARGET.TotalDisk  = ? =  undefined  )   ||   (  TARGET.TotalDisk  =   21000000   )   )     (  TARGET.Arch  ==   X86_64   )     (  TARGET.OpSys  ==   LINUX   )     (  TARGET.Disk  =  RequestDisk  )     (  TARGET.Memory  =  RequestMemory  )     (  TARGET.HasFileTransfer  ) ;   \\ \n     eval_set_AccountingGroup   =  strcat ( group_gatekpr.other. ,Owner ) ;   \\ \n     set_localQue   =   Default ;   \\ \n     set_IsAnalyJob   =  False ;   \\ \n     set_Rank   =   ( SlotID +  ( 64 -TARGET.DETECTED_CORES )) *1.0 ;   \\ \n     set_JobMemoryLimit   =   4194000 ;   \\ \n     set_Periodic_Remove   =   (   (  RemoteWallClockTime    ( 3 *24*60*60 +  5 *60 )   )   ||   ( ImageSize   JobMemoryLimit )   ) ;   \\ \n   ]   \\ \n/* ***** Route no  10  ***** */  \\ \n/* ***** Anything  else . Set queue as Default and assign to other VOs  ***** */  \\ \n   [   \\ \n     GridResource   =   condor localhost localhost ;   \\ \n     eval_set_GridResource   =  strcat ( condor  ,  $( FULL_HOSTNAME ) ,    $( JOB_ROUTER_SCHEDD2_POOL ) ) ;   \\ \n     Requirements   =  target.queue is undefined   ifThenElse ( regexp ( usatlas ,target.Owner ) ,false,true ) ;   \\ \n     Name   =   Other Jobs ;   \\ \n     TargetUniverse   =   5 ;   \\ \n     set_requirements   =   (   (  TARGET.TotalDisk  = ? =  undefined  )   ||   (  TARGET.TotalDisk  =   21000000   )   )     (  TARGET.Arch  ==   X86_64   )     (  TARGET.OpSys  ==   LINUX   )     (  TARGET.Disk  =  RequestDisk  )     (  TARGET.Memory  =  RequestMemory  )     (  TARGET.HasFileTransfer  ) ;   \\ \n     eval_set_AccountingGroup   =  strcat ( group_VOgener. ,Owner ) ;   \\ \n     set_localQue   =   Default ;   \\ \n     set_IsAnalyJob   =  False ;   \\ \n     set_Rank   =   ( SlotID +  ( 64 -TARGET.DETECTED_CORES )) *1.0 ;   \\ \n     set_JobMemoryLimit   =   4194000 ;   \\ \n     set_Periodic_Remove   =   (   (  RemoteWallClockTime    ( 3 *24*60*60 +  5 *60 )   )   ||   ( ImageSize   JobMemoryLimit )   ) ;   \\ \n   ]", 
            "title": "AGLT2\u2019s job routes"
        }, 
        {
            "location": "/compute-element/job_router/#bnls-job-routes", 
            "text": "Atlas BNL T1, they are using an HTCondor batch system. Here are some things to note about their routes:   Setting various HTCondor-specific attributes like  JobLeaseDuration ,  Requirements  and  Periodic_Hold  (see the  HTCondor manual  for more). Some of these are site-specific like  RACF_Group ,  Experiment ,  Job_Type  and  VO .  Jobs are split into different routes based on the  GlideIn  queue that they\u2019re in.  There is a difference between  Requirements  and  set_requirements . The  Requirements  attribute matches  incoming  jobs to specific routes while the  set_requirements  sets the  Requirements  attribute on the  routed  job, which confines which machines that the routed job can land on.   Source:  http://www.usatlas.bnl.gov/twiki/bin/view/Admins/HTCondorCE.html  TWISTY_OPTS_OUTPUT  showlink=\"Click to expand full job route\u2026\"  ###############################################################################  #  # HTCondor-CE HTCondor batch system configuration file.  #  ###############################################################################  # Submit the job to the site Condor  JOB_ROUTER_ENTRIES   =   \\ \n    [   \\ \n      GridResource   =   condor localhost localhost ;   \\ \n      eval_set_GridResource   =  strcat ( condor  ,  $( FULL_HOSTNAME ) ,  $( FULL_HOSTNAME ) ) ;   \\ \n      TargetUniverse   =   5 ;   \\ \n      name   =   BNL_Condor_Pool_long ;   \\ \n      Requirements   =  target.queue == analysis.long ;   \\ \n      eval_set_RACF_Group   =   long ;   \\ \n      set_Experiment   =   atlas ;   \\ \n      set_requirements   =   (   (   Arch   ==   INTEL   ||   Arch   ==   X86_64   )     (   CPU_Experiment   ==   atlas   )   )     (  TARGET.OpSys  ==   LINUX   )     (  TARGET.Disk  =  RequestDisk  )     (  TARGET.Memory  =  RequestMemory  )     (  TARGET.HasFileTransfer  ) ;   \\ \n      set_Job_Type   =   cas ;   \\ \n      set_JobLeaseDuration   =   3600 ;   \\ \n      set_Periodic_Hold   =   ( NumJobStarts  =   1     JobStatus   ==   1 )   ||  NumJobStarts    1 ;   \\ \n      eval_set_VO   =  x509UserProxyVOName ;   \\ \n    ]   \\ \n    [   \\ \n      GridResource   =   condor localhost localhost ;   \\ \n      eval_set_GridResource   =  strcat ( condor  ,  $( FULL_HOSTNAME ) ,  $( FULL_HOSTNAME ) ) ;   \\ \n      TargetUniverse   =   5 ;   \\ \n      name   =   BNL_Condor_Pool_short ;   \\ \n      Requirements   =  target.queue == analysis.short ;   \\ \n      eval_set_RACF_Group   =   short ;   \\ \n      set_Experiment   =   atlas ;   \\ \n      set_requirements   =   (   (   Arch   ==   INTEL   ||   Arch   ==   X86_64   )     (   CPU_Experiment   ==   atlas   )   )     (  TARGET.OpSys  ==   LINUX   )     (  TARGET.Disk  =  RequestDisk  )     (  TARGET.Memory  =  RequestMemory  )     (  TARGET.HasFileTransfer  ) ;   \\ \n      set_Job_Type   =   cas ;   \\ \n      set_JobLeaseDuration   =   3600 ;   \\ \n      set_Periodic_Hold   =   ( NumJobStarts  =   1     JobStatus   ==   1 )   ||  NumJobStarts    1 ;   \\ \n      eval_set_VO   =  x509UserProxyVOName ;   \\ \n    ]   \\ \n    [   \\ \n      GridResource   =   condor localhost localhost ;   \\ \n      eval_set_GridResource   =  strcat ( condor  ,  $( FULL_HOSTNAME ) ,  $( FULL_HOSTNAME ) ) ;   \\ \n      TargetUniverse   =   5 ;   \\ \n      name   =   BNL_Condor_Pool_grid ;   \\ \n      Requirements   =  target.queue == grid ;   \\ \n      eval_set_RACF_Group   =   grid ;   \\ \n      set_Experiment   =   atlas ;   \\ \n      set_requirements   =   (   (   Arch   ==   INTEL   ||   Arch   ==   X86_64   )     (   CPU_Experiment   ==   atlas   )   )     (  TARGET.OpSys  ==   LINUX   )     (  TARGET.Disk  =  RequestDisk  )     (  TARGET.Memory  =  RequestMemory  )     (  TARGET.HasFileTransfer  ) ;   \\ \n      set_Job_Type   =   cas ;   \\ \n      set_JobLeaseDuration   =   3600 ;   \\ \n      set_Periodic_Hold   =   ( NumJobStarts  =   1     JobStatus   ==   1 )   ||  NumJobStarts    1 ;   \\ \n      eval_set_VO   =  x509UserProxyVOName ;   \\ \n    ]   \\ \n    [   \\ \n      GridResource   =   condor localhost localhost ;   \\ \n      eval_set_GridResource   =  strcat ( condor  ,  $( FULL_HOSTNAME ) ,  $( FULL_HOSTNAME ) ) ;   \\ \n      TargetUniverse   =   5 ;   \\ \n      name   =   BNL_Condor_Pool ;   \\ \n      Requirements   =  target.queue is undefined ;   \\ \n      eval_set_RACF_Group   =   grid ;   \\ \n      set_requirements   =   (   (   Arch   ==   INTEL   ||   Arch   ==   X86_64   )     (   CPU_Experiment   ==   rcf   )   )     (  TARGET.OpSys  ==   LINUX   )     (  TARGET.Disk  =  RequestDisk  )     (  TARGET.Memory  =  RequestMemory  )     (  TARGET.HasFileTransfer  ) ;   \\ \n      set_Experiment   =   atlas ;   \\ \n      set_Job_Type   =   cas ;   \\ \n      set_JobLeaseDuration   =   3600 ;   \\ \n      set_Periodic_Hold   =   ( NumJobStarts  =   1     JobStatus   ==   1 )   ||  NumJobStarts    1 ;   \\ \n      eval_set_VO   =  x509UserProxyVOName ;   \\ \n    ]", 
            "title": "BNL\u2019s job routes"
        }, 
        {
            "location": "/compute-element/job_router/#reference", 
            "text": "Here are some other HTCondor-CE documents that might be helpful:   HTCondor-CE overview and architecture  Installing HTCondor-CE  The HTCondor-CE troubleshooting guide  Submitting Jobs to HTCondor-CE", 
            "title": "Reference"
        }, 
        {
            "location": "/storage/bestman-overview/", 
            "text": "Berkeley Storage Manager\n\n\nBeStMan, or Berkeley Storage Manager, is a full implementation of SRM v2.2, developed by Lawrence Berkeley National Laboratory, for a disk based storage and mass storage systems. End users may have their own personal BeStMan that manages and gives an SRM interface to their own local disks. It works on top of existing disk-based unix file systems, and has been reported so far to work on file systems such as NFS, GPFS, PVFS, GFS, Ibrix, HFS+, Hadoop, XrootdFS and Lustre. It also works with any existing file transfer service, such as gsiftp, http, https, bbftp and ftp. It requires minimal administrative efforts on the deployment and updates. BeStMan2 is a Jetty based implementation of SRM v2.2.\n\n\nAs of the June 2017 release of OSG 3.4.0, this software is officially deprecated.  Support is scheduled to end as of June 2018.\n\n\nPlanning\n\n\n\n\nInformation on various BeStMan architectures\n\n\nBestman home page\n: Bestman project home\n\n\n\n\nInstallation\n\n\n\n\nInstall Bestman SE\n: BeStMan installation interfacing with local disk\n\n\nInstall Bestman Gateway Xrootd\n: BeStMan gateway mode on top of XRootD\n\n\nInstall Bestman Gateway Hadoop\n: BeStMan gateway mode on top of Hadoop\n\n\nLBNL Configuration Reference\n\n\n\n\nOperation\n\n\n\n\nLBNL SRM Client\n: SRM client provided with BeStMan.  This is deprecated; use of \ngfal-utils\n is strongly encouraged instead.\n\n\nBeStMan SRMTester\n: Tester for BeStMan SRM instances\n\n\nUsing Adler checksums with BeStMan", 
            "title": "BeStMan Overview"
        }, 
        {
            "location": "/storage/bestman-overview/#berkeley-storage-manager", 
            "text": "BeStMan, or Berkeley Storage Manager, is a full implementation of SRM v2.2, developed by Lawrence Berkeley National Laboratory, for a disk based storage and mass storage systems. End users may have their own personal BeStMan that manages and gives an SRM interface to their own local disks. It works on top of existing disk-based unix file systems, and has been reported so far to work on file systems such as NFS, GPFS, PVFS, GFS, Ibrix, HFS+, Hadoop, XrootdFS and Lustre. It also works with any existing file transfer service, such as gsiftp, http, https, bbftp and ftp. It requires minimal administrative efforts on the deployment and updates. BeStMan2 is a Jetty based implementation of SRM v2.2.  As of the June 2017 release of OSG 3.4.0, this software is officially deprecated.  Support is scheduled to end as of June 2018.", 
            "title": "Berkeley Storage Manager"
        }, 
        {
            "location": "/storage/bestman-overview/#planning", 
            "text": "Information on various BeStMan architectures  Bestman home page : Bestman project home", 
            "title": "Planning"
        }, 
        {
            "location": "/storage/bestman-overview/#installation", 
            "text": "Install Bestman SE : BeStMan installation interfacing with local disk  Install Bestman Gateway Xrootd : BeStMan gateway mode on top of XRootD  Install Bestman Gateway Hadoop : BeStMan gateway mode on top of Hadoop  LBNL Configuration Reference", 
            "title": "Installation"
        }, 
        {
            "location": "/storage/bestman-overview/#operation", 
            "text": "LBNL SRM Client : SRM client provided with BeStMan.  This is deprecated; use of  gfal-utils  is strongly encouraged instead.  BeStMan SRMTester : Tester for BeStMan SRM instances  Using Adler checksums with BeStMan", 
            "title": "Operation"
        }, 
        {
            "location": "/storage/bestman-install/", 
            "text": "Installing BeStMan\n\n\n\n\nWarning\n\n\nAs of the June 2017 release of OSG 3.4.0, this software is officially deprecated.  Support is scheduled to end as of June 2018.\n\n\n\n\nAbout this Document\n\n\nThis document explains how to install a BeStMan SRMv2 service. This procedure will guide one through the installation and configuration of a basic \nbestman2\n host with an underlying GridFTP server. This will allow the service to service requests via the SRM (Storage Resource Manager) protocol or the GridFTP protocol.\n\n\nInstalling BeStMan Storage Element\n\n\nThis procedure explains how to install the stand-alone BeStMan Storage Element server; \nsee below\n for notes on upgrading.  The service has the following components:\n\n\n\n\nBeStMan - provides load-balancing across GridFTP servers.\n\n\nGridFTP server - provides file transfer services using the GridFTP protocol.\n\n\nGratia gridftp transfer probe\n (optional) - provides transfer accounting information to the OSG.\n\n\n\n\nRequirements\n\n\nHost and OS\n\n\n\n\nYou need at least one node in order to install this service.\n\n\nThe OS must be in the \nsupported platforms\n list.\n\n\nThe \nOSG software repositories\n must be configured correctly.\n\n\nAll procedures in this document require \nroot\n privileges.\n\n\n\n\nUsers\n\n\nThis installation will create following users unless they are already created:\n\n\n\n\n\n\n\n\nUser\n\n\nComment\n\n\n\n\n\n\n\n\n\n\nbestman\n\n\nUsed by Bestman SRM server\n\n\n\n\n\n\n\n\nFor full functionality, the \nbestman\n account will need limited \nsudo\n access to a few commands, described below.\n\n\nFor this package to function correctly, you will have to create the users needed for grid operation. Any user that can be authenticated should be created.  For grid-mapfile users, each line of the grid-mapfile is a certificate/user pair. Each user in this file should be created on the server. For GUMS sites, this means that each user that can be authenticated by GUMS should be created on the server.\n\n\nNote that these users must be kept in sync with the authentication method. For instance, if new users or rules are added in GUMS, then new users should also be added here.\n\n\nCertificates\n\n\nTwo certificates are needed for operation of this service.\n\n\n\n\n\n\n\n\nCertificate\n\n\nUser that owns certificate\n\n\nPath to certificate\n\n\n\n\n\n\n\n\n\n\nHost certificate\n\n\nroot\n\n\n/etc/grid-security/hostcert.pem\n and \n/etc/grid-security/hostkey.pem\n\n\n\n\n\n\nBestman service certificate\n\n\nbestman\n\n\n/etc/grid-security/bestman/bestmancert.pem\n and \n/etc/grid-security/bestman/bestmankey.pem\n\n\n\n\n\n\n\n\nFollowing the \ninstructions\n to request a service certificate.\n\n\nYou will also need a copy of CA certificates. Note that the \nosg-se-bestman\n package will automatically install a certificate package but will not necessarily pick the cert package you expect; see \nthe CA certificates\n documentation for more information.\n\n\nNetworking\n\n\nFor more details on overall firewall configuration, please see our \nfirewall documentation\n.\n\n\n\n\n\n\n\n\nService Name\n\n\nProtocol\n\n\nPort Number\n\n\nInbound\n\n\nOutbound\n\n\nComment\n\n\n\n\n\n\n\n\n\n\nGridFTP data channels\n\n\ntcp\n\n\nGLOBUS_TCP_PORT_RANGE\n\n\nX\n\n\n\n\ncontiguous range of ports is necessary.\n\n\n\n\n\n\nGridFTP data channels\n\n\ntcp\n\n\nGLOBUS_TCP_SOURCE_RANGE\n\n\n\n\nX\n\n\ncontiguous range of ports is necessary.\n\n\n\n\n\n\nGridFTP control channel\n\n\ntcp\n\n\n2811\n\n\nX\n\n\n\n\n\n\n\n\n\n\nSRM\n\n\ntcp\n\n\n8443\n\n\nX\n\n\n\n\n\n\n\n\n\n\n\n\nEngineering Considerations\n\n\nPlease answer following questions before you proceed with installation and configuration of BeStMan storage element:\n\n\nQ. \nWhat authorization mechanism should I use?\n\n\nDecide between a \ngrid-mapfile\n or a \nGUMS\n server for authorization.  Both mechanisms are deprecated with a planned removal by June 2018.  The replacement mechanism, however, does not work with \nbestman2\n.\n\n\nQ. \nHow many GridFTP servers will I need?\n\n\nChoose to run multiple GridFTP servers for load balancing and better performance. We recommend to install additional GridFTP servers if your Storage Element:\n\n\n\n\nIs serving data to more than 1000 cores for VOs that use storage heavily (e.g. CMS, ATLAS, CDF, and D0),\n\n\nIs managing more than 500 TB of disk space, OR\n\n\nHas more than 10Gbps bandwidth\n\n\n\n\nWe recommend approximately one GridFTP server for each 8Gbps of desired utilized bandwidth.\n\n\nQ. \nDo I need to change default configuration of Gridftp server?\n\n\nYes, you may want to do this if the node on which GridFTP server will be installed has multiple network interfaces. Read \nthis section\n for more details.\n\n\nQ. \nDo you need to enable Gratia gridftp-transfer probes?\n \n\nThe Gratia gridftp-transfer probes provide OSG storage statistics for accounting purposes. The reports include the source and destination of transfers, certificate subject of transfer initiator, as well as the size and status of the transferred file. The probe needs to be installed on every GridFTP server.\n\n\nInstall Instructions\n\n\nInstalling BeStMan2\n\n\n\n\nInstall Java using \nthese instructions\n.\n\n\nInstall the BeStMan Storage element meta-package:\n\n\n\n\n[root@client ~] #\n yum install osg-se-bestman\n\n\n\n\n\nAuthorization\n\n\nThere are two authorization options:\n\n\n\n\nGridmap file\n\n\nGUMS authentication server\n\n\n\n\nPlease choose one of these and follow the instructions in one of the two following sections.\n\n\nConfiguring Gridmap Support\n\n\nBy default, GridFTP uses a gridmap file, found in \n/etc/grid-security/grid-mapfile\n. This file is not generated by default. can generate this file. You can generate this file manually, by including DN/username combinations (this is most useful for debugging). Otherwise, you can use \nedg-mkgridmap\n, which will periodically contact a list of VOMS servers that you specify.\n\n\nOnce \nedg-mkgridmap\n is configured, you will have to modify \n/etc/bestman2/conf/bestman2.rc\n and change \nGridMapFileName\n from \n/etc/bestman2/conf/grid-mapfile.empty\n to:\n\n\nGridMapFileName=/etc/grid-security/grid-mapfile\n\n\n\n\n\nIn \n/etc/sysconfig/bestman2\n, change\n\n\nBESTMAN_GUMS_ENABLED\n=\nno\n\n\n\n\n\nConfiguring GUMS support\n\n\nBy default, GridFTP uses a gridmap file, found in \n/etc/grid-security/gridmap-file\n. If you want to use GUMS security (recommended), you will need to enable it using the following steps.\n\n\nFirst, edit \n/etc/grid-security/gsi-authz.conf\n and uncomment the authorization callout:\n\n\nglobus_mapping liblcas_lcmaps_gt4_mapping.so lcmaps_callout\n\n\n\n\n\nNext edit \n/etc/lcmaps.db\n to enter the correct GUMS hostname:\n\n\ngumsclient = \nlcmaps_gums_client.mod\n\n             \n-resourcetype ce\n\n             \n-actiontype execute-now\n\n             \n-capath /etc/grid-security/certificates\n\n             \n-cert   /etc/grid-security/hostcert.pem\n\n             \n-key    /etc/grid-security/hostkey.pem\n\n             \n--cert-owner root\n\n# Change this URL to your GUMS server\n             \n--endpoint https://\nGUMS_HOSTNAME\n:8443/gums/services/GUMSXACMLAuthorizationServicePort\n\n\n\n\n\n\nYou will need to modify the following settings in \n/etc/sysconfig/bestman2\n\n\nBESTMAN_GUMSCERTPATH\n=\n/etc/grid-security/bestman/bestmancert.pem\n\nBESTMAN_GUMSKEYPATH\n=\n/etc/grid-security/bestman/bestmankey.pem\n\n\n\n\n\nYou will need to modify the following settings in \n/etc/bestman2/conf/bestman2.rc\n\n\nGUMSserviceURL=https://\nGUMS_HOST\n:8443/gums/services/GUMSXACMLAuthorizationServicePort\n\n\n\n\n\nEdit Bestman Settings\n\n\nBestman settings are split into three files:\n\n\n\n\nEnvironment variables (except those that represent server and client libraries) are stored in \n/etc/sysconfig/bestman2\n.\n\n\nThe server and client library environment variables are stored in \n/etc/sysconfig/bestman2lib\n.\n\n\nConfiguration is stored in \n/etc/bestman2/conf/bestman2.rc\n.\n\n\n\n\nYou should review these settings to make sure all of them comply with your environment. You are not expected to edit \n/etc/sysconfig/bestman2lib\n .\n\n\n\n\nNote\n\n\nIf you are upgrading from a version prior to 2.3.0-9, you will need to remove \nall\n entries for \nBESTMAN2_SERVER_LIB\n and \nBESTMAN2_CLIENT_LIB\n in file \n/etc/sysconfig/bestman2.\n These settings are now present in file \n/etc/sysconfig/bestman2lib\n\n\n\n\nYou will likely need to modify the following settings in \n/etc/bestman2/conf/bestman2.rc\n:\n\n\nlocalPathListAllowed=/tmp\nCertFileName=/etc/grid-security/bestman/bestmancert.pem\nKeyFileName=/etc/grid-security/bestman/bestmankey.pem\nsupportedProtocolList=gsiftp://\nGRIDFTP_HOSTNAME\n;gsiftp://\nGRIDFTP_HOSTNAME2\n\n\n\n\n\n\n\n\nNote\n\n\nMake sure the value for \nlocalPathListAllowed\n is correctly entered - i.e. each path separated by a \n;\n. If it is not, this parameter may not be effective.\nMake sure the permissions for the \nlocalPathListAllowed\n directory(ies) are set to 1777, which is the default for \n/tmp\n. Further, note that on many systems, \n/tmp\n gets cleared out automatically, so you may want to use a different location to ensure that the files persist.\n\n\n\n\nBeStMan requires up to two sets of certificate pairs. One is for host services; when clients connect to BeStMan, they will receive this certificate (\nCertFileName\n, \nKeyFileName\n) as proof of the server identity. The second certificate pair (\nBESTMAN_GUMSCERTPATH\n, \nBESTMAN_GUMSKEYPATH\n) is used to communicate with GUMS when verifying identity information (this only applicable for GUMS-enabled sites). These two can (and usually will be) the same files, but can be split if your GUMS setup requires a specific identity.\n\n\nlocalPathListAllowed\n determines which paths users will be able to access via SRM.\n\n\nsupportedProtocolList\n is a semi-colon list of GridFTP servers that the BeStMan will use as transfer agents. If you are using anything but the standard GridFTP port 2811, you will also have to add the port (ie \ngsiftp://\nHOSTNAME\n:port\n).\n\n\nFinally, modify \nGUMSserviceURL\n to use your local GUMS installation if you are using GUMS.\n\n\nModify \n/etc/sudoers\n\n\nBeStman requires the \nsudo\n command in order to write information as the proper user. You will need to give the \nbestman\n user the proper permissions to run these commands.\n\n\nModify \n/etc/sudoers\n and comment the following line.\n\n\n#Defaults    requiretty\n\n\n\n\n\nThen add the following lines at the end of the \n/etc/sudoers\n file.\n\n\nCmnd_Alias SRM_CMD = /bin/rm, /bin/mkdir, /bin/rmdir, /bin/mv, /bin/cp, /bin/ls\nRunas_Alias SRM_USR = ALL, !root\nbestman   ALL=(SRM_USR) NOPASSWD: SRM_CMD\n\n\n\n\n\nCopying certificates to an alternate location\n\n\nBeStMan requires a certificate pair to function; this must be readable by the \nbestman\n user.\n\n\n[root@client ~] #\n cp /etc/grid-security/hostkey.pem /etc/grid-security/bestman/bestmankey.pem\n\n[root@client ~] #\n cp /etc/grid-security/hostcert.pem /etc/grid-security/bestman/bestmancert.pem\n\n[root@client ~] #\n chown -R bestman:bestman /etc/grid-security/bestman/\n\n\n\n\n\nVerify \nCertFileName\n and \nKeyFileName\n in \n/etc/bestman2/conf/bestman2.rc\n are set appropriately.\n\n\n(Optional) Using a different bestman user\n\n\nIf you would like to use a different user than the default \nbestman\n user (\nnot recommended\n), you will need to change the following:\n\n\n\n\nOwnership of bestman certs in \n/etc/grid-security/bestman\n.\n\n\nSRM_OWNER\n in \n/etc/sysconfig/bestman2\n to the new user.\n\n\nUser in \n/etc/sudoers\n. The last line (\nbestman ALL(SRM_USR) NOPASSWD: SRM_CMD\n) should be changed from \nbestman\n to the new user.\n\n\nOwnership of \n/var/log/bestman2\n\n\n\n\n\n\nWarning\n\n\nCurrently the RPM packaging will change the ownership of the \n/var/log/bestman2\n directory back to \nbestman\n on upgrades.\n\n\n\n\n(Optional) Modifying default logging for \nevent.srm.log\n\n\nThe logging directory (\n/var/log/bestman2\n) has two types of logs - \nbestman2.log\n and \nevent.srm.log\n.\n\n\nLog-rotation of \nbestman2.log\n file is controlled by \n/etc/logrotate.d/bestman2\n file.\n\n\nBy default, the size of \nevent.srm.log\n log file is set to 50MB within the Bestman code itself.\n\n\nLeft unchanged, \nevent.srm.log\n file counts will keep increasing indefinitely.  Depending on the usage, the number of these files can become high enough to fill up the partition that holds these logs.\n\n\nThere are 3 ways to avoid this -\n\n\n\n\n\n\nModify following parameters (commented by default) in the \n/etc/sysconfig/bestman2\n file\n\n\n# Number of files to keep\n\n\nBESTMAN_EVENT_LOG_COUNT\n=\n10\n\n\n# Size of each file in bytes\n\n\nBESTMAN_EVENT_LOG_SIZE\n=\n20971520\n\n\n\n\n\n\nThe optimal value for these depends on usage of the service.\n\n\n\n\n\n\nCreate a directory under a much bigger partition and have a symlink from \n/var/log/bestman2\n to that directory.\n\n\n\n\nLeave the default settings, but have your own custom script that cleans these files according to your needs.\n\n\n\n\nStarting Services\n\n\n\n\n\n\nfetch-crl\n\n\nFor RHEL 6:\n\n\n[root@client ~] #\n /usr/sbin/fetch-crl   \n# This fetches the CRLs \n\n\n[root@client ~] #\n /sbin/service fetch-crl-boot start\n\n[root@client ~] #\n /sbin/service fetch-crl-cron start\n\n\n\n\n\nFor RHEL 7:\n\n\n[root@client ~] #\n /usr/sbin/fetch-crl   \n# This fetches the CRLs \n\n\n[root@client ~] #\n systemctl start fetch-crl-boot\n\n[root@client ~] #\n systemctl start fetch-crl-cron\n\n\n\n\n\n\n\n\n\nGridFTP\n\n\n[root@client ~] #\n service globus-gridftp-server start\n\n\n\n\n\n\n\n\n\nBestman\n\n\n[root@client ~] #\n service bestman2 start\n\n\n\n\n\nTo start Bestman automatically at boot time\n\n\n[root@client ~] #\n chkconfig bestman2 on\n\n\n\n\n\n\n\n\n\nGratia transfer probe:\n\n\n[root@client ~] #\n service gratia-gridftp-transfer start\n\n\n\n\n\n\n\n\n\nStopping Services\n\n\n\n\n\n\nfetch-crl\n\n\nFor RHEL 6:\n\n\n[root@client ~] #\n /usr/sbin/fetch-crl   \n# This fetches the CRLs\n\n\n[root@client ~] #\n /sbin/service fetch-crl-boot stop\n\n[root@client ~] #\n /sbin/service fetch-crl-cron stop\n\n\n\n\n\nFor RHEL 7:\n\n\n[root@client ~] #\n /usr/sbin/fetch-crl   \n# This fetches the CRLs\n\n\n[root@client ~] #\n systemctl stop fetch-crl-boot\n\n[root@client ~] #\n systemctl stop fetch-crl-cron\n\n\n\n\n\n\n\n\n\nGridFTP\n\n\n[root@client ~] #\n service globus-gridftp-server stop\n\n\n\n\n\n\n\n\n\nBestman\n\n\n[root@client ~] #\n service bestman2 stop\n\n\n\n\n\n\n\n\n\nGratia transfer probe\n\n\n[root@client ~] #\n service gratia-gridftp-transfer stop\n\n\n\n\n\n\n\n\n\nValidation of Service Operation\n\n\nOnce you have your SE setup and configured, there are several ways to monitor your installation. Refer to the following pages for more information:\n\n\n\n\nBeStMan SRM Tester\n.\n\n\nRSV\n which includes SRM probes as well.\n\n\n\n\nYou can also self-test to verify your installation with an SRM client such as \ngfal-copy\n.\n\n\nTroubleshooting\n\n\n\n\n\n\n\n\nService/Process\n\n\nLog File\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nBeStMan2\n\n\n/var/log/bestman2/bestman2.log\n\n\nBeStMan2 server log and errors\n\n\n\n\n\n\n\n\n/var/log/bestman2/event.srm.log\n\n\nRecords all SRM transactions\n\n\n\n\n\n\nGridFTP\n\n\n/var/log/gridftp.log\n\n\nTransfer log\n\n\n\n\n\n\n\n\n/var/log/gridftp-auth.log\n\n\nAuthentication log\n\n\n\n\n\n\n\n\n/var/log/messages\n\n\nMain system log (look here for LCMAPS errors)\n\n\n\n\n\n\n\n\nDebugging Procedure\n\n\nIf system validation failed, you would probably need to check each component in order to verify your installation. In order to do so, you should check all of them in the following order\n\n\n\n\nGUMS (if in use)\n\n\nGridFTP\n\n\nBeStMan\n\n\n\n\nVerifying GUMS\n\n\nMake sure that the service certificate you specified for BeStMan configuration with \nGUMSHOSTCERT\n, \nGUMSHOSTKEY\n options and GridFTP service certificate are accepted by GUMS.\n\n\nTest GUMS by running:\n\n\n[root@client ~] #\n srm-ping srm://\nBESTMAN_HOST\n:8443/srm/v2/server\n\n\n\n\n\nIn the output, check that your \ngumsIDMapped\n is not \nnull\n. It returns the \nuid\n that GUMS will map you to. This can be obtained from your GUMS administrator. Verify that this \nuid\n exists on BeStMan and GridFTP node.\n\n\nVerifying GridFTP\n\n\nLogin on the node where your certificate and \nOSG Client\n is installed You will need to generate your proxy credentials using \ngrid-proxy-init\n or \nvoms-proxy-init\n.\n\n\nThen test GridFTP using \nglobus-url-copy\n:\n\n\n[user@client ~] $\n \necho\n \nThis is a test\n \n/tmp/test \n\n[user@client ~] $\n globus-url-copy -dbg file:///tmp/test gsiftp://\nGRIDFTP_HOST\n/tmp/test \n\n\n\n\n\nCheck the GridFTP logs to see if you have encountered any errors.\n\n\nVerifying BeStMan\n\n\nMake sure that the BeStMan process is running\n\n\n[root@client ~] #\n ps -ef \n|\n grep bestman\n\nbestman   5121     1 99 19:59 ?        00:00:01 /usr/java/latest/bin/java -server -Xmx1024m -XX:MaxDirectMemorySize=1024m -DX509_CERT_DIR=/etc/grid-security/certificates -DCADIR=/etc/grid-security/certificates -Daxis.socketSecureFactory=org.glite.security.trustmanager.axis.AXISSocketFactory -DsslCAFiles=/etc/grid-security/certificates/*.0 -DsslCertfile=/etc/grid-security/bestman/bestmancert.pem -DsslKey=/etc/grid-security/bestman/bestmankey.pem -DJettyConfiguration=/etc/bestman2/conf/WEB-INF/jetty.xml -DJettyDescriptor=/etc/bestman2/conf/WEB-INF/web.xml -DJettyResource=/etc/bestman2/conf/ -Dorg.eclipse.jetty.util.log.IGNORE=true gov.lbl.srm.server.Server /etc/bestman2/conf/bestman2.rc\n\n\n\n\n\n\nIf \nbestman2\n is not running, check information in the log file \n/var/log/bestman2/bestman2.log\n.\n\n\nUseful Configuration and Log Files\n\n\n\n\n\n\n\n\nService/Process\n\n\nConfiguration File\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nBeStMan2\n\n\n/etc/bestman2/conf/bestman2.rc\n\n\nMain BeStMan2 configuration file\n\n\n\n\n\n\n\n\n/etc/sysconfig/bestman2\n\n\nEnvironment variables used by BeStMan2\n\n\n\n\n\n\n\n\n/etc/sysconfig/bestman2lib\n\n\nEnvironment variables that store values of various client and server libraries used by BeStMan2\n\n\n\n\n\n\n\n\n/etc/bestman2/conf/*\n\n\nOther runtime configuration files\n\n\n\n\n\n\n\n\n/etc/init.d/bestman2\n\n\ninit.d startup script\n\n\n\n\n\n\n\n\n/etc/gridftp.conf\n\n\nStartup parameters\n\n\n\n\n\n\nGridFTP\n\n\n/etc/sysconfig/globus-gridftp-server\n\n\nEnvironment variables for GridFTP\n\n\n\n\n\n\nGratia Probe\n\n\n/etc/gratia/gridftp-transfer/ProbeConfig\n\n\nGridFTP Gratia Probe configuration\n\n\n\n\n\n\n\n\n/etc/cron.d/gratia-probe-gridftp-transfer.cron\n\n\nCron tab file\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nService/Process\n\n\nLog File\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nBeStMan2\n\n\n/var/log/bestman2/bestman2.log\n\n\nBeStMan2 container log\n\n\n\n\n\n\n\n\n/var/log/bestman2/event.srm.log\n\n\nRecords all SRM transactions\n\n\n\n\n\n\nGridFTP\n\n\n/var/log/gridftp.log\n\n\nTransfer log\n\n\n\n\n\n\n\n\n/var/log/gridftp-auth.log\n\n\nGridFTP authorization log\n\n\n\n\n\n\n\n\n/var/log/messages\n\n\nMain system log (look here for LCMAPS errors)\n\n\n\n\n\n\nGratia probe\n\n\n/var/log/gratia\n\n\n\n\n\n\n\n\n\n\nUpgrading BeStMan\n\n\nUpgrading BeStMan can be done by\n\n\n[root@client ~] #\n yum upgrade bestman2-server\n\n\n\n\n\nThere are a few notes to be aware of when upgrading BeStMan.\n\n\n\n\nFrom many of the versions of the BeStMan, configuration changes have taken place. Do not ignore any warnings about rpmsave or rpmnew files. You will need to especially be careful about and \n/etc/bestman2/conf/bestman2.rc\n.\n\n\nBeginning with BeStMan 2.3.0-9, many dependency locations changed. Be sure that \n/etc/sysconfig/bestman2lib\n contains the \nbuild-classpath\n directives in the \nBESTMAN2_SERVER_LIB\n and \nBESTMAN2_CLIENT_LIB\n. Otherwise, you may get java class loading errors on startup or on run-time. Be sure to remove these entries from the \n/etc/sysconfig/bestman2\n file.\n\n\nFor BeStMan 2.1.3, certain versions had a combined sysconfig and configuration file. You may need to split these files apart if this is the case.\n\n\n\n\nFor more help, please contact the GOC to create a support ticket.\n\n\nHow to get Help?\n\n\nIf you cannot resolve the problem, there are several ways to receive help:\n\n\n\n\nFor bug support and issues, submit a ticket to the \nGrid Operations Center\n.\n\n\nFor community support and best-effort software team support contact \n.\n\n\n\n\nFor a full set of help options, see the \nHelp Procedure\n.\n\n\nReferences\n\n\n\n\nStorage infrastructure software\n\n\nInformation on planning, installing and validating storage software\n\n\nTips and FAQ\n\n\nOSG Gratia Transfer Probe page\n\n\nSRM v2.2 LBNL client command line examples\n\n\nSRM-Tester\n\n\nBeStMan official website\n\n\nBeStMan User guides\n\n\nBeStMan FAQ\n\n\n\n\n\n\nSLAC Gateway mode Instruction\n - SLAC guide on gateway mode\n\n\nUS ATLAS instruction page\n\n\nSRM specifications and collaboration\n - from SRM collaboration working group\n\n\nS2\n - A SRM v2.2 test suite from CERN. It provides basic functionality tests based on use cases, and cross-copy tests, as part of the certification process and supports file access/transfer protocols: rfio, dcap, gsidcap, gsiftp\n\n\nSHA-2 compliance page\n\n\nBestman scalability tuning\n\n\n\n\nKnown Issues\n\n\nRequesting host certificates in RHEL6\n\n\nBestman may not start if the certificates were requested on slc6. This is be caused by a bug in JGlobus (see \nJGlobusIssue118\n), a \nbestman2\n dependency. A known workaround is to run this command\n\n\n[user@client ~] $\n openssl rsa -in mykey.pem -out mykey.pem.old\n\n\n\n\n\nThis command on converts \nmykey.pem\n to \nmykey.pem.old\n; the latter format is supported.", 
            "title": "BeStMan Install"
        }, 
        {
            "location": "/storage/bestman-install/#installing-bestman", 
            "text": "Warning  As of the June 2017 release of OSG 3.4.0, this software is officially deprecated.  Support is scheduled to end as of June 2018.", 
            "title": "Installing BeStMan"
        }, 
        {
            "location": "/storage/bestman-install/#about-this-document", 
            "text": "This document explains how to install a BeStMan SRMv2 service. This procedure will guide one through the installation and configuration of a basic  bestman2  host with an underlying GridFTP server. This will allow the service to service requests via the SRM (Storage Resource Manager) protocol or the GridFTP protocol.", 
            "title": "About this Document"
        }, 
        {
            "location": "/storage/bestman-install/#installing-bestman-storage-element", 
            "text": "This procedure explains how to install the stand-alone BeStMan Storage Element server;  see below  for notes on upgrading.  The service has the following components:   BeStMan - provides load-balancing across GridFTP servers.  GridFTP server - provides file transfer services using the GridFTP protocol.  Gratia gridftp transfer probe  (optional) - provides transfer accounting information to the OSG.", 
            "title": "Installing BeStMan Storage Element"
        }, 
        {
            "location": "/storage/bestman-install/#requirements", 
            "text": "", 
            "title": "Requirements"
        }, 
        {
            "location": "/storage/bestman-install/#host-and-os", 
            "text": "You need at least one node in order to install this service.  The OS must be in the  supported platforms  list.  The  OSG software repositories  must be configured correctly.  All procedures in this document require  root  privileges.", 
            "title": "Host and OS"
        }, 
        {
            "location": "/storage/bestman-install/#users", 
            "text": "This installation will create following users unless they are already created:     User  Comment      bestman  Used by Bestman SRM server     For full functionality, the  bestman  account will need limited  sudo  access to a few commands, described below.  For this package to function correctly, you will have to create the users needed for grid operation. Any user that can be authenticated should be created.  For grid-mapfile users, each line of the grid-mapfile is a certificate/user pair. Each user in this file should be created on the server. For GUMS sites, this means that each user that can be authenticated by GUMS should be created on the server.  Note that these users must be kept in sync with the authentication method. For instance, if new users or rules are added in GUMS, then new users should also be added here.", 
            "title": "Users"
        }, 
        {
            "location": "/storage/bestman-install/#certificates", 
            "text": "Two certificates are needed for operation of this service.     Certificate  User that owns certificate  Path to certificate      Host certificate  root  /etc/grid-security/hostcert.pem  and  /etc/grid-security/hostkey.pem    Bestman service certificate  bestman  /etc/grid-security/bestman/bestmancert.pem  and  /etc/grid-security/bestman/bestmankey.pem     Following the  instructions  to request a service certificate.  You will also need a copy of CA certificates. Note that the  osg-se-bestman  package will automatically install a certificate package but will not necessarily pick the cert package you expect; see  the CA certificates  documentation for more information.", 
            "title": "Certificates"
        }, 
        {
            "location": "/storage/bestman-install/#networking", 
            "text": "For more details on overall firewall configuration, please see our  firewall documentation .     Service Name  Protocol  Port Number  Inbound  Outbound  Comment      GridFTP data channels  tcp  GLOBUS_TCP_PORT_RANGE  X   contiguous range of ports is necessary.    GridFTP data channels  tcp  GLOBUS_TCP_SOURCE_RANGE   X  contiguous range of ports is necessary.    GridFTP control channel  tcp  2811  X      SRM  tcp  8443  X", 
            "title": "Networking"
        }, 
        {
            "location": "/storage/bestman-install/#engineering-considerations", 
            "text": "Please answer following questions before you proceed with installation and configuration of BeStMan storage element:  Q.  What authorization mechanism should I use?  Decide between a  grid-mapfile  or a  GUMS  server for authorization.  Both mechanisms are deprecated with a planned removal by June 2018.  The replacement mechanism, however, does not work with  bestman2 .  Q.  How many GridFTP servers will I need?  Choose to run multiple GridFTP servers for load balancing and better performance. We recommend to install additional GridFTP servers if your Storage Element:   Is serving data to more than 1000 cores for VOs that use storage heavily (e.g. CMS, ATLAS, CDF, and D0),  Is managing more than 500 TB of disk space, OR  Has more than 10Gbps bandwidth   We recommend approximately one GridFTP server for each 8Gbps of desired utilized bandwidth.  Q.  Do I need to change default configuration of Gridftp server?  Yes, you may want to do this if the node on which GridFTP server will be installed has multiple network interfaces. Read  this section  for more details.  Q.  Do you need to enable Gratia gridftp-transfer probes?   \nThe Gratia gridftp-transfer probes provide OSG storage statistics for accounting purposes. The reports include the source and destination of transfers, certificate subject of transfer initiator, as well as the size and status of the transferred file. The probe needs to be installed on every GridFTP server.", 
            "title": "Engineering Considerations"
        }, 
        {
            "location": "/storage/bestman-install/#install-instructions", 
            "text": "", 
            "title": "Install Instructions"
        }, 
        {
            "location": "/storage/bestman-install/#installing-bestman2", 
            "text": "Install Java using  these instructions .  Install the BeStMan Storage element meta-package:   [root@client ~] #  yum install osg-se-bestman", 
            "title": "Installing BeStMan2"
        }, 
        {
            "location": "/storage/bestman-install/#authorization", 
            "text": "There are two authorization options:   Gridmap file  GUMS authentication server   Please choose one of these and follow the instructions in one of the two following sections.", 
            "title": "Authorization"
        }, 
        {
            "location": "/storage/bestman-install/#configuring-gridmap-support", 
            "text": "By default, GridFTP uses a gridmap file, found in  /etc/grid-security/grid-mapfile . This file is not generated by default. can generate this file. You can generate this file manually, by including DN/username combinations (this is most useful for debugging). Otherwise, you can use  edg-mkgridmap , which will periodically contact a list of VOMS servers that you specify.  Once  edg-mkgridmap  is configured, you will have to modify  /etc/bestman2/conf/bestman2.rc  and change  GridMapFileName  from  /etc/bestman2/conf/grid-mapfile.empty  to:  GridMapFileName=/etc/grid-security/grid-mapfile  In  /etc/sysconfig/bestman2 , change  BESTMAN_GUMS_ENABLED = no", 
            "title": "Configuring Gridmap Support"
        }, 
        {
            "location": "/storage/bestman-install/#configuring-gums-support", 
            "text": "By default, GridFTP uses a gridmap file, found in  /etc/grid-security/gridmap-file . If you want to use GUMS security (recommended), you will need to enable it using the following steps.  First, edit  /etc/grid-security/gsi-authz.conf  and uncomment the authorization callout:  globus_mapping liblcas_lcmaps_gt4_mapping.so lcmaps_callout  Next edit  /etc/lcmaps.db  to enter the correct GUMS hostname:  gumsclient =  lcmaps_gums_client.mod \n              -resourcetype ce \n              -actiontype execute-now \n              -capath /etc/grid-security/certificates \n              -cert   /etc/grid-security/hostcert.pem \n              -key    /etc/grid-security/hostkey.pem \n              --cert-owner root \n# Change this URL to your GUMS server\n              --endpoint https:// GUMS_HOSTNAME :8443/gums/services/GUMSXACMLAuthorizationServicePort   You will need to modify the following settings in  /etc/sysconfig/bestman2  BESTMAN_GUMSCERTPATH = /etc/grid-security/bestman/bestmancert.pem BESTMAN_GUMSKEYPATH = /etc/grid-security/bestman/bestmankey.pem  You will need to modify the following settings in  /etc/bestman2/conf/bestman2.rc  GUMSserviceURL=https:// GUMS_HOST :8443/gums/services/GUMSXACMLAuthorizationServicePort", 
            "title": "Configuring GUMS support"
        }, 
        {
            "location": "/storage/bestman-install/#edit-bestman-settings", 
            "text": "Bestman settings are split into three files:   Environment variables (except those that represent server and client libraries) are stored in  /etc/sysconfig/bestman2 .  The server and client library environment variables are stored in  /etc/sysconfig/bestman2lib .  Configuration is stored in  /etc/bestman2/conf/bestman2.rc .   You should review these settings to make sure all of them comply with your environment. You are not expected to edit  /etc/sysconfig/bestman2lib  .   Note  If you are upgrading from a version prior to 2.3.0-9, you will need to remove  all  entries for  BESTMAN2_SERVER_LIB  and  BESTMAN2_CLIENT_LIB  in file  /etc/sysconfig/bestman2.  These settings are now present in file  /etc/sysconfig/bestman2lib   You will likely need to modify the following settings in  /etc/bestman2/conf/bestman2.rc :  localPathListAllowed=/tmp\nCertFileName=/etc/grid-security/bestman/bestmancert.pem\nKeyFileName=/etc/grid-security/bestman/bestmankey.pem\nsupportedProtocolList=gsiftp:// GRIDFTP_HOSTNAME ;gsiftp:// GRIDFTP_HOSTNAME2    Note  Make sure the value for  localPathListAllowed  is correctly entered - i.e. each path separated by a  ; . If it is not, this parameter may not be effective.\nMake sure the permissions for the  localPathListAllowed  directory(ies) are set to 1777, which is the default for  /tmp . Further, note that on many systems,  /tmp  gets cleared out automatically, so you may want to use a different location to ensure that the files persist.   BeStMan requires up to two sets of certificate pairs. One is for host services; when clients connect to BeStMan, they will receive this certificate ( CertFileName ,  KeyFileName ) as proof of the server identity. The second certificate pair ( BESTMAN_GUMSCERTPATH ,  BESTMAN_GUMSKEYPATH ) is used to communicate with GUMS when verifying identity information (this only applicable for GUMS-enabled sites). These two can (and usually will be) the same files, but can be split if your GUMS setup requires a specific identity.  localPathListAllowed  determines which paths users will be able to access via SRM.  supportedProtocolList  is a semi-colon list of GridFTP servers that the BeStMan will use as transfer agents. If you are using anything but the standard GridFTP port 2811, you will also have to add the port (ie  gsiftp:// HOSTNAME :port ).  Finally, modify  GUMSserviceURL  to use your local GUMS installation if you are using GUMS.", 
            "title": "Edit Bestman Settings"
        }, 
        {
            "location": "/storage/bestman-install/#modify-etcsudoers", 
            "text": "BeStman requires the  sudo  command in order to write information as the proper user. You will need to give the  bestman  user the proper permissions to run these commands.  Modify  /etc/sudoers  and comment the following line.  #Defaults    requiretty  Then add the following lines at the end of the  /etc/sudoers  file.  Cmnd_Alias SRM_CMD = /bin/rm, /bin/mkdir, /bin/rmdir, /bin/mv, /bin/cp, /bin/ls\nRunas_Alias SRM_USR = ALL, !root\nbestman   ALL=(SRM_USR) NOPASSWD: SRM_CMD", 
            "title": "Modify /etc/sudoers"
        }, 
        {
            "location": "/storage/bestman-install/#copying-certificates-to-an-alternate-location", 
            "text": "BeStMan requires a certificate pair to function; this must be readable by the  bestman  user.  [root@client ~] #  cp /etc/grid-security/hostkey.pem /etc/grid-security/bestman/bestmankey.pem [root@client ~] #  cp /etc/grid-security/hostcert.pem /etc/grid-security/bestman/bestmancert.pem [root@client ~] #  chown -R bestman:bestman /etc/grid-security/bestman/  Verify  CertFileName  and  KeyFileName  in  /etc/bestman2/conf/bestman2.rc  are set appropriately.", 
            "title": "Copying certificates to an alternate location"
        }, 
        {
            "location": "/storage/bestman-install/#optional-using-a-different-bestman-user", 
            "text": "If you would like to use a different user than the default  bestman  user ( not recommended ), you will need to change the following:   Ownership of bestman certs in  /etc/grid-security/bestman .  SRM_OWNER  in  /etc/sysconfig/bestman2  to the new user.  User in  /etc/sudoers . The last line ( bestman ALL(SRM_USR) NOPASSWD: SRM_CMD ) should be changed from  bestman  to the new user.  Ownership of  /var/log/bestman2    Warning  Currently the RPM packaging will change the ownership of the  /var/log/bestman2  directory back to  bestman  on upgrades.", 
            "title": "(Optional) Using a different bestman user"
        }, 
        {
            "location": "/storage/bestman-install/#optional-modifying-default-logging-for-eventsrmlog", 
            "text": "The logging directory ( /var/log/bestman2 ) has two types of logs -  bestman2.log  and  event.srm.log .  Log-rotation of  bestman2.log  file is controlled by  /etc/logrotate.d/bestman2  file.  By default, the size of  event.srm.log  log file is set to 50MB within the Bestman code itself.  Left unchanged,  event.srm.log  file counts will keep increasing indefinitely.  Depending on the usage, the number of these files can become high enough to fill up the partition that holds these logs.  There are 3 ways to avoid this -    Modify following parameters (commented by default) in the  /etc/sysconfig/bestman2  file  # Number of files to keep  BESTMAN_EVENT_LOG_COUNT = 10  # Size of each file in bytes  BESTMAN_EVENT_LOG_SIZE = 20971520   The optimal value for these depends on usage of the service.    Create a directory under a much bigger partition and have a symlink from  /var/log/bestman2  to that directory.   Leave the default settings, but have your own custom script that cleans these files according to your needs.", 
            "title": "(Optional) Modifying default logging for event.srm.log"
        }, 
        {
            "location": "/storage/bestman-install/#starting-services", 
            "text": "fetch-crl  For RHEL 6:  [root@client ~] #  /usr/sbin/fetch-crl    # This fetches the CRLs   [root@client ~] #  /sbin/service fetch-crl-boot start [root@client ~] #  /sbin/service fetch-crl-cron start  For RHEL 7:  [root@client ~] #  /usr/sbin/fetch-crl    # This fetches the CRLs   [root@client ~] #  systemctl start fetch-crl-boot [root@client ~] #  systemctl start fetch-crl-cron    GridFTP  [root@client ~] #  service globus-gridftp-server start    Bestman  [root@client ~] #  service bestman2 start  To start Bestman automatically at boot time  [root@client ~] #  chkconfig bestman2 on    Gratia transfer probe:  [root@client ~] #  service gratia-gridftp-transfer start", 
            "title": "Starting Services"
        }, 
        {
            "location": "/storage/bestman-install/#stopping-services", 
            "text": "fetch-crl  For RHEL 6:  [root@client ~] #  /usr/sbin/fetch-crl    # This fetches the CRLs  [root@client ~] #  /sbin/service fetch-crl-boot stop [root@client ~] #  /sbin/service fetch-crl-cron stop  For RHEL 7:  [root@client ~] #  /usr/sbin/fetch-crl    # This fetches the CRLs  [root@client ~] #  systemctl stop fetch-crl-boot [root@client ~] #  systemctl stop fetch-crl-cron    GridFTP  [root@client ~] #  service globus-gridftp-server stop    Bestman  [root@client ~] #  service bestman2 stop    Gratia transfer probe  [root@client ~] #  service gratia-gridftp-transfer stop", 
            "title": "Stopping Services"
        }, 
        {
            "location": "/storage/bestman-install/#validation-of-service-operation", 
            "text": "Once you have your SE setup and configured, there are several ways to monitor your installation. Refer to the following pages for more information:   BeStMan SRM Tester .  RSV  which includes SRM probes as well.   You can also self-test to verify your installation with an SRM client such as  gfal-copy .", 
            "title": "Validation of Service Operation"
        }, 
        {
            "location": "/storage/bestman-install/#troubleshooting", 
            "text": "Service/Process  Log File  Description      BeStMan2  /var/log/bestman2/bestman2.log  BeStMan2 server log and errors     /var/log/bestman2/event.srm.log  Records all SRM transactions    GridFTP  /var/log/gridftp.log  Transfer log     /var/log/gridftp-auth.log  Authentication log     /var/log/messages  Main system log (look here for LCMAPS errors)", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/storage/bestman-install/#debugging-procedure", 
            "text": "If system validation failed, you would probably need to check each component in order to verify your installation. In order to do so, you should check all of them in the following order   GUMS (if in use)  GridFTP  BeStMan", 
            "title": "Debugging Procedure"
        }, 
        {
            "location": "/storage/bestman-install/#verifying-gums", 
            "text": "Make sure that the service certificate you specified for BeStMan configuration with  GUMSHOSTCERT ,  GUMSHOSTKEY  options and GridFTP service certificate are accepted by GUMS.  Test GUMS by running:  [root@client ~] #  srm-ping srm:// BESTMAN_HOST :8443/srm/v2/server  In the output, check that your  gumsIDMapped  is not  null . It returns the  uid  that GUMS will map you to. This can be obtained from your GUMS administrator. Verify that this  uid  exists on BeStMan and GridFTP node.", 
            "title": "Verifying GUMS"
        }, 
        {
            "location": "/storage/bestman-install/#verifying-gridftp", 
            "text": "Login on the node where your certificate and  OSG Client  is installed You will need to generate your proxy credentials using  grid-proxy-init  or  voms-proxy-init .  Then test GridFTP using  globus-url-copy :  [user@client ~] $   echo   This is a test   /tmp/test  [user@client ~] $  globus-url-copy -dbg file:///tmp/test gsiftp:// GRIDFTP_HOST /tmp/test   Check the GridFTP logs to see if you have encountered any errors.", 
            "title": "Verifying GridFTP"
        }, 
        {
            "location": "/storage/bestman-install/#verifying-bestman", 
            "text": "Make sure that the BeStMan process is running  [root@client ~] #  ps -ef  |  grep bestman bestman   5121     1 99 19:59 ?        00:00:01 /usr/java/latest/bin/java -server -Xmx1024m -XX:MaxDirectMemorySize=1024m -DX509_CERT_DIR=/etc/grid-security/certificates -DCADIR=/etc/grid-security/certificates -Daxis.socketSecureFactory=org.glite.security.trustmanager.axis.AXISSocketFactory -DsslCAFiles=/etc/grid-security/certificates/*.0 -DsslCertfile=/etc/grid-security/bestman/bestmancert.pem -DsslKey=/etc/grid-security/bestman/bestmankey.pem -DJettyConfiguration=/etc/bestman2/conf/WEB-INF/jetty.xml -DJettyDescriptor=/etc/bestman2/conf/WEB-INF/web.xml -DJettyResource=/etc/bestman2/conf/ -Dorg.eclipse.jetty.util.log.IGNORE=true gov.lbl.srm.server.Server /etc/bestman2/conf/bestman2.rc   If  bestman2  is not running, check information in the log file  /var/log/bestman2/bestman2.log .", 
            "title": "Verifying BeStMan"
        }, 
        {
            "location": "/storage/bestman-install/#useful-configuration-and-log-files", 
            "text": "Service/Process  Configuration File  Description      BeStMan2  /etc/bestman2/conf/bestman2.rc  Main BeStMan2 configuration file     /etc/sysconfig/bestman2  Environment variables used by BeStMan2     /etc/sysconfig/bestman2lib  Environment variables that store values of various client and server libraries used by BeStMan2     /etc/bestman2/conf/*  Other runtime configuration files     /etc/init.d/bestman2  init.d startup script     /etc/gridftp.conf  Startup parameters    GridFTP  /etc/sysconfig/globus-gridftp-server  Environment variables for GridFTP    Gratia Probe  /etc/gratia/gridftp-transfer/ProbeConfig  GridFTP Gratia Probe configuration     /etc/cron.d/gratia-probe-gridftp-transfer.cron  Cron tab file        Service/Process  Log File  Description      BeStMan2  /var/log/bestman2/bestman2.log  BeStMan2 container log     /var/log/bestman2/event.srm.log  Records all SRM transactions    GridFTP  /var/log/gridftp.log  Transfer log     /var/log/gridftp-auth.log  GridFTP authorization log     /var/log/messages  Main system log (look here for LCMAPS errors)    Gratia probe  /var/log/gratia", 
            "title": "Useful Configuration and Log Files"
        }, 
        {
            "location": "/storage/bestman-install/#upgrading-bestman", 
            "text": "Upgrading BeStMan can be done by  [root@client ~] #  yum upgrade bestman2-server  There are a few notes to be aware of when upgrading BeStMan.   From many of the versions of the BeStMan, configuration changes have taken place. Do not ignore any warnings about rpmsave or rpmnew files. You will need to especially be careful about and  /etc/bestman2/conf/bestman2.rc .  Beginning with BeStMan 2.3.0-9, many dependency locations changed. Be sure that  /etc/sysconfig/bestman2lib  contains the  build-classpath  directives in the  BESTMAN2_SERVER_LIB  and  BESTMAN2_CLIENT_LIB . Otherwise, you may get java class loading errors on startup or on run-time. Be sure to remove these entries from the  /etc/sysconfig/bestman2  file.  For BeStMan 2.1.3, certain versions had a combined sysconfig and configuration file. You may need to split these files apart if this is the case.   For more help, please contact the GOC to create a support ticket.", 
            "title": "Upgrading BeStMan"
        }, 
        {
            "location": "/storage/bestman-install/#how-to-get-help", 
            "text": "If you cannot resolve the problem, there are several ways to receive help:   For bug support and issues, submit a ticket to the  Grid Operations Center .  For community support and best-effort software team support contact  .   For a full set of help options, see the  Help Procedure .", 
            "title": "How to get Help?"
        }, 
        {
            "location": "/storage/bestman-install/#references", 
            "text": "Storage infrastructure software  Information on planning, installing and validating storage software  Tips and FAQ  OSG Gratia Transfer Probe page  SRM v2.2 LBNL client command line examples  SRM-Tester  BeStMan official website  BeStMan User guides  BeStMan FAQ    SLAC Gateway mode Instruction  - SLAC guide on gateway mode  US ATLAS instruction page  SRM specifications and collaboration  - from SRM collaboration working group  S2  - A SRM v2.2 test suite from CERN. It provides basic functionality tests based on use cases, and cross-copy tests, as part of the certification process and supports file access/transfer protocols: rfio, dcap, gsidcap, gsiftp  SHA-2 compliance page  Bestman scalability tuning", 
            "title": "References"
        }, 
        {
            "location": "/storage/bestman-install/#known-issues", 
            "text": "", 
            "title": "Known Issues"
        }, 
        {
            "location": "/storage/bestman-install/#requesting-host-certificates-in-rhel6", 
            "text": "Bestman may not start if the certificates were requested on slc6. This is be caused by a bug in JGlobus (see  JGlobusIssue118 ), a  bestman2  dependency. A known workaround is to run this command  [user@client ~] $  openssl rsa -in mykey.pem -out mykey.pem.old  This command on converts  mykey.pem  to  mykey.pem.old ; the latter format is supported.", 
            "title": "Requesting host certificates in RHEL6"
        }, 
        {
            "location": "/client/glexec/", 
            "text": "Glexec Installation Guide\n\n\n\n\nWarning\n\n\nAs of the June 2017 release of OSG 3.4.0, this software is officially deprecated.  Support is scheduled to end as of June 2018.\n\n\n\n\nThis document is intended for System Administrators that are installing the OSG version of glexec.\n\n\nGlexec is commonly used for what are referred to as \"pilot\" or \"glidein\" jobs.\n\n\nTraditionally, users submitted their jobs directly to a remote site (or compute element gatekeeper). The user job was authenticated/authorized to run at that site based on the user\u2019s proxy credentials and run under the local unix account assigned.\n\n\nIn a pilot-based infrastructure, users submit their jobs to a centralized site (or queue). The pilot/glidein software at the centralized site then recognizes there is a demand for computing resources. It will then submit what is called a pilot/glidein job to a remote site. This pilot job gets authenticated/authorized to run on a worker node in that site\u2019s cluster. It will then \"pull\" down user jobs from the centralized queue and execute them. Both the pilot and the user job are run under the pilot job\u2019s proxy certificate credentials and local unix account. This represents a security problem in pilot-based systems as there is no authentication/authorization of the individual user\u2019s proxy credentials and, thus, the user\u2019s jobs do not run using it\u2019s own local unix account.\n\n\nGlexec is a security tool that can be used to resolve this problem. It is meant to be used by VOs that run these pilot-based jobs. It has a number of authentication plugins and can be used both by European grid and by OSG.\n\n\nThe pilot job will \"pull\" user jobs down from the central queue and invoke glexec which will then\n\n\n\n\nauthenticate the user job\u2019s proxy,\n\n\nperform an authorization callout (to GUMS in the case of OSG, or possibly a gridmapfile) similar to that done by the gatekeeper,\n\n\nand then run the user job under the local account assigned by the authorization service for that user.\n\n\n\n\nIn effect, glexec functions much the same as a compute element gatekeeper, except these functions are now performed on the individual worker node. The pilot jobs authentication/authorization is done by the gatekeeper and the individual user jobs are now done by glexec on the individual worker node.\n\n\nMany worker node clusters use shared file systems like NFS for much of their software and user home accounts. Since glexec is an suid program, it must be installed on every single worker node individually. Most shared file systems do not handle this correctly so it cannot and must not be NFS-exported.\n\n\nFor more information regarding pilot-based systems and glexec:\n\n\n\n\nglideinWMS - The glidein based WMS\n\n\nAddressing the pilot security problem with gLExec (pdf)\n\n\n\n\nEngineering Considerations\n\n\nIf glexec is to be used at a site, it should be installed and configured on every worker node.\n\n\nA large number of batch slots using glexec can occasionally put an enormous strain on GUMS servers and cause overloading and client timeouts. In order to survive peak loads, the sysctl parameter \nnet.core.somaxconn\n on a GUMS server machine should be set at least as high as the maximum number of job slots that might attempt to contact the server at about the same time.  For example, Fermilab set the value to 4096 on each of two servers and tested with a continuous load from 5000 job slots.\n\n\nRequirements\n\n\nThese are the requirements that must be met to install glexec.\n\n\n\n\nNote\n\n\nNormally you will install the \nOSG worker node\n first. Installing the \nosg-wn-client-glexec\n package will also install the worker node, but we do not duplicate instructions specific to the worker node here.\n\n\n\n\n\n\nVerify you are using one of the \nsupported platforms\n.\n\n\nPrior to installing \nglexec\n, verify the \nyum repositories\n are correctly configured.\n\n\nroot\n access to the host is required.\n\n\nThe worker nodes will need the \nCA certificates\n used to sign the proxies.\n\n\nfetch-crl\n should be enabled and working.\n\n\n\n\nThe glexec installation will create two users unless they are already created.\n\n\n\n\n\n\n\n\nUser\n\n\nComment\n\n\n\n\n\n\n\n\n\n\nglexec\n\n\nReduced privilege separate id used to improve security. If creating the account by hand, set the default gid of the \nglexec\n user to be a group that is also called \nglexec\n.\n\n\n\n\n\n\ngratia\n\n\nNeeded for the glexec gratia probe which is also automatically installed.\n\n\n\n\n\n\n\n\nIn addition, OSG glexec requires a range of \ngroup ids\n for tracking purposes. You don\u2018t actually have to create the group entries but it is recommended to do so in order to reserve the gids and so they can be associated with names in the \n/usr/bin/id\n command. The recommended names are \nglexecNN\n where NN is a number starting from 00.\n\n\n\n\nDefine at least 4 group ids per batch slot per worker node. A conservative way to handle this is to multiply the number of batch slots on the largest worker node by 6 and then share the group ids between all the worker nodes.\n\n\nThey must be consecutive and in any range (default range is 65000-65049, configured in the \nconfiguring glexec\n section below).\n\n\nThe same group IDs can be used on every worker node.\n\n\n\n\nInstall Instructions\n\n\n\n\nNote\n\n\nThe glexec tracking function requires a part of HTCondor. There are multiple ways to install HTCondor, for details see \nthese instructions\n. If you want a minimal install, you can run just this command to install the needed piece from the OSG distribution:\n\n\n[root@client ~] #\n yum install condor-procd\n\n\n\n\n\n\n\nAfter meeting all the requirements in the previous section, install glexec with this command:\n\n\n[root@client ~] #\n yum install osg-wn-client-glexec\n\n\n\n\n\nConfiguring glexec\n\n\nThe following steps need to be done after the glexec installation is complete.\n\n\n\n\nFirst, review the contents of \n/etc/glexec.conf\n. All of the defaults should be fine, but if you want to change the behavior, the parameters are described in \nman glexec.conf\n.\n\n\n\n\nNext, review all of the contents of \n/etc/lcmaps.db\n and in particular update the following pieces.\n\n\n\n\n\n\nIf you have GUMS, change \nGUMS_HOST\n in the following line to the fully qualified domain name of your GUMS server:\n\n\n\u2013endpoint https://\nGUMS_HOST\n:8443/gums/services/GUMSXACMLAuthorizationServicePort\n\n\n\n\n\n\n\n\n\n\nIf you want to use a range of tracking group ids other than the default as described in the \nRequirements\n section above, uncomment and change the \n-min-gid\n and \n-max-gid\n lines to your chosen values:\n\n\n-min-gid 65000\n \n-max-gid 65049\n\n\n\n\n\n\n\n\n\n\nUncomment the following two lines:\n\n\nglexectracking = \nlcmaps_glexec_tracking.mod\n\n                 \n-exec /usr/sbin/glexec_monitor\n\n\n\n\n\n\n\n\n\n\nIf you have GUMS, uncomment the following policy toward the end of the file:\n\n\nverifyproxy -\n gumsclient\ngumsclient -\n glexectracking\n\n\n\n\n\nor if you have do not have GUMS and want to use a gridmapfile, uncomment the following policy:\n\n\nverifyproxy -\n gridmapfile\ngridmapfile -\n glexectracking\n\n\n\n\n\n\n\n\n\n\n\n\n\nTesting the Installation of glexec\n\n\nNow, \nas a non-privileged user (not root)\n, do the following (where \n is your VO, and \n is your uid as reported by \n/usr/bin/id\n):\n\n\n[user@client ~] $\n voms-proxy-init -voms \nYOURVO\n:/\nYOURVO\n\n\n[user@client ~] $\n \nexport\n \nGLEXEC_CLIENT_CERT\n=\n/tmp/x509up_u\nUID\n\n\n[user@client ~] $\n \nexport\n \nX509_USER_PROXY\n=\n/tmp/x509up_u\nUID\n\n\n[user@client ~] $\n /usr/sbin/glexec /usr/bin/id\n\n[user@client ~] $\n \nuid\n=\n13160\n(\nfnalgrid\n)\n \ngid\n=\n9767\n(\nfnalgrid\n)\n \ngroups\n=\n65000\n(\nglexec00\n)\n\n\n\n\n\n\nIf \nglexec\n is successful, it will print out the uid and gid that your proxy would normally be mapped to by your GUMS server, plus a supplementary tracking group. (The actual names and numbers will be different from what you see above.)\n\n\nIf you have problems, please read about \ntroubleshooting glexec\n.\n\n\nGlexec log files\n\n\nGlexec sends all its log information by default to syslog. By default they go to \n/var/log/messages\n, but this may differ if you have customized your syslog setup. Here are some sample messages:\n\n\nApr 25 16:36:16 fermicloud053 glexec[2867]: lcmaps: lcmaps.mod-PluginInit(): plugin glexectracking not found (arguments: )\nApr 25 16:36:16 fermicloud053 glexec[2867]: lcmaps: lcmaps.mod-lcmaps_startPluginManager(): error initializing plugin: glexectracking\nApr 25 16:36:16 fermicloud053 glexec[2867]: lcmaps: lcmaps_init() error: could not start plugin manager\nApr 25 16:36:16 fermicloud053 glexec[2867]: Initialisation of LCMAPS failed.\n\n\n\n\n\nThese particular messages are pretty common, caused by forgetting to uncomment the beginning of the \nglexectracking\n rule in \n/etc/lcmaps.db\n.\n\n\nIt is possible to redirect glexec log messages to a different file with standard syslog. To do that, choose one of the \nLOG_LOCAL[0-7]\n log facilities that are unused, for example \nLOG_LOCAL1\n. Then set the following in \n/etc/glexec.conf\n:\n\n\nsyslog_facility = LOG_LOCAL1\n\n\n\n\n\nand add a corresponding parameter to the \nlcmaps_glexec_tracking.mod\n entry in \n/etc/lcmaps.db\n:\n\n\n  \n-log-facility LOG_LOCAL1\n\n\n\n\n\n\nThen in \n/etc/rsyslog.conf\n, add a line like this:\n\n\nlocal1.* /var/log/glexec.log\n\n\n\n\n\nand also exclude those messages from \n/var/log/messages\n by adding \nlocal1.none\n after other wildcards on the existing \n/var/log/messages\n line, for example:\n\n\n*.info;local1.none;mail.none;authpriv.none;cron.none /var/log/messages\n\n\n\n\n\nBe sure to notify the system logger to re-read the configuration file with \nservice rsyslog restart\n.\n\n\nrsyslog\n, by default, limits the rate at which messages may be logged, and if maximum debugging is enabled in glexec this limit is reached. To avoid that, you can add the following to \n/etc/rsyslog.conf\n after the line \"$ModLoad imuxsock.so\":\n\n\n$SystemLogRateLimitInterval 0\n$SystemLogRateLimitBurst 0\n\n\n\n\n\nand do \nservice rsyslog restart\n.\n\n\nAlternatively, \nsyslog-ng\n (available in the EPEL repository) can do the same job by matching all the messages that have the string \"glexec\" in the name.\nThese rules in \n/etc/syslog-ng/syslog-ng.conf\n will separate the glexec messages into \n/var/log/glexec.log\n:\n\n\ndestination d_glexec { file(\n/var/log/glexec.log\n); };\nfilter f_glexec { program(\n^glexec\n); };\nfilter f_notglexec { not program(\n^glexec\n); };\nlog { source(s_sys); filter(f_glexec); destination(d_glexec); };\n\n\n\n\n\nThen later, in the log rule writing sending to \nd_mesg\n, add a \nfilter(f_notglexec);\n before the destination rule to keep glexec messages out of \n/var/log/messages\n:\n\n\nlog { source(s_sys); filter(f_filter1); filter(f_notglexec); destination(d_mesg); };\n\n\n\n\n\nHow to get Help?\n\n\nTo get assistance please use the \nHelp Procedure\n.", 
            "title": "Worker node glexec"
        }, 
        {
            "location": "/client/glexec/#glexec-installation-guide", 
            "text": "Warning  As of the June 2017 release of OSG 3.4.0, this software is officially deprecated.  Support is scheduled to end as of June 2018.   This document is intended for System Administrators that are installing the OSG version of glexec.  Glexec is commonly used for what are referred to as \"pilot\" or \"glidein\" jobs.  Traditionally, users submitted their jobs directly to a remote site (or compute element gatekeeper). The user job was authenticated/authorized to run at that site based on the user\u2019s proxy credentials and run under the local unix account assigned.  In a pilot-based infrastructure, users submit their jobs to a centralized site (or queue). The pilot/glidein software at the centralized site then recognizes there is a demand for computing resources. It will then submit what is called a pilot/glidein job to a remote site. This pilot job gets authenticated/authorized to run on a worker node in that site\u2019s cluster. It will then \"pull\" down user jobs from the centralized queue and execute them. Both the pilot and the user job are run under the pilot job\u2019s proxy certificate credentials and local unix account. This represents a security problem in pilot-based systems as there is no authentication/authorization of the individual user\u2019s proxy credentials and, thus, the user\u2019s jobs do not run using it\u2019s own local unix account.  Glexec is a security tool that can be used to resolve this problem. It is meant to be used by VOs that run these pilot-based jobs. It has a number of authentication plugins and can be used both by European grid and by OSG.  The pilot job will \"pull\" user jobs down from the central queue and invoke glexec which will then   authenticate the user job\u2019s proxy,  perform an authorization callout (to GUMS in the case of OSG, or possibly a gridmapfile) similar to that done by the gatekeeper,  and then run the user job under the local account assigned by the authorization service for that user.   In effect, glexec functions much the same as a compute element gatekeeper, except these functions are now performed on the individual worker node. The pilot jobs authentication/authorization is done by the gatekeeper and the individual user jobs are now done by glexec on the individual worker node.  Many worker node clusters use shared file systems like NFS for much of their software and user home accounts. Since glexec is an suid program, it must be installed on every single worker node individually. Most shared file systems do not handle this correctly so it cannot and must not be NFS-exported.  For more information regarding pilot-based systems and glexec:   glideinWMS - The glidein based WMS  Addressing the pilot security problem with gLExec (pdf)", 
            "title": "Glexec Installation Guide"
        }, 
        {
            "location": "/client/glexec/#engineering-considerations", 
            "text": "If glexec is to be used at a site, it should be installed and configured on every worker node.  A large number of batch slots using glexec can occasionally put an enormous strain on GUMS servers and cause overloading and client timeouts. In order to survive peak loads, the sysctl parameter  net.core.somaxconn  on a GUMS server machine should be set at least as high as the maximum number of job slots that might attempt to contact the server at about the same time.  For example, Fermilab set the value to 4096 on each of two servers and tested with a continuous load from 5000 job slots.", 
            "title": "Engineering Considerations"
        }, 
        {
            "location": "/client/glexec/#requirements", 
            "text": "These are the requirements that must be met to install glexec.   Note  Normally you will install the  OSG worker node  first. Installing the  osg-wn-client-glexec  package will also install the worker node, but we do not duplicate instructions specific to the worker node here.    Verify you are using one of the  supported platforms .  Prior to installing  glexec , verify the  yum repositories  are correctly configured.  root  access to the host is required.  The worker nodes will need the  CA certificates  used to sign the proxies.  fetch-crl  should be enabled and working.   The glexec installation will create two users unless they are already created.     User  Comment      glexec  Reduced privilege separate id used to improve security. If creating the account by hand, set the default gid of the  glexec  user to be a group that is also called  glexec .    gratia  Needed for the glexec gratia probe which is also automatically installed.     In addition, OSG glexec requires a range of  group ids  for tracking purposes. You don\u2018t actually have to create the group entries but it is recommended to do so in order to reserve the gids and so they can be associated with names in the  /usr/bin/id  command. The recommended names are  glexecNN  where NN is a number starting from 00.   Define at least 4 group ids per batch slot per worker node. A conservative way to handle this is to multiply the number of batch slots on the largest worker node by 6 and then share the group ids between all the worker nodes.  They must be consecutive and in any range (default range is 65000-65049, configured in the  configuring glexec  section below).  The same group IDs can be used on every worker node.", 
            "title": "Requirements"
        }, 
        {
            "location": "/client/glexec/#install-instructions", 
            "text": "Note  The glexec tracking function requires a part of HTCondor. There are multiple ways to install HTCondor, for details see  these instructions . If you want a minimal install, you can run just this command to install the needed piece from the OSG distribution:  [root@client ~] #  yum install condor-procd   After meeting all the requirements in the previous section, install glexec with this command:  [root@client ~] #  yum install osg-wn-client-glexec", 
            "title": "Install Instructions"
        }, 
        {
            "location": "/client/glexec/#configuring-glexec", 
            "text": "The following steps need to be done after the glexec installation is complete.   First, review the contents of  /etc/glexec.conf . All of the defaults should be fine, but if you want to change the behavior, the parameters are described in  man glexec.conf .   Next, review all of the contents of  /etc/lcmaps.db  and in particular update the following pieces.    If you have GUMS, change  GUMS_HOST  in the following line to the fully qualified domain name of your GUMS server:  \u2013endpoint https:// GUMS_HOST :8443/gums/services/GUMSXACMLAuthorizationServicePort     If you want to use a range of tracking group ids other than the default as described in the  Requirements  section above, uncomment and change the  -min-gid  and  -max-gid  lines to your chosen values:  -min-gid 65000   -max-gid 65049     Uncomment the following two lines:  glexectracking =  lcmaps_glexec_tracking.mod \n                  -exec /usr/sbin/glexec_monitor     If you have GUMS, uncomment the following policy toward the end of the file:  verifyproxy -  gumsclient\ngumsclient -  glexectracking  or if you have do not have GUMS and want to use a gridmapfile, uncomment the following policy:  verifyproxy -  gridmapfile\ngridmapfile -  glexectracking", 
            "title": "Configuring glexec"
        }, 
        {
            "location": "/client/glexec/#testing-the-installation-of-glexec", 
            "text": "Now,  as a non-privileged user (not root) , do the following (where   is your VO, and   is your uid as reported by  /usr/bin/id ):  [user@client ~] $  voms-proxy-init -voms  YOURVO :/ YOURVO  [user@client ~] $   export   GLEXEC_CLIENT_CERT = /tmp/x509up_u UID  [user@client ~] $   export   X509_USER_PROXY = /tmp/x509up_u UID  [user@client ~] $  /usr/sbin/glexec /usr/bin/id [user@client ~] $   uid = 13160 ( fnalgrid )   gid = 9767 ( fnalgrid )   groups = 65000 ( glexec00 )   If  glexec  is successful, it will print out the uid and gid that your proxy would normally be mapped to by your GUMS server, plus a supplementary tracking group. (The actual names and numbers will be different from what you see above.)  If you have problems, please read about  troubleshooting glexec .", 
            "title": "Testing the Installation of glexec"
        }, 
        {
            "location": "/client/glexec/#glexec-log-files", 
            "text": "Glexec sends all its log information by default to syslog. By default they go to  /var/log/messages , but this may differ if you have customized your syslog setup. Here are some sample messages:  Apr 25 16:36:16 fermicloud053 glexec[2867]: lcmaps: lcmaps.mod-PluginInit(): plugin glexectracking not found (arguments: )\nApr 25 16:36:16 fermicloud053 glexec[2867]: lcmaps: lcmaps.mod-lcmaps_startPluginManager(): error initializing plugin: glexectracking\nApr 25 16:36:16 fermicloud053 glexec[2867]: lcmaps: lcmaps_init() error: could not start plugin manager\nApr 25 16:36:16 fermicloud053 glexec[2867]: Initialisation of LCMAPS failed.  These particular messages are pretty common, caused by forgetting to uncomment the beginning of the  glexectracking  rule in  /etc/lcmaps.db .  It is possible to redirect glexec log messages to a different file with standard syslog. To do that, choose one of the  LOG_LOCAL[0-7]  log facilities that are unused, for example  LOG_LOCAL1 . Then set the following in  /etc/glexec.conf :  syslog_facility = LOG_LOCAL1  and add a corresponding parameter to the  lcmaps_glexec_tracking.mod  entry in  /etc/lcmaps.db :     -log-facility LOG_LOCAL1   Then in  /etc/rsyslog.conf , add a line like this:  local1.* /var/log/glexec.log  and also exclude those messages from  /var/log/messages  by adding  local1.none  after other wildcards on the existing  /var/log/messages  line, for example:  *.info;local1.none;mail.none;authpriv.none;cron.none /var/log/messages  Be sure to notify the system logger to re-read the configuration file with  service rsyslog restart .  rsyslog , by default, limits the rate at which messages may be logged, and if maximum debugging is enabled in glexec this limit is reached. To avoid that, you can add the following to  /etc/rsyslog.conf  after the line \"$ModLoad imuxsock.so\":  $SystemLogRateLimitInterval 0\n$SystemLogRateLimitBurst 0  and do  service rsyslog restart .  Alternatively,  syslog-ng  (available in the EPEL repository) can do the same job by matching all the messages that have the string \"glexec\" in the name.\nThese rules in  /etc/syslog-ng/syslog-ng.conf  will separate the glexec messages into  /var/log/glexec.log :  destination d_glexec { file( /var/log/glexec.log ); };\nfilter f_glexec { program( ^glexec ); };\nfilter f_notglexec { not program( ^glexec ); };\nlog { source(s_sys); filter(f_glexec); destination(d_glexec); };  Then later, in the log rule writing sending to  d_mesg , add a  filter(f_notglexec);  before the destination rule to keep glexec messages out of  /var/log/messages :  log { source(s_sys); filter(f_filter1); filter(f_notglexec); destination(d_mesg); };", 
            "title": "Glexec log files"
        }, 
        {
            "location": "/client/glexec/#how-to-get-help", 
            "text": "To get assistance please use the  Help Procedure .", 
            "title": "How to get Help?"
        }, 
        {
            "location": "/common/help/", 
            "text": "How to Get Help\n\n\nThis page is aimed at OSG site administrators looking for support. Help for OSG users is found at \nour support desk\n.\n\n\nGrid Operations Center\n\n\nThe Grid Operations Center (GOC) is available to coordinate users, site admins, and developers around an issue.  Additionally, the GOC can provide basic monitoring and troubleshooting.  There are several ways to receive support:\n\n\n\n\nYou can \nsubmit a trouble ticket\n or send an email to \ngoc@opensciencegrid.org\n (which also accept general inquiries not intended for tickets.)\n\n\nThe \ntrouble ticket system\n is searchable.  Historical tickets may contain the solution for similar problems others have encountered.\n\n\nThe \noperations blog\n contains information about recent software releases, and important outage and maintenance notifications of central OSG services.\n\n\nFor emergencies, the OSG Grid Operation Center provides extended support. Operators are on hand 24x7 at the GOC and can be reached via phone at +1 317-278-9699.   Non-emergency issues can be opened 24x7 but will be handled during normal business hours.\n\n\n\n\nSecurity incident\n\n\nSecurity incidents can be reported by following the instructions on the \nIncident Discovery and Reporting\n page.  Additional steps to aid in the incident handling process are also linked from that page.\n\n\nInformation Required to Help You\n\n\nIf you came to this page from an installation or other document in this website, then follow instructions in the \nTroubleshooting\n and \nDebugging\n sections of that document and include results in your support inquiry, no matter which channel you choose (email, trouble ticket, web chat, ...)\n\n\nFor problems with installation of some software run \nosg-system-profiler\n:\n\n\n[root@client ~] #\n osg-system-profiler\n\n\n\n\n\nAttach the generated \nosg-profile.txt\n to your support inquiry.\n\n\nCommunity-specific Resources\n\n\nSome OSG VOs have dedicated forums or mechanisms for community-specific support.  If your VO provides user support, that should be a user's first line of support because the VO is most familiar with your applications and requirements.\n\n\n\n\nThe list of support contacts for OSG VOs can be found in the \nSupport Center Tab on MyOSG\n.\n\n\nResources for \nCMS\n sites:\n\n\nhttp://www.uscms.org/uscms_at_work/physics/computing/grid/index.shtml\n\n\nCMS Hyper News: \nhttps://hypernews.cern.ch/HyperNews/CMS/get/osg-tier3.html\n\n\nCMS Twiki: \nhttps://twiki.cern.ch/twiki/bin/viewauth/CMS/USTier3Computing", 
            "title": "Get Help"
        }, 
        {
            "location": "/common/help/#how-to-get-help", 
            "text": "This page is aimed at OSG site administrators looking for support. Help for OSG users is found at  our support desk .", 
            "title": "How to Get Help"
        }, 
        {
            "location": "/common/help/#grid-operations-center", 
            "text": "The Grid Operations Center (GOC) is available to coordinate users, site admins, and developers around an issue.  Additionally, the GOC can provide basic monitoring and troubleshooting.  There are several ways to receive support:   You can  submit a trouble ticket  or send an email to  goc@opensciencegrid.org  (which also accept general inquiries not intended for tickets.)  The  trouble ticket system  is searchable.  Historical tickets may contain the solution for similar problems others have encountered.  The  operations blog  contains information about recent software releases, and important outage and maintenance notifications of central OSG services.  For emergencies, the OSG Grid Operation Center provides extended support. Operators are on hand 24x7 at the GOC and can be reached via phone at +1 317-278-9699.   Non-emergency issues can be opened 24x7 but will be handled during normal business hours.", 
            "title": "Grid Operations Center"
        }, 
        {
            "location": "/common/help/#security-incident", 
            "text": "Security incidents can be reported by following the instructions on the  Incident Discovery and Reporting  page.  Additional steps to aid in the incident handling process are also linked from that page.", 
            "title": "Security incident"
        }, 
        {
            "location": "/common/help/#information-required-to-help-you", 
            "text": "If you came to this page from an installation or other document in this website, then follow instructions in the  Troubleshooting  and  Debugging  sections of that document and include results in your support inquiry, no matter which channel you choose (email, trouble ticket, web chat, ...)  For problems with installation of some software run  osg-system-profiler :  [root@client ~] #  osg-system-profiler  Attach the generated  osg-profile.txt  to your support inquiry.", 
            "title": "Information Required to Help You"
        }, 
        {
            "location": "/common/help/#community-specific-resources", 
            "text": "Some OSG VOs have dedicated forums or mechanisms for community-specific support.  If your VO provides user support, that should be a user's first line of support because the VO is most familiar with your applications and requirements.   The list of support contacts for OSG VOs can be found in the  Support Center Tab on MyOSG .  Resources for  CMS  sites:  http://www.uscms.org/uscms_at_work/physics/computing/grid/index.shtml  CMS Hyper News:  https://hypernews.cern.ch/HyperNews/CMS/get/osg-tier3.html  CMS Twiki:  https://twiki.cern.ch/twiki/bin/viewauth/CMS/USTier3Computing", 
            "title": "Community-specific Resources"
        }
    ]
}